{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys,os\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "import concurrent.futures\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target_dir = \"my_results/icml_experiments/cifar10/\"\n",
    "ATTACK_RESULTS_PATH = \"my_results/icml_experiments/cifar10_attack_results_quick/\"\n",
    "\n",
    "TOTAL_PROCESSES = 128\n",
    "MAX_MACHINES =  8\n",
    "MAX_ITERATIONS=10000\n",
    "STARTING_ITERATION = 0\n",
    "\n",
    "linestyles = {\n",
    "    \"ZeroSum\" : \"--\"\n",
    "}\n",
    "\n",
    "fontsize=20\n",
    "\n",
    "alpha = 0.1\n",
    "\n",
    "save_directory = \"assets/\"\n",
    "\n",
    "\n",
    "\n",
    "assert TOTAL_PROCESSES%MAX_MACHINES == 0\n",
    "MAX_PROCESSES = TOTAL_PROCESSES//MAX_MACHINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the file list\n",
    "experiments_dict = utils.get_full_path_dict(target_dir)\n",
    "experiments_attributes = utils.get_experiments_dict(experiments_dict)\n",
    "\n",
    "print(experiments_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_folder = 'machine{}'\n",
    "result_file = '{}_results.json'\n",
    "\n",
    "\n",
    "def load_data(dir):\n",
    "    data = pd.DataFrame({})\n",
    "    for machine in range(MAX_MACHINES):\n",
    "        for rank in range(MAX_PROCESSES):\n",
    "            # print(f\"Loading results for machine {machine} and rank {rank}.  \",end = \"\\r\")\n",
    "            uid = rank + machine * MAX_PROCESSES\n",
    "\n",
    "            file = os.path.join(dir, machine_folder.format(machine), result_file.format(rank))\n",
    "            tmp_df = pd.read_json(file)\n",
    "            tmp_df[\"uid\"] = uid # Manually add the uid for further processing                                                                   \n",
    "            tmp_df[\"iteration\"] = tmp_df.index\n",
    "            # print(tmp_df)\n",
    "            tmp_df = tmp_df[tmp_df[\"iteration\"]>=STARTING_ITERATION]\n",
    "            tmp_df = tmp_df[tmp_df[\"iteration\"]<=MAX_ITERATIONS]\n",
    "            data = pd.concat([data,tmp_df])\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_attack_results(current_experiment_data,experiment_name,attack_results_path):\n",
    "    expected_file_name = experiment_name + \".csv\"\n",
    "    directories = sorted(os.listdir(attack_results_path))\n",
    "    \n",
    "    if expected_file_name not in directories:\n",
    "        raise ValueError(f\"{expected_file_name} was not listed with attack results in {attack_results_path}. Entire directory:\\n{directories}\")\n",
    "    \n",
    "    attacks_df = pd.read_csv(os.path.join(attack_results_path,expected_file_name))\n",
    "    attacks_df = attacks_df.drop(columns = \"Unnamed: 0\")\n",
    "    attacks_df = attacks_df.rename(columns = {\"agent\":\"uid\"})\n",
    "    # print(attacks_df.columns)\n",
    "    # print(current_experiment_data)\n",
    "    # print(attacks_df)\n",
    "    \n",
    "    res = pd.merge(current_experiment_data, attacks_df,on = [\"uid\",\"iteration\"],how=\"outer\" )\n",
    "    # print(res)\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "def load_data_element(input_dict,name,filepath,attack_result_path):\n",
    "    print(f\"Loading data from {name}\")\n",
    "    current_results = load_data(filepath).dropna()\n",
    "    input_dict[name] = load_attack_results(current_results,name,attack_results_path=attack_result_path)\n",
    "    print(f\"Finished loading data from {name}\")\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "loaded_data = {}\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:\n",
    "    for name,filepath in sorted(experiments_dict.items()):\n",
    "        executor.submit(load_data_element,loaded_data,name,filepath,ATTACK_RESULTS_PATH)\n",
    "        # load_data_element(loaded_data,name,filepath,ATTACK_RESULTS_PATH)\n",
    "        # break\n",
    "print(\"Finished loading all data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_methods = [\"mean\", \"std\", \"sum\",\"min\",\"max\"]\n",
    "\n",
    "def format_data(data,key):\n",
    "    usable_data = data.groupby('iteration').agg(agg_methods)\n",
    "    usable_data.reset_index(inplace=True)\n",
    "\n",
    "    usable_data.insert(1,\"experience_name\",key)\n",
    "    usable_data.insert(2,\"number_agents\",TOTAL_PROCESSES)\n",
    "\n",
    "    usable_data.columns = [' '.join(e) if len(e[-1])>0 else e[0] for e in usable_data.columns]\n",
    "\n",
    "    usable_data.set_index(\"iteration\",inplace=True)\n",
    "    return usable_data\n",
    "\n",
    "formatted_data = {}\n",
    "for name,data in loaded_data.items():\n",
    "    formatted_data[name] = format_data(data,name)\n",
    "# formatted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_all_experiments(\n",
    "    formatted_data,\n",
    "    experiments_attributes,\n",
    "    experiments_attributes,\n",
    "    None,\n",
    "    \"test_acc mean\",\n",
    "    save_directory=save_directory\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise cancellation vs no noise cancellation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "zerosum_attributes = {\"variant\":[\"nonoise\",\"zerosum\"],\"topology_type\":[\"static\"]}\n",
    "\n",
    "display_attributes ={\n",
    "    \"color\":{\n",
    "        \"nonoise\":\"cyan\",\n",
    "        \"2th\":\"red\",\n",
    "        \"4th\":\"orange\",\n",
    "        \"8th\": \"yellow\",\n",
    "        \"16th\":\"green\",\n",
    "        \"32th\":\"blue\",\n",
    "        \"64th\":\"purple\",\n",
    "    },\n",
    "    \"linestyle\":{\n",
    "        \"noselfnoise\":\"--\",\n",
    "        \"selfnoise\":\"-\"\n",
    "    },\n",
    "    \"linewidth\":{\n",
    "        \"nonoise\":5,\n",
    "        \"zerosum\":1,\n",
    "    }\n",
    "}\n",
    "\n",
    "zerosum_experiments = utils.filter_attribute(experiments_attributes,zerosum_attributes)\n",
    "for experiment in sorted(zerosum_experiments):\n",
    "    print(experiment)\n",
    "\n",
    "utils.plot_all_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    experiments_attributes,\n",
    "    display_attributes,\n",
    "    \"test_acc mean\",\n",
    "    save_directory=save_directory\n",
    "    \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the dynamic case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "zerosum_attributes = {\"variant\":[\"nonoise\",\"zerosum\"],\"topology_type\":[\"dynamic\"]}\n",
    "\n",
    "display_attributes ={\n",
    "    \"color\":{\n",
    "        \"nonoise\":\"cyan\",\n",
    "        \"2th\":\"red\",\n",
    "        \"4th\":\"orange\",\n",
    "        \"8th\": \"yellow\",\n",
    "        \"16th\":\"green\",\n",
    "        \"32th\":\"blue\",\n",
    "        \"64th\":\"purple\",\n",
    "    },\n",
    "    \"linestyle\":{\n",
    "        \"noselfnoise\":\"--\",\n",
    "        \"selfnoise\":\"-\"\n",
    "    },\n",
    "    \"linewidth\":{\n",
    "        \"nonoise\":5,\n",
    "        \"zerosum\":1,\n",
    "    }\n",
    "}\n",
    "\n",
    "zerosum_experiments = utils.filter_attribute(experiments_attributes,zerosum_attributes)\n",
    "for experiment in sorted(zerosum_experiments):\n",
    "    print(experiment)\n",
    "\n",
    "utils.plot_all_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    experiments_attributes,\n",
    "    display_attributes,\n",
    "    \"test_acc mean\",\n",
    "    save_directory=save_directory\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attack results\n",
    "## In the static case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "zerosum_attributes = {\"variant\":[\"nonoise\",\"zerosum\"],\"topology_type\":[\"static\"]}\n",
    "\n",
    "display_attributes ={\n",
    "    \"color\":{\n",
    "        \"nonoise\":\"cyan\",\n",
    "        \"2th\":\"red\",\n",
    "        \"4th\":\"orange\",\n",
    "        \"8th\": \"yellow\",\n",
    "        \"16th\":\"green\",\n",
    "        \"32th\":\"blue\",\n",
    "        \"64th\":\"purple\",\n",
    "    },\n",
    "    \"linestyle\":{\n",
    "        \"noselfnoise\":\"--\",\n",
    "        \"selfnoise\":\"-\"\n",
    "    },\n",
    "    \"linewidth\":{\n",
    "        \"nonoise\":5,\n",
    "        \"zerosum\":1,\n",
    "    }\n",
    "}\n",
    "\n",
    "zerosum_experiments = utils.filter_attribute(experiments_attributes,zerosum_attributes)\n",
    "for experiment in sorted(zerosum_experiments):\n",
    "    print(experiment)\n",
    "\n",
    "utils.plot_all_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    experiments_attributes,\n",
    "    display_attributes,\n",
    "    \"roc_auc mean\",\n",
    "    save_directory=save_directory,\n",
    "    figsize=(10,10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack results in the dynamic case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "zerosum_attributes = {\"variant\":[\"nonoise\",\"zerosum\"],\"topology_type\":[\"dynamic\"]}\n",
    "\n",
    "display_attributes ={\n",
    "    \"color\":{\n",
    "        \"nonoise\":\"cyan\",\n",
    "        \"2th\":\"red\",\n",
    "        \"4th\":\"orange\",\n",
    "        \"8th\": \"yellow\",\n",
    "        \"16th\":\"green\",\n",
    "        \"32th\":\"blue\",\n",
    "        \"64th\":\"purple\",\n",
    "    },\n",
    "    \"linestyle\":{\n",
    "        \"noselfnoise\":\"--\",\n",
    "        \"selfnoise\":\"-\"\n",
    "    },\n",
    "    \"linewidth\":{\n",
    "        \"nonoise\":5,\n",
    "        \"zerosum\":1,\n",
    "    }\n",
    "}\n",
    "\n",
    "zerosum_experiments = utils.filter_attribute(experiments_attributes,zerosum_attributes)\n",
    "for experiment in sorted(zerosum_experiments):\n",
    "    print(experiment)\n",
    "\n",
    "utils.plot_all_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    experiments_attributes,\n",
    "    display_attributes,\n",
    "    \"roc_auc mean\",\n",
    "    save_directory=save_directory,\n",
    "    figsize= (10,10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results vs Muffliato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "zerosum_attributes = {\"variant\":[\"nonoise\",\"zerosum\",\"muffliato\"],\"topology_type\":[\"static\"],\"avgsteps\": [None,\"10avgsteps\"], \"additional_attribute\": [None,\"selfnoise\"]}\n",
    "\n",
    "display_attributes ={\n",
    "    \"color\":{\n",
    "        \"nonoise\":\"cyan\",\n",
    "        \"2th\":\"red\",\n",
    "        \"4th\":\"orange\",\n",
    "        \"8th\": \"yellow\",\n",
    "        \"16th\":\"green\",\n",
    "        \"32th\":\"blue\",\n",
    "        \"64th\":\"purple\",\n",
    "    },\n",
    "    \"linestyle\":{\n",
    "        \"muffliato\":\"--\",\n",
    "        \"zerosum\":\"-\"\n",
    "    },\n",
    "    \"linewidth\":{\n",
    "        \"nonoise\":5,\n",
    "        \"zerosum\":1,\n",
    "    }\n",
    "}\n",
    "\n",
    "zerosum_experiments = utils.filter_attribute(experiments_attributes,zerosum_attributes)\n",
    "for experiment in sorted(zerosum_experiments):\n",
    "    print(experiment)\n",
    "\n",
    "utils.plot_all_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    experiments_attributes,\n",
    "    display_attributes,\n",
    "    \"roc_auc mean\",\n",
    "    save_directory=save_directory,\n",
    "    figsize=(10,10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "zerosum_attributes = {\"variant\":[\"nonoise\",\"zerosum\",\"muffliato\"],\"topology_type\":[\"dynamic\"],\"avgsteps\": [None,\"10avgsteps\"], \"additional_attribute\": [None,\"selfnoise\"]}\n",
    "\n",
    "display_attributes ={\n",
    "    \"color\":{\n",
    "        \"nonoise\":\"cyan\",\n",
    "        \"2th\":\"red\",\n",
    "        \"4th\":\"orange\",\n",
    "        \"8th\": \"yellow\",\n",
    "        \"16th\":\"green\",\n",
    "        \"32th\":\"blue\",\n",
    "        \"64th\":\"purple\",\n",
    "    },\n",
    "    \"linestyle\":{\n",
    "        \"muffliato\":\"--\",\n",
    "        \"zerosum\":\"-\"\n",
    "    },\n",
    "    \"linewidth\":{\n",
    "        \"nonoise\":5,\n",
    "        \"zerosum\":1,\n",
    "    }\n",
    "}\n",
    "\n",
    "zerosum_experiments = utils.filter_attribute(experiments_attributes,zerosum_attributes)\n",
    "for experiment in sorted(zerosum_experiments):\n",
    "    print(experiment)\n",
    "\n",
    "utils.plot_all_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    experiments_attributes,\n",
    "    display_attributes,\n",
    "    \"roc_auc mean\",\n",
    "    save_directory=save_directory,\n",
    "    figsize=(10,10)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
