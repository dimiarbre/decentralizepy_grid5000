{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data refactoring\n",
    "\n",
    "The aim of this script is to recompile the entire data in a single CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "sorted(os.listdir(\"my_results/128nodes_avgsteps\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_dir = { \n",
    "#     \"No_noise_static\" : \"my_results/128nodes/1954546_128nodes_static_unnoised_mia\",\n",
    "#     \"No_noise_dynamic\" : \"my_results/128nodes/1956015_128nodes_dynamic_unnoised_mia\",\n",
    "\n",
    "#     \"Gaussian64_static\": \"my_results/128nodes/1954571_128nodes_static_gaussian_64th\",\n",
    "#     \"Gaussian64_dynamic\" : \"my_results/128nodes/1955830_128nodes_dynamic_gaussian_64th\",\n",
    "#     \"Gaussian32_static\": \"my_results/128nodes/1954562_128nodes_static_gaussian_32th\",\n",
    "#     \"Gaussian32_dynamic\" : \"my_results/128nodes/1955812_128nodes_dynamic_gaussian_32th\",\n",
    "#     \"Gaussian16_static\" : \"my_results/128nodes/1954554_128nodes_static_gaussian_niidattacks_16th\",\n",
    "#     \"Gaussian16_dynamic\" : \"my_results/128nodes/1955617_128nodes_dynamic_gaussian_16th\",\n",
    "#     \"Gaussian8_static\": \"my_results/128nodes/1954558_128nodes_static_gaussian_8th\",\n",
    "#     \"Gaussian8_dynamic\": \"my_results/128nodes/1955680_128nodes_dynamic_gaussian_8th\",\n",
    "#     \"Gaussian4_static\": \"my_results/128nodes/1954577_128nodes_static_gaussian_4th\",\n",
    "#     \"Gaussian4_dynamic\" : \"my_results/128nodes/1955991_128nodes_dynamic_gaussian_4th\",\n",
    "#     \"Gaussian2_static\": \"my_results/128nodes/1954582_128nodes_static_gaussian_2th\",\n",
    "#     \"Gaussian2_dynamic\" : \"my_results/128nodes/1955994_128nodes_dynamic_gaussian_2th\",\n",
    "\n",
    "#     \"ZeroSum64_static\": \"my_results/128nodes/1954570_128nodes_static_zerosum_64th\" ,\n",
    "#     \"ZeroSum64_dynamic\" : \"my_results/128nodes/1955816_128nodes_dynamic_zerosum_64th\",\n",
    "#     \"ZeroSum32_static\":\"my_results/128nodes/1954567_128nodes_static_zerosum_32th\" ,\n",
    "#     \"ZeroSum32_dynamic\" : \"my_results/128nodes/1955813_128nodes_dynamic_zerosum_32th\",\n",
    "#     \"ZeroSum16_static\": \"my_results/128nodes/1954548_128nodes_static_zerosum_niidattacks_16th\",\n",
    "#     \"ZeroSum16_dynamic\" : \"my_results/128nodes/1955618_128nodes_dynamic_zerosum_16th\",\n",
    "#     \"ZeroSum8_static\": \"my_results/128nodes/1954559_128nodes_static_zerosum_8th\",\n",
    "#     \"ZeroSum8_dynamic\" : \"my_results/128nodes/1955810_128nodes_dynamic_zerosum_8th\",\n",
    "#     \"ZeroSum4_static\": \"my_results/128nodes/1954578_128nodes_static_zerosum_4th\",\n",
    "#     \"ZeroSum4_dynamic\" : \"my_results/128nodes/1955838_128nodes_dynamic_zerosum_4th\",\n",
    "#     \"ZeroSum2_static\": \"my_results/128nodes/1954581_128nodes_static_zerosum_2th\",\n",
    "#     \"ZeroSum2_dynamic\" : \"my_results/128nodes/1955995_128nodes_dynamic_zerosum_2th\",\n",
    "\n",
    "   \n",
    "#     \"Muffliato64_static\": \"my_results/128nodes/1954568_128nodes_static_muffliato_64th\",\n",
    "#     \"Muffliato64_dynamic\" : \"my_results/128nodes/1955814_128nodes_dynamic_muffliato_64th\",\n",
    "#     \"Muffliato32_static\": \"my_results/128nodes/1954561_128nodes_static_muffliato_32th\",\n",
    "#     \"Muffliato32_dynamic\" : \"my_results/128nodes/1955811_128nodes_dynamic_muffliato_32th\",\n",
    "#     \"Muffliato16_static\" : \"my_results/128nodes/1954552_128nodes_static_muffliato_niidattacks_16th\",\n",
    "#     \"Muffliato16_dynamic\" : \"my_results/128nodes/1955616_128nodes_dynamic_muffliato_16th\",\n",
    "#     \"Muffliato8_static\": \"my_results/128nodes/1954557_128nodes_static_muffliato_8th\",\n",
    "#     \"Muffliato8_dynamic\": \"my_results/128nodes/1955681_128nodes_dynamic_muffliato_8th\",\n",
    "#     \"Muffliato4_static\": \"my_results/128nodes/1954576_128nodes_static_muffliato_4th\",\n",
    "#     \"Muffliato4_dynamic\" : \"my_results/128nodes/1955990_128nodes_dynamic_muffliato_4th\",\n",
    "#     \"Muffliato2_static\": \"my_results/128nodes/1954579_128nodes_static_muffliato_2th\",\n",
    "#     \"Muffliato2_dynamic\" : \"my_results/128nodes/1955993_128nodes_dynamic_muffliato_2th\",\n",
    "# }\n",
    "# folder_name = \"formatted_results/128nodes\"\n",
    "\n",
    "# target_dir = { \n",
    "#     \"No_noise_static\" : \"my_results/128nodes/1954546_128nodes_static_unnoised_mia\",\n",
    "    \n",
    "#     \"ZeroSum16_static\": \"my_results/128nodes/1954548_128nodes_static_zerosum_niidattacks_16th\",\n",
    "#     \"ZeroSum4_static\": \"my_results/128nodes/1954578_128nodes_static_zerosum_4th\",\n",
    "    \n",
    "#     \"Muffliato16_static_1steps\" : \"my_results/128nodes_avgsteps/1956392_128nodes_static_muffliato_16th_1step/\",\n",
    "#     \"Muffliato16_static_2steps\" : \"my_results/128nodes_avgsteps/1956391_128nodes_static_muffliato_16th_2steps/\",\n",
    "#     \"Muffliato16_static_3steps\" : \"my_results/128nodes_avgsteps/1956422_128nodes_static_muffliato_16th_3steps/\",\n",
    "#     \"Muffliato16_static_5steps\" : \"my_results/128nodes_avgsteps/1956393_128nodes_static_muffliato_16th_5steps/\",\n",
    "#     \"Muffliato16_static_10steps\" : \"my_results/128nodes_avgsteps/1956390_128nodes_static_muffliato_16th_10steps/\",\n",
    "#     \"Muffliato16_static_20steps\" : \"my_results/128nodes_avgsteps/1956394_128nodes_static_muffliato_16th_20steps/\",\n",
    "\n",
    "#     \"Muffliato4_static_1steps\" : 'my_results/128nodes_avgsteps/1957667_128nodes_static_muffliato_4th_1steps',\n",
    "#     \"Muffliato4_static_10steps\" : \"my_results/128nodes_avgsteps/1957621_128nodes_static_muffliato_4th_10steps/\",\n",
    "#     \"Muffliato4_static_20steps\" : \"my_results/128nodes_avgsteps/1957620_128nodes_static_muffliato_4th_20steps/\",\n",
    "\n",
    "#     \"Muffliato2_static_10steps\" : 'my_results/128nodes_avgsteps/1957672_128nodes_static_muffliato_2th_10steps',\n",
    "#     \"Muffliato8_static_10steps\" : 'my_results/128nodes_avgsteps/1957673_128nodes_static_muffliato_8th_10steps',\n",
    "#     \"Muffliato32_static_10steps\" : 'my_results/128nodes_avgsteps/1957674_128nodes_static_muffliato_32th_10steps',\n",
    "#     \"Muffliato64_static_10steps\" : 'my_results/128nodes_avgsteps/1957675_128nodes_static_muffliato_64th_10steps',\n",
    "\n",
    "#     \"Muffliato2_dynamic_10steps\": 'my_results/128nodes_avgsteps/1957689_128nodes_dynamic_muffliato_2th_10steps',\n",
    "#     \"Muffliato4_dynamic_10steps\":'my_results/128nodes_avgsteps/1957690_128nodes_dynamic_muffliato_4th_10steps',\n",
    "#     \"Muffliato8_dynamic_10steps\":'my_results/128nodes_avgsteps/1957691_128nodes_dynamic_muffliato_8th_10steps',\n",
    "#     \"Muffliato16_dynamic_10steps\":'my_results/128nodes_avgsteps/1957837_128nodes_dynamic_muffliato_16th_10steps',\n",
    "#     \"Muffliato32_dynamic_10steps\":'my_results/128nodes_avgsteps/1957838_128nodes_dynamic_muffliato_32th_10steps',\n",
    "#     \"Muffliato64_dynamic_10steps\":'my_results/128nodes_avgsteps/1957839_128nodes_dynamic_muffliato_64th_10steps',\n",
    "# }\n",
    "# folder_name = \"formatted_results/averaging_steps\"\n",
    "\n",
    "target_dir = { \n",
    "    \"No_noise_static\" : \"my_results/femnist/128nodes_CNN/1958090_femnist_128nodes_static_unnoised_mia_CNN/\",\n",
    "    \n",
    "    \"Muffliato64_static_10steps\": \"my_results/femnist/128nodes_CNN/1958100_femnist_128nodes_static_muffliato_64th_10steps_CNN/\",\n",
    "    # \"Muffliato64_dynamic_10steps\" : \"my_results/femnist/128nodes_CNN/\",\n",
    "    \"Muffliato32_static_10steps\": \"my_results/femnist/128nodes_CNN/1958138_femnist_128nodes_static_muffliato_32th_10steps_CNN/\",\n",
    "    # \"Muffliato32_dynamic_10steps\" : \"my_results/femnist/128nodes_CNN/\",\n",
    "    \"Muffliato16_static_10steps\" : \"my_results/femnist/128nodes_CNN/1958137_femnist_128nodes_static_muffliato_16th_10steps_CNN/\",\n",
    "    # \"Muffliato16_dynamic_10steps\" : \"my_results/femnist/128nodes_CNN/\",\n",
    "    \"Muffliato8_static_10steps\": \"my_results/femnist/128nodes_CNN/1958136_femnist_128nodes_static_muffliato_8th_10steps_CNN/\",\n",
    "    # \"Muffliato8_dynamic_10steps\": \"my_results/femnist/128nodes_CNN/\",\n",
    "    \"Muffliato4_static_10steps\": \"my_results/femnist/128nodes_CNN/1958139_femnist_128nodes_static_muffliato_4th_10steps_CNN/\",\n",
    "    # \"Muffliato4_dynamic_10steps\" : \"my_results/femnist/128nodes_CNN/\",\n",
    "    \"Muffliato2_static_10steps\": \"my_results/femnist/128nodes_CNN/1958141_femnist_128nodes_static_muffliato_2th_10steps_CNN/\",\n",
    "    # \"Muffliato2_dynamic_10steps\" : \"my_results/femnist/128nodes_CNN/\",\n",
    "\n",
    "    \"ZeroSum64_static\": \"my_results/femnist/128nodes_CNN/1958101_femnist_128nodes_static_zerosum_64th_CNN/\" ,\n",
    "    # \"ZeroSum64_dynamic\" : \"my_results/femnist/128nodes_CNN/\",\n",
    "    \"ZeroSum32_static\":\"my_results/femnist/128nodes_CNN/1958096_femnist_128nodes_static_zerosum_32th_CNN/\" ,\n",
    "    # \"ZeroSum32_dynamic\" : \"my_results/femnist/128nodes_CNN/\",\n",
    "    \"ZeroSum16_static\": \"my_results/femnist/128nodes_CNN/1958094_femnist_128nodes_static_zerosum_16th_CNN/\",\n",
    "    # \"ZeroSum16_dynamic\" : \"my_results/femnist/128nodes_CNN/\",\n",
    "    \"ZeroSum8_static\": \"my_results/femnist/128nodes_CNN/1958092_femnist_128nodes_static_zerosum_8th_CNN/\",\n",
    "    # \"ZeroSum8_dynamic\" : \"my_results/femnist/128nodes_CNN/\",\n",
    "    \"ZeroSum4_static\": \"my_results/femnist/128nodes_CNN/1958140_femnist_128nodes_static_zerosum_4th_CNN/\",\n",
    "    # \"ZeroSum4_dynamic\" : \"my_results/femnist/128nodes_CNN/\",\n",
    "    \"ZeroSum2_static\": \"my_results/femnist/128nodes_CNN/1958142_femnist_128nodes_static_zerosum_2th_CNN/\",\n",
    "    # \"ZeroSum2_dynamic\" : \"my_results/femnist/128nodes_CNN/\",   \n",
    "}\n",
    "folder_name = \"formatted_results/femnist/128nodes_CNN\"\n",
    "\n",
    "TOTAL_PROCESSES = 128\n",
    "MAX_MACHINES =  8\n",
    "STARTING_ITERATION = 0\n",
    "MAX_ITERATIONS=4000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import nansum\n",
    "from numpy import nanmean\n",
    "from numpy import sqrt\n",
    "\n",
    "import os\n",
    "import threading\n",
    "import concurrent.futures\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "assert TOTAL_PROCESSES%MAX_MACHINES == 0\n",
    "MAX_PROCESSES = TOTAL_PROCESSES//MAX_MACHINES\n",
    "\n",
    "machine_folder = 'machine{}'\n",
    "result_file = '{}_results.json'\n",
    "\n",
    "\n",
    "\n",
    "def load_data(dir):\n",
    "    data = pd.DataFrame({})\n",
    "    for machine in range(MAX_MACHINES):\n",
    "        for rank in range(MAX_PROCESSES):\n",
    "            # print(f\"Loading results for machine {machine} and rank {rank}.  \",end = \"\\r\")\n",
    "            uid = rank + machine * MAX_PROCESSES\n",
    "\n",
    "            file = os.path.join(dir, machine_folder.format(machine), result_file.format(rank))\n",
    "            tmp_df = pd.read_json(file)\n",
    "            tmp_df[\"uid\"] = uid # Manually add the uid for further processing                                                                   \n",
    "            tmp_df[\"iteration\"] = tmp_df.index\n",
    "            # print(tmp_df)\n",
    "            tmp_df = tmp_df[tmp_df[\"iteration\"]>=STARTING_ITERATION]\n",
    "            tmp_df = tmp_df[tmp_df[\"iteration\"]<=MAX_ITERATIONS]\n",
    "            data = pd.concat([data,tmp_df])\n",
    "    return data\n",
    "    \n",
    "# Load the data\n",
    "# data_dict = {}\n",
    "# for (key, dir) in target_dir.items():\n",
    "#     print(f\"Loading results for run {key} at folder {dir}.  \")\n",
    "#     data_dict[key] = load_data(dir)\n",
    "# print(\"Loading finished!\" + \" \"*40)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load privacy data as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCATIONS_OF_ATTACKS = [\"PRE-STEP\",\"PRE-STEP-niid\"]\n",
    "\n",
    "\n",
    "\n",
    "assert TOTAL_PROCESSES%MAX_MACHINES == 0\n",
    "MAX_PROCESSES = TOTAL_PROCESSES//MAX_MACHINES\n",
    "\n",
    "machine_folder = 'machine{}'\n",
    "privacy_folder = 'privacy'\n",
    "summary_folder = 'summary'\n",
    "process_folder = '{}'\n",
    "\n",
    "def load_privacy_data(path_dir):\n",
    "    data = {}\n",
    "    for loc in LOCATIONS_OF_ATTACKS:\n",
    "        location = f\"privacy-summary-{loc}.json\"\n",
    "        data[loc] = pd.DataFrame({})  \n",
    "        for machine in range(MAX_MACHINES):\n",
    "            for rank in range(MAX_PROCESSES):\n",
    "                # print(f\"Loading {location} for machine {machine} and rank {rank}  \",end = \"\\r\")\n",
    "                file = os.path.join(path_dir, machine_folder.format(machine),privacy_folder, summary_folder, process_folder.format(machine*MAX_PROCESSES+rank), location)\n",
    "                tmp_df = pd.read_json(file)\n",
    "                tmp_df = tmp_df[tmp_df.iteration <= MAX_ITERATIONS]\n",
    "                tmp_df = tmp_df[tmp_df.iteration >= STARTING_ITERATION]\n",
    "                #tmp_df['location_of_attack']= file.split('.')[0]\n",
    "                data[loc] = pd.concat([data[loc],tmp_df])\n",
    "    return data\n",
    "\n",
    "# privacy_data_dict = {}\n",
    "# for key,dir in target_dir.items():\n",
    "#     print(f\"Loading privacy data for {key} at \\\"{dir}\\\"\")\n",
    "#     privacy_data_dict[key] = load_privacy_data(dir)\n",
    "# print(\"Loading finished!\" + \" \"*40)\n",
    "\n",
    "# data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['iteration','test_acc',\"total_bytes\", 'test_niid_acc']\n",
    "agg_methods = [\"mean\", \"std\", \"sum\"]\n",
    "privacy_columns = ['iteration', 'Attacker advantage']\n",
    "confidence = [\"test_acc\", \"test_niid_acc\"]\n",
    "\n",
    "def format_data(key,dir):\n",
    "    filename = f\"{key}.csv\"\n",
    "    output_path = f\"{folder_name}/{filename}\"\n",
    "    if filename in os.listdir(folder_name):\n",
    "        print(f\"Data for {key} already formatted!\")\n",
    "        return\n",
    "    print(f\"Started formatting data for {key}\" + \" \" *40)\n",
    "    gen_data = load_data(dir)\n",
    "    usable_data = gen_data[columns].dropna()\n",
    "    \n",
    "    usable_data = usable_data.groupby('iteration').agg(agg_methods)\n",
    "    usable_data.reset_index(inplace=True)\n",
    "\n",
    "    usable_data.insert(1,\"experience_name\",key)\n",
    "    usable_data.insert(2,\"number_agents\",TOTAL_PROCESSES)\n",
    "\n",
    "    usable_data.columns = [' '.join(e) if len(e[-1])>0 else e[0] for e in usable_data.columns]\n",
    "\n",
    "    usable_data.set_index(\"iteration\",inplace=True)\n",
    "\n",
    "    privacy_data = load_privacy_data(dir)\n",
    "    for loc in LOCATIONS_OF_ATTACKS:\n",
    "        privacy_data_loc = privacy_data[loc]\n",
    "\n",
    "        privacy_data_loc = privacy_data_loc[privacy_data_loc[\"slice feature\"] == \"Entire dataset\"]\n",
    "        averaged = privacy_data_loc[privacy_columns].groupby('iteration').agg([\"mean\"])\n",
    "        averaged.columns = list(map(' '.join, averaged.columns.values))\n",
    "        averaged.reset_index(inplace=True)\n",
    "        \n",
    "        # averaged.drop(1,axis=1)\n",
    "        # print(averaged[\"Attacker advantage\"])\n",
    "        averaged.rename(columns = {('Attacker advantage mean'): f\"Attacker advantage mean {loc}\"}, errors=\"raise\", inplace=True)\n",
    "        # print(usable_data)\n",
    "        # print(privacy_data_loc)\n",
    "        # privacy_data \n",
    "        averaged.set_index(\"iteration\",inplace=True)\n",
    "\n",
    "        # print(usable_data)\n",
    "        # print(averaged)\n",
    "        usable_data = usable_data.join(averaged, on = 'iteration')\n",
    "        # print(\"Joined:\")\n",
    "        # print(usable_data)\n",
    "\n",
    "    # print(usable_data)\n",
    "\n",
    "    # Compute confidence intervals\n",
    "    for metric in confidence:\n",
    "        lower_interval = usable_data[f\"{metric} mean\"] - 1.96 * usable_data[f\"{metric} std\"] / np.sqrt(TOTAL_PROCESSES)\n",
    "        upper_interval = usable_data[f\"{metric} mean\"] + 1.96 * usable_data[f\"{metric} std\"] / np.sqrt(TOTAL_PROCESSES)\n",
    "        usable_data[f\"{metric} lower confidence\"] = lower_interval\n",
    "        usable_data[f\"{metric} upper confidence\"] = upper_interval\n",
    "\n",
    "    # Save the formatted result \n",
    "    usable_data.to_csv(output_path)\n",
    "    print(f\"Formatted data for {key} at {output_path}\" + \" \" *40)\n",
    "    return\n",
    "\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    for key,dir in target_dir.items():\n",
    "        executor.submit(format_data,key,dir)\n",
    "        # format_data(key,dir)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Finished formatting all data\" + \" \"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
