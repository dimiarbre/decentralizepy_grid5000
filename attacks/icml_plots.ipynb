{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys, os\n",
    "import matplotlib.pyplot as plt\n",
    "import concurrent.futures\n",
    "import importlib\n",
    "import seaborn as sns\n",
    "import scienceplots\n",
    "import plot_loaders\n",
    "import plot_utils\n",
    "\n",
    "plt.style.use([\"science\",\"ieee\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORDERINGS = {\n",
    "    \"noise_level\": [\n",
    "        x[0] for x in sorted(plot_loaders.NOISES_MAPPING.items(), key=lambda x: x[1])\n",
    "    ][::1],\n",
    "    \"variant\": [\"nonoise\", \"zerosum\", \"muffliato\"],\n",
    "    \"avgsteps\": [i for i in range(20)][::1],\n",
    "    \"topology_type\": [\"static\", \"dynamic\"],\n",
    "    \"additional_attribute\": [\"nonoise\", \"muffliato\",\"selfnoise\",\"noselfnoise\"]\n",
    "}\n",
    "print(ORDERINGS)\n",
    "\n",
    "# CIFAR Additional runs with seeds:\n",
    "# target_dir = \"my_results/icml_experiments/additional_cifar10_v2/\"\n",
    "# ORDERINGS = {\n",
    "#     \"noise_level\" : [\"nonoise\",\"4th\",\"64th\"],\n",
    "#     \"variant\":[\"nonoise\",\"zerosum\",\"muffliato\"],\n",
    "#     \"avgsteps\": [\"10\", \"1\"],\n",
    "#     \"topology_type\": [\"static\",\"dynamic\"],\n",
    "# }\n",
    "\n",
    "\n",
    "# Muffliato experiments on CIFAR with multiple avg steps\n",
    "# target_dir = \"my_results/icml_experiments/muffliato_avgsteps\"\n",
    "# ORDERINGS = {\n",
    "#     \"noise_level\" : [\"4th\",\"16th\",\"64th\"],\n",
    "#     \"variant\":[\"muffliato\",\"zerosum\"],\n",
    "#     \"avgsteps\": [\"20\", \"15\", \"10\",\"5\", \"1\"].reverse(),\n",
    "#     \"topology_type\": [\"static\",\"dynamic\"],\n",
    "# }\n",
    "\n",
    "\n",
    "# S&P Femnist experiments\n",
    "# target_dir = \"my_results/femnist_10shards_correctedrandomness/\"\n",
    "\n",
    "# MovieLens Experiments\n",
    "# target_dir = \"my_results/movielens_full/\"\n",
    "\n",
    "# Renewed CIFAR\n",
    "target_dir= \"my_results/cifar_longer/\"\n",
    "\n",
    "# Femnist full experiments\n",
    "# target_dir = \"my_results/femnistLabelSplit_10shards_renewed/\"\n",
    "\n",
    "# Muffliato with less averaging rounds\n",
    "# target_dir = \"my_results/cifar_muffliato_shorteravgrounds/\"\n",
    "\n",
    "linestyles = {\"ZeroSum\": \"--\"}\n",
    "\n",
    "fontsize = 20\n",
    "\n",
    "alpha = 0.1\n",
    "\n",
    "save_directory = \"assets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the file list\n",
    "experiments_dict = plot_loaders.get_full_path_dict(target_dir)\n",
    "experiments_attributes = plot_loaders.get_experiments_dict(experiments_dict)\n",
    "\n",
    "experiments_attributes_df = pd.DataFrame({})\n",
    "for experiment_name, experiment_attribute in sorted(experiments_attributes.items()):\n",
    "    print(experiment_name)\n",
    "    experiments_attributes_df = pd.concat(\n",
    "        [\n",
    "            experiments_attributes_df,\n",
    "            pd.DataFrame(experiment_attribute, index=[experiment_name]),\n",
    "        ]\n",
    "    )\n",
    "# print(experiments_attributes_df.columns)\n",
    "\n",
    "# print(experiments_attributes[\"4447548_muffliato_128nodes_10avgsteps_64th_dynamic_seed105\"])\n",
    "print(experiments_dict)\n",
    "# for seed in range(91,105):\n",
    "#     print(f\"Seed: {seed:3.0f}:\", end= \"\")\n",
    "#     current_seed = experiments_attributes_df[experiments_attributes_df[\"seed\"] == f\"seed{seed}\"]\n",
    "#     current_variants = list(current_seed[\"variant\"])\n",
    "#     current_topologies = list(current_seed[\"topology_type\"])\n",
    "#     print(sorted(list(zip(current_variants,current_topologies))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plot_loaders)\n",
    "loaded_data = {}\n",
    "\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=20) as executor:\n",
    "    futures = {}\n",
    "    for name, filepath in sorted(experiments_dict.items()):\n",
    "        # plot_loaders.load_data_element(filepath)\n",
    "        futures[name] = executor.submit(plot_loaders.load_data_element, filepath)\n",
    "    for name, result in futures.items():\n",
    "        print(f\"Adding data from {name}\")\n",
    "        res = result.result()\n",
    "        if res.empty:\n",
    "            print(f\"Empty result for {name}\")\n",
    "        loaded_data[name] = res\n",
    "# print(loaded_data)\n",
    "print(\"Finished loading all data\")\n",
    "for column in loaded_data[name]:\n",
    "    print(column)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agregate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load at once since we'll pop from the dict, this should sanitize the for loop.\n",
    "for experiment_name, experiment_data in list(loaded_data.items()):\n",
    "    if experiment_data.empty:\n",
    "        print(f\"Deleting {experiment_name} as it did not load\")\n",
    "        loaded_data.pop(experiment_name)\n",
    "        experiments_attributes.pop(experiment_name)\n",
    "\n",
    "\n",
    "importlib.reload(plot_loaders)\n",
    "# For most of the attacks\n",
    "general_agg_methods = [\n",
    "    \"mean\",\n",
    "    \"std\",\n",
    "    \"sum\",\n",
    "    \"min\",\n",
    "    \"max\",\n",
    "    plot_loaders.percentile(0.5),\n",
    "    plot_loaders.percentile(0.95),\n",
    "]\n",
    "columns_to_agg = [\n",
    "    \"train_loss\",\n",
    "    \"test_loss\",\n",
    "    \"test_acc\",\n",
    "    \"total_bytes\",\n",
    "    \"total_meta\",\n",
    "    \"total_data_per_n\",\n",
    "]\n",
    "\n",
    "# Comment from here if some results are not there.\n",
    "# columns_to_agg += [\n",
    "#     \"roc_auc\",\n",
    "#     \"roc_auc_balanced\",\n",
    "#     \"50auc-distance\",\n",
    "#     \"50auc-distance_balanced\",\n",
    "# ]\n",
    "columns_to_agg += [\n",
    "    \"classifier_roc_auc\",\n",
    "]\n",
    "columns_to_agg += [\n",
    "    f\"classifier_tpr_at_fpr{fpr}\" for fpr in [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "]\n",
    "\n",
    "linkability_aggregators = {\n",
    "    \"linkability_top1\": [plot_loaders.count_percentage_success],\n",
    "    \"linkability_top5\": [plot_loaders.count_percentage_success],\n",
    "    \"linkability_real_rank\": [\"median\", \"min\", \"max\"],\n",
    "}\n",
    "# Remember to comment this line if you want linkability results.\n",
    "linkability_aggregators = {}\n",
    "\n",
    "to_start_avg = []\n",
    "# to_start_avg = [\n",
    "#     \"roc_auc mean\",\n",
    "#     \"linkability_top1 count_percentage_success\",\n",
    "#     \"roc_auc max\",\n",
    "# ]\n",
    "general_aggregator = {column: general_agg_methods for column in columns_to_agg}\n",
    "\n",
    "general_aggregator.update(linkability_aggregators)\n",
    "\n",
    "formatted_data = {}\n",
    "for name, data in sorted(loaded_data.items()):\n",
    "    print(f\"Formatting {name}\")\n",
    "    current_res = plot_loaders.format_data(\n",
    "        data,\n",
    "        name,\n",
    "        columns_to_agg,\n",
    "        linkability_aggregators,\n",
    "        general_aggregator,\n",
    "        to_start_avg,\n",
    "    )\n",
    "    if current_res.empty:\n",
    "        print(f\"WARNING: Removed experiment {name}!!!!\")\n",
    "        experiments_attributes.pop(name)\n",
    "    else:\n",
    "        formatted_data[name] = current_res\n",
    "\n",
    "formatted_data[list(formatted_data)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([x for x in formatted_data[list(formatted_data)[0]].columns if \"classifier\" in x])\n",
    "formatted_data[list(formatted_data)[0]][\"communication_step\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plot_loaders)\n",
    "importlib.reload(plot_utils)\n",
    "static_filter = {\"topology_type\": [\"static\"]}\n",
    "dynamic_filter = {\"topology_type\": [\"dynamic\"]}\n",
    "\n",
    "noisy_filter = {\"variant\": [\"muffliato\", \"zerosum\"]}\n",
    "\n",
    "static_experiments = plot_loaders.filter_attribute(\n",
    "    experiments_attributes, static_filter\n",
    ")\n",
    "dynamic_experiments = plot_loaders.filter_attribute(\n",
    "    experiments_attributes, dynamic_filter\n",
    ")\n",
    "\n",
    "nonoise_experiments = plot_loaders.filter_attribute(\n",
    "    experiments_attributes, {\"variant\": [\"nonoise\"]}\n",
    ")\n",
    "\n",
    "noisy_experiments = plot_loaders.filter_attribute(\n",
    "    experiments_attributes, {\"variant\": [\"muffliato\", \"zerosum\"]}\n",
    ")\n",
    "\n",
    "\n",
    "# To display full experiments\n",
    "display_attributes = {\n",
    "    \"hue\": \"noise_level\",\n",
    "    \"style\":[\"variant\",\"avgsteps\"],\n",
    "    \"col\" : \"topology_type\",\n",
    "}\n",
    "\n",
    "# To display experiment parameters tuning.\n",
    "# display_attributes = {\n",
    "#     \"hue\": \"lr\",\n",
    "#     \"style\":\"local_rounds\",\n",
    "#     \"col\" : \"model\",\n",
    "# }\n",
    "\n",
    "# To display muffliato results\n",
    "# display_attributes = {\n",
    "#     \"hue\": \"avgsteps\",\n",
    "#     \"style\": \"variant\",\n",
    "#     \"col\": \"noise_level\",\n",
    "# }\n",
    "\n",
    "\n",
    "for experiment in experiments_attributes:\n",
    "    print(experiment)\n",
    "    # print(formatted_data[experiment])\n",
    "\n",
    "\n",
    "\n",
    "for y_axis, title in [\n",
    "    (\"train_loss mean\", \"All experiments train losses evolution\"),\n",
    "    (\"test_acc mean\", \"All experiments accuracies evolution\"),\n",
    "]:\n",
    "    plot = plot_utils.plot_all_experiments(\n",
    "        data=formatted_data,\n",
    "        experiments=noisy_experiments,\n",
    "        display_attributes=display_attributes,\n",
    "        plot_name=title,\n",
    "        column_name=y_axis,\n",
    "        x_axis=\"iteration\",\n",
    "        save_directory=save_directory,\n",
    "        orderings = ORDERINGS,\n",
    "        baseline={nonoise_experiments[0]:formatted_data[nonoise_experiments[0]]},\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing the same plot, but with communication steps instead of iterations (and thus gradient descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plot_utils)\n",
    "for y_axis, title in [\n",
    "    (\"train_loss mean\", \"All experiments train losses evolution - communication steps\"),\n",
    "    (\"test_acc mean\", \"All experiments accuracies evolution - communication steps\"),\n",
    "]:\n",
    "    plot = plot_utils.plot_all_experiments(\n",
    "        data=formatted_data,\n",
    "        experiments=experiments_attributes,\n",
    "        display_attributes=display_attributes,\n",
    "        plot_name=title,\n",
    "        column_name=y_axis,\n",
    "        x_axis=\"communication_step\",\n",
    "        save_directory=save_directory,\n",
    "        baseline={nonoise_experiments[0]:formatted_data[nonoise_experiments[0]]},\n",
    "        orderings = ORDERINGS,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attack results\n",
    "## In the static case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plot_utils)\n",
    "zerosum_attributes = {\"variant\":[\"nonoise\",\"zerosum\"]}\n",
    "# zerosum_attributes = {\"variant\":[\"nonoise\",\"zerosum\"],\"topology_type\":[\"static\"]}\n",
    "# zerosum_attributes = {\"variant\":[\"nonoise\",\"zerosum\"],\"topology_type\":[\"dynamic\"]}\n",
    "\n",
    "display_attributes = {\n",
    "    \"hue\":\"noise_level\",\n",
    "    \"style\": \"additional_attribute\",\n",
    "    \"size\": \"variant\",\n",
    "    \"col\": \"topology_type\",\n",
    "}\n",
    "\n",
    "zerosum_experiments = plot_loaders.filter_attribute(experiments_attributes,zerosum_attributes)\n",
    "for experiment in sorted(zerosum_experiments):\n",
    "    print(experiment)\n",
    "\n",
    "plot_utils.plot_all_experiments(\n",
    "    data=formatted_data,\n",
    "    experiments=zerosum_experiments,\n",
    "    display_attributes=display_attributes,\n",
    "    plot_name=\"Attack AUC of Zerosum with and without self noise\",\n",
    "    column_name=\"roc_auc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results vs Muffliato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plot_utils)\n",
    "\n",
    "zerosum_attributes = {\n",
    "    \"variant\":[\"zerosum\",\"nonoise\"],\n",
    "    # \"topology_type\":[\"static\"],\n",
    "    # \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"1avgsteps\"],\n",
    "    # \"avgsteps\": [\"1avgsteps\",\"10avgsteps\"],\n",
    "    \"additional_attribute\": [\"nonoise\",\"selfnoise\"]}\n",
    "muffliato_attributes = {\n",
    "    \"variant\":[\"muffliato\"],\n",
    "    # \"topology_type\":[\"static\"],\n",
    "    # \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\":[\"10avgsteps\"],\n",
    "}\n",
    "\n",
    "current_attributes= [zerosum_attributes,muffliato_attributes]\n",
    "\n",
    "# display_attributes = {\n",
    "#     \"hue\":\"noise_level\",\n",
    "#     \"style\":\"variant\",\n",
    "#     # \"size\":\"variant\", # For some reason having both style and size breaks in this case.\n",
    "#     \"col\":\"topology_type\",\n",
    "# }\n",
    "\n",
    "display_attributes = {\n",
    "    \"hue\":[\"noise_level\", \"variant\"],\n",
    "    \"style\":[\"noise_level\", \"variant\"],\n",
    "    # \"size\":\"variant\", # For some reason having both style and size breaks in this case.\n",
    "    \"col\":\"topology_type\",\n",
    "}\n",
    "\n",
    "zerosum_experiments = plot_loaders.filter_attribute_list(experiments_attributes,current_attributes)\n",
    "for experiment in sorted(zerosum_experiments):\n",
    "    print(experiment)\n",
    "\n",
    "\n",
    "plot_utils.plot_all_experiments(\n",
    "    data=formatted_data,\n",
    "    experiments=zerosum_experiments,\n",
    "    display_attributes=display_attributes,\n",
    "    plot_name=\"Accuracy of Zerosum and Muffliato\",\n",
    "    column_name=\"test_acc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "plot_utils.plot_all_experiments(\n",
    "    data=formatted_data,\n",
    "    experiments=zerosum_experiments,\n",
    "    display_attributes=display_attributes,\n",
    "    plot_name=\"Attack AUC of Zerosum and Muffliato\",\n",
    "    column_name=\"roc_auc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smaller plots to have an easier time to read the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plot_utils)\n",
    "zerosum_attributes = {\n",
    "    \"variant\":[\"nonoise\",\"zerosum\"],\n",
    "    # \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"1avgsteps\"], \n",
    "    \"additional_attribute\": [\"nonoise\",\"selfnoise\"],\n",
    "    \"noise_level\":[\"nonoise\",\"1th\",\"2th\",\"4th\"]\n",
    "}\n",
    "\n",
    "muffliato_attributes = {\n",
    "    \"variant\":[\"muffliato\"],\n",
    "    # \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"10avgsteps\"], \n",
    "    \"noise_level\":[\"1th\",\"2th\",\"4th\"]\n",
    "}\n",
    "current_attributes= [zerosum_attributes,muffliato_attributes]\n",
    "\n",
    "\n",
    "# display_attributes = {\n",
    "#     \"hue\":\"noise_level\",\n",
    "#     \"style\":\"variant\",\n",
    "#     # \"size\":\"variant\", # For some reason having both style and size breaks in this case.\n",
    "#     \"col\":\"topology_type\",\n",
    "# }\n",
    "\n",
    "display_attributes = {\n",
    "    \"hue\":[\"noise_level\", \"variant\"],\n",
    "    \"style\":[\"noise_level\", \"variant\"],\n",
    "    # \"size\":\"variant\", # For some reason having both style and size breaks in this case.\n",
    "    \"col\":\"topology_type\",\n",
    "}\n",
    "\n",
    "zerosum_experiments = plot_loaders.filter_attribute_list(experiments_attributes,current_attributes)\n",
    "for experiment in sorted(zerosum_experiments):\n",
    "    print(experiment)\n",
    "\n",
    "\n",
    "\n",
    "plot_utils.plot_all_experiments(\n",
    "    data=formatted_data,\n",
    "    experiments=zerosum_experiments,\n",
    "    display_attributes=display_attributes,\n",
    "    plot_name=\"High noise:Accuracy of Zerosum and Muffliato with and without self noise\",\n",
    "    column_name=\"test_acc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plot_utils.plot_all_experiments(\n",
    "    data=formatted_data,\n",
    "    experiments=zerosum_experiments,\n",
    "    display_attributes=display_attributes,\n",
    "    plot_name=\"High noise:Attack AUC of Zerosum and Muffliato with and without self noise\",\n",
    "    column_name=\"roc_auc max\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")\n",
    "plt.ylim(top=1)\n",
    "\n",
    "# Plot the middle noises\n",
    "importlib.reload(plot_utils)\n",
    "zerosum_attributes = {\n",
    "    \"variant\":[\"nonoise\",\"zerosum\"],\n",
    "    # \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"1avgsteps\"], \n",
    "    \"additional_attribute\": [\"nonoise\",\"selfnoise\"],\n",
    "    \"noise_level\":[\"nonoise\",\"8th\",\"16th\"]\n",
    "}\n",
    "\n",
    "muffliato_attributes = {\n",
    "    \"variant\":[\"muffliato\"],\n",
    "    # \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"10avgsteps\"], \n",
    "    \"noise_level\":[\"8th\",\"16th\"]\n",
    "}\n",
    "current_attributes= [zerosum_attributes,muffliato_attributes]\n",
    "zerosum_experiments = plot_loaders.filter_attribute_list(experiments_attributes,current_attributes)\n",
    "\n",
    "plt.figure()\n",
    "plot_utils.plot_all_experiments(\n",
    "    data=formatted_data,\n",
    "    experiments=zerosum_experiments,\n",
    "    display_attributes=display_attributes,\n",
    "    plot_name=\"Middle noise:Accuracy of Zerosum and Muffliato with and without self noise\",\n",
    "    column_name=\"test_acc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "plot_utils.plot_all_experiments(\n",
    "    data=formatted_data,\n",
    "    experiments=zerosum_experiments,\n",
    "    display_attributes=display_attributes,\n",
    "    plot_name=\"Middle noise:Attack AUC of Zerosum and Muffliato with and without self noise\",\n",
    "    column_name=\"roc_auc max\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")\n",
    "plt.ylim(top=1)\n",
    "\n",
    "# Plot the low noises\n",
    "importlib.reload(plot_utils)\n",
    "zerosum_attributes = {\n",
    "    \"variant\":[\"nonoise\",\"zerosum\"],\n",
    "    # \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"1avgsteps\"], \n",
    "    \"additional_attribute\": [\"nonoise\",\"selfnoise\"],\n",
    "    \"noise_level\":[\"nonoise\",\"32th\",\"64th\",\"128th\"]\n",
    "}\n",
    "\n",
    "muffliato_attributes = {\n",
    "    \"variant\":[\"muffliato\"],\n",
    "    # \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"10avgsteps\"], \n",
    "    \"noise_level\":[\"32th\",\"64th\",\"128th\"]\n",
    "}\n",
    "current_attributes= [zerosum_attributes,muffliato_attributes]\n",
    "zerosum_experiments = plot_loaders.filter_attribute_list(experiments_attributes,current_attributes)\n",
    "\n",
    "plt.figure()\n",
    "plot_utils.plot_all_experiments(\n",
    "    data=formatted_data,\n",
    "    experiments=zerosum_experiments,\n",
    "    display_attributes=display_attributes,\n",
    "    plot_name=\"Low noise:Accuracy of Zerosum and Muffliato with and without self noise\",\n",
    "    column_name=\"test_acc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "plot_utils.plot_all_experiments(\n",
    "    data=formatted_data,\n",
    "    experiments=zerosum_experiments,\n",
    "    display_attributes=display_attributes,\n",
    "    plot_name=\"Low noise:Attack AUC of Zerosum and Muffliato with and without self noise\",\n",
    "    column_name=\"roc_auc max\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS\n",
    ")\n",
    "plt.ylim(top=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying out scatterplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregated plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = formatted_data[list(formatted_data)[0]]\n",
    "print(test_data.columns)\n",
    "test_data[[\"classifier_attacked_information\",\"classifier_attacker_model\",\"classifier_attacker_fraction\",\"classifier_attacker_dataset_mode\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plot_loaders)\n",
    "importlib.reload(plot_utils)\n",
    "# Aggregation of each experiments (across iterations)\n",
    "x_method = \"mean\"\n",
    "y_method = \"max\" # We often consider the maximum accuracy)\n",
    "# y_method = \"mean\"\n",
    "# y_method = \"min\"\n",
    "filter_classifier_result = [\"mid\",\"SimpleAttacker\",0.7,\"global\"]\n",
    "\n",
    "zerosum_attributes = {\n",
    "    \"variant\":[\"nonoise\",\"zerosum\"],\n",
    "    \"topology_type\":[\"static\"],\n",
    "    \"avgsteps\": [\"1avgsteps\"], \n",
    "    \"additional_attribute\": [\"nonoise\",\"selfnoise\"],\n",
    "}\n",
    "\n",
    "muffliato_attributes = {\n",
    "    \"variant\":[\"muffliato\"],\n",
    "    \"topology_type\":[\"static\"],\n",
    "    \"avgsteps\": [\"5avgsteps\"],\n",
    "}\n",
    "\n",
    "name_formater = {\n",
    "    \"test_acc mean max\":\"Maximum test accuracy [%]\",\n",
    "    \"nonoise\":\"test\"\n",
    "}\n",
    "\n",
    "\n",
    "current_attributes = [zerosum_attributes,muffliato_attributes]\n",
    "\n",
    "display_attributes = {\n",
    "    \"hue\":\"variant\",\n",
    "    \"style\":\"variant\",\n",
    "    \"size\":\"variant\", # For some reason having both style and size breaks in this case.\n",
    "    # \"col\":\"topology_type\",# Cannot have col argument for the lineplot function\n",
    "}\n",
    "zerosum_experiments = plot_loaders.filter_attribute_list(experiments_attributes,current_attributes)\n",
    "for experiment in sorted(zerosum_experiments):\n",
    "    print(experiment)\n",
    "\n",
    "\n",
    "# print([x for x in formatted_data[experiment].columns if \"test_acc\" in x])\n",
    "# plot_utils.scatter_averaged_experiments(\n",
    "#     formatted_data,\n",
    "#     zerosum_experiments,\n",
    "#     display_attributes,\n",
    "#     \"Accuracy vs AUC evolution accross entire runs-static topology\",\n",
    "#     \"test_acc mean\",\n",
    "#     # x_axis_name=\"50auc-distance mean\",\n",
    "#     x_axis_name=\"roc_auc mean\",\n",
    "#     save_directory=save_directory,\n",
    "#     y_method=y_method,\n",
    "#     x_method=x_method,\n",
    "#     orderings=ORDERINGS,\n",
    "#     name_formater=name_formater,\n",
    "# )\n",
    "\n",
    "# plt.figure()\n",
    "# plot_utils.scatter_averaged_experiments(\n",
    "#     formatted_data,\n",
    "#     zerosum_experiments,\n",
    "#     display_attributes,\n",
    "#     \"Accuracy vs Linkability attack for the entire run-static topology\",\n",
    "#     y_axis_name=\"test_loss mean\",\n",
    "#     x_axis_name=\"linkability_top1 count_percentage_success\",\n",
    "#     save_directory=save_directory,\n",
    "#     y_method=y_method,\n",
    "#     x_method=x_method,\n",
    "#     orderings=ORDERINGS,\n",
    "#     name_formater=name_formater,\n",
    "# )\n",
    "\n",
    "plt.figure()\n",
    "plot_utils.scatter_averaged_experiments(\n",
    "    plot_loaders.filter_classifier(formatted_data,*filter_classifier_result),\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    f\"Classifier attack for the entire run\\n {filter_classifier_result}\",\n",
    "    y_axis_name=\"test_acc mean\",\n",
    "    x_axis_name=\"classifier_roc_auc mean\",\n",
    "    save_directory=save_directory,\n",
    "    y_method=y_method,\n",
    "    x_method=x_method,\n",
    "    orderings=ORDERINGS,\n",
    "    name_formater=name_formater,\n",
    ")\n",
    "plt.figure()\n",
    "plot_utils.scatter_averaged_experiments(\n",
    "    plot_loaders.filter_classifier(formatted_data,*filter_classifier_result),\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    f\"Classifier attack for the entire run\\n {filter_classifier_result}\",\n",
    "    y_axis_name=\"test_acc mean\",\n",
    "    x_axis_name=\"classifier_tpr_at_fpr0.1 mean\",\n",
    "    save_directory=save_directory,\n",
    "    y_method=y_method,\n",
    "    x_method=x_method,\n",
    "    orderings=ORDERINGS,\n",
    "    name_formater=name_formater,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the dynamic case\n",
    "zerosum_attributes = {\n",
    "    \"variant\":[\"nonoise\",\"zerosum\"],\n",
    "    \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"1avgsteps\"], \n",
    "    \"additional_attribute\": [\"nonoise\",\"selfnoise\"],\n",
    "}\n",
    "\n",
    "muffliato_attributes = {\n",
    "    \"variant\":[\"muffliato\"],\n",
    "    \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"10avgsteps\"],\n",
    "}\n",
    "current_attributes = [zerosum_attributes,muffliato_attributes]\n",
    "zerosum_experiments = plot_loaders.filter_attribute_list(experiments_attributes,current_attributes)\n",
    "\n",
    "plt.figure()\n",
    "plot_utils.scatter_averaged_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Accuracy vs AUC evolution accross entire runs-dynamic topology\",\n",
    "    \"test_acc mean\",\n",
    "    \"roc_auc mean\",\n",
    "    save_directory=save_directory,\n",
    "    y_method=y_method,\n",
    "    x_method=x_method,\n",
    "    orderings=ORDERINGS,\n",
    "    name_formater=name_formater,\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "plot_utils.scatter_averaged_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Accuracy vs Linkability attack for the entire run-dynamic topology\",\n",
    "    y_axis_name=\"test_acc mean\",\n",
    "    x_axis_name=\"linkability_top1 count_percentage_success\",\n",
    "    save_directory=save_directory,\n",
    "    y_method=y_method,\n",
    "    x_method=x_method,\n",
    "    orderings=ORDERINGS,\n",
    "    name_formater=name_formater,\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "plot_utils.scatter_averaged_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Accuracy vs Linkability top5 attack for the entire run-dynamic topology\",\n",
    "    y_axis_name=\"test_acc mean\",\n",
    "    x_axis_name=\"linkability_top5 count_percentage_success\",\n",
    "    save_directory=save_directory,\n",
    "    y_method=y_method,\n",
    "    x_method=x_method,\n",
    "    orderings=ORDERINGS,\n",
    "    name_formater=name_formater,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plot_utils)\n",
    "zerosum_attributes = {\n",
    "    \"variant\":[\"nonoise\"],\n",
    "    \"topology_type\":[\"static\"],\n",
    "    \"avgsteps\": [\"1avgsteps\"],\n",
    "    # \"noise_level\":[None,\"2th\",\"4th\"]\n",
    "}\n",
    "\n",
    "\n",
    "zerosum_experiments = plot_loaders.filter_attribute(experiments_attributes,zerosum_attributes)\n",
    "for experiment in sorted(zerosum_experiments):\n",
    "    print(experiment)\n",
    "\n",
    "\n",
    "experiment = zerosum_experiments[0]\n",
    "experiment_data = formatted_data[experiment] \n",
    "\n",
    "sns.set_theme()\n",
    "sns.relplot(data=experiment_data, x=\"roc_auc mean\", y=\"test_acc mean\", hue=\"iteration\")\n",
    "\n",
    "title = \"Evolution of the unnoised test accuracy and AUC-static topology\"\n",
    "plt.title(title)\n",
    "plt.savefig(save_directory + title.replace(\" \",\"_\") +\".pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better experiment display (selected noises levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plot_utils)\n",
    "zerosum_attributes = {\n",
    "    \"variant\":[\"nonoise\",\"zerosum\"],\n",
    "    # \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"1avgsteps\"], \n",
    "    \"additional_attribute\": [\"nonoise\",\"selfnoise\"],\n",
    "    \"noise_level\":[\"nonoise\",\"4th\"]\n",
    "}\n",
    "\n",
    "muffliato_attributes = {\n",
    "    \"variant\":[\"muffliato\"],\n",
    "    # \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"10avgsteps\"], \n",
    "    \"noise_level\":[\"64th\"]\n",
    "}\n",
    "current_attributes= [zerosum_attributes,muffliato_attributes]\n",
    "\n",
    "display_attributes = {\n",
    "    \"hue\":[\"variant\",\"noise_level\",\"avgsteps\"],\n",
    "    \"style\":[\"variant\",\"noise_level\",\"avgsteps\"],\n",
    "    \"size\":[\"variant\",\"noise_level\",\"avgsteps\"], # For some reason having both style and size breaks in this case.\n",
    "    \"col\":\"topology_type\",\n",
    "}\n",
    "\n",
    "order_mapper = {\"muffliato\":2,\"nonoise\":0,\"zerosum\":1}\n",
    "zerosum_experiments = plot_loaders.filter_attribute_list(experiments_attributes,current_attributes)\n",
    "zerosum_experiments = sorted(zerosum_experiments, key = lambda x : order_mapper[x.split(\"_\")[1]])\n",
    "for experiment in zerosum_experiments:\n",
    "    print(experiment)\n",
    "# zerosum_experiments = [zerosum_experiments[i] for i in [0,1,4,5,2,3] ]\n",
    "\n",
    "\n",
    "\n",
    "plot_utils.plot_all_experiments(\n",
    "    data=formatted_data,\n",
    "    experiments=zerosum_experiments,\n",
    "    display_attributes=display_attributes,\n",
    "    plot_name=\"Selected noise:Accuracy of Zerosum and Muffliato\",\n",
    "    column_name=\"test_acc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings = ORDERINGS,\n",
    ")\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plot_utils.plot_all_experiments(\n",
    "    data=formatted_data,\n",
    "    experiments=zerosum_experiments,\n",
    "    display_attributes=display_attributes,\n",
    "    plot_name=\"Selected noise:Attack AUC of Zerosum and Muffliato\",\n",
    "    column_name=\"roc_auc mean_start_avg\",\n",
    "    save_directory=save_directory,\n",
    "    orderings = ORDERINGS,\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plot_utils.plot_all_experiments(\n",
    "    data=formatted_data,\n",
    "    experiments=zerosum_experiments,\n",
    "    display_attributes=display_attributes,\n",
    "    plot_name=\"Selected noise:Linkability attack ac of Zerosum and Muffliato\",\n",
    "    column_name=\"linkability_top1 count_percentage_success_start_avg\",\n",
    "    save_directory=save_directory,\n",
    "    orderings = ORDERINGS,\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "#Needs to only have hue since we can't have other attributes in jointplots\n",
    "display_attributes = {\n",
    "    \"hue\":[\"variant\",\"noise_level\",\"avgsteps\"],\n",
    "}\n",
    "\n",
    "zerosum_attributes = {\n",
    "    \"variant\":[\"nonoise\",\"zerosum\"],\n",
    "    \"topology_type\":[\"static\"],\n",
    "    \"avgsteps\": [\"1avgsteps\"], \n",
    "    \"additional_attribute\": [\"nonoise\",\"selfnoise\"],\n",
    "    \"noise_level\":[\"nonoise\",\"4th\"]\n",
    "}\n",
    "\n",
    "muffliato_attributes = {\n",
    "    \"variant\":[\"muffliato\"],\n",
    "    \"topology_type\":[\"static\"],\n",
    "    \"avgsteps\": [\"10avgsteps\"], \n",
    "    \"noise_level\":[\"64th\"]\n",
    "}\n",
    "current_attributes= [zerosum_attributes,muffliato_attributes]\n",
    "\n",
    "zerosum_experiments = plot_loaders.filter_attribute_list(experiments_attributes,current_attributes)\n",
    "for experiment in sorted(zerosum_experiments):\n",
    "    print(experiment)\n",
    "print(\"-\"*40)\n",
    "\n",
    "\n",
    "plot_utils.scatter_all_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Selected noise:Accuracy vs AUC-static\",\n",
    "    \"roc_auc mean\",\n",
    "    \"test_acc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")\n",
    "plt.figure()\n",
    "plot_utils.scatter_all_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Selected noise:Accuracy vs Linkability sucess rate-static\",\n",
    "    \"linkability_top1 count_percentage_success\",\n",
    "    \"test_acc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plot_utils)\n",
    "zerosum_attributes = {\n",
    "    \"variant\":[\"nonoise\",\"zerosum\"],\n",
    "    # \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"1avgsteps\"], \n",
    "    \"additional_attribute\": [\"nonoise\",\"selfnoise\"],\n",
    "    \"noise_level\":[\"nonoise\",\"1th\",\"2th\",\"4th\"]\n",
    "}\n",
    "\n",
    "muffliato_attributes = {\n",
    "    \"variant\":[\"muffliato\"],\n",
    "    # \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"10avgsteps\"], \n",
    "    \"noise_level\":[\"1th\",\"2th\",\"4th\"]\n",
    "}\n",
    "current_attributes= [zerosum_attributes,muffliato_attributes]\n",
    "\n",
    "\n",
    "display_attributes = {\n",
    "    \"hue\":\"noise_level\",\n",
    "    \"style\":\"variant\",\n",
    "    \"size\":\"avgsteps\", # For some reason having both style and size breaks in this case.\n",
    "    \"col\":\"topology_type\",\n",
    "}\n",
    "\n",
    "zerosum_experiments = plot_loaders.filter_attribute_list(experiments_attributes,current_attributes)\n",
    "for experiment in sorted(zerosum_experiments):\n",
    "    print(experiment)\n",
    "\n",
    "\n",
    "\n",
    "plot_utils.plot_all_experiments(\n",
    "    data=formatted_data,\n",
    "    experiments=zerosum_experiments,\n",
    "    display_attributes=display_attributes,\n",
    "    plot_name=\"High noise:Accuracy of Zerosum and Muffliato with and without self noise-dynamic topology\",\n",
    "    column_name=\"test_acc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plot_utils.plot_all_experiments(\n",
    "    data=formatted_data,\n",
    "    experiments=zerosum_experiments,\n",
    "    display_attributes=display_attributes,\n",
    "    plot_name=\"High noise:Linkability attack accuracy of Zerosum and Muffliato with and without self noise-dynamic topology\",\n",
    "    column_name=\"linkability_top1 count_percentage_success\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")\n",
    "\n",
    "# Plot the middle noises\n",
    "importlib.reload(plot_utils)\n",
    "zerosum_attributes = {\n",
    "    \"variant\":[\"nonoise\",\"zerosum\"],\n",
    "    # \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"1avgsteps\"], \n",
    "    \"additional_attribute\": [\"nonoise\",\"selfnoise\"],\n",
    "    \"noise_level\":[\"nonoise\",\"8th\",\"16th\"]\n",
    "}\n",
    "\n",
    "muffliato_attributes = {\n",
    "    \"variant\":[\"muffliato\"],\n",
    "    # \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"10avgsteps\"], \n",
    "    \"noise_level\":[\"8th\",\"16th\"]\n",
    "}\n",
    "current_attributes= [zerosum_attributes,muffliato_attributes]\n",
    "zerosum_experiments = plot_loaders.filter_attribute_list(experiments_attributes,current_attributes)\n",
    "\n",
    "plt.figure()\n",
    "plot_utils.plot_all_experiments(\n",
    "    data=formatted_data,\n",
    "    experiments=zerosum_experiments,\n",
    "    display_attributes=display_attributes,\n",
    "    plot_name=\"Middle noise:Accuracy of Zerosum and Muffliato with and without self noise-dynamic topology\",\n",
    "    column_name=\"test_acc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "plot_utils.plot_all_experiments(\n",
    "    data=formatted_data,\n",
    "    experiments=zerosum_experiments,\n",
    "    display_attributes=display_attributes,\n",
    "    plot_name=\"Middle noise:Linkability attack accuracy of Zerosum and Muffliato with and without self noise-dynamic topology\",\n",
    "    column_name=\"linkability_top1 count_percentage_success\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")\n",
    "\n",
    "\n",
    "# Plot the low noises\n",
    "importlib.reload(plot_utils)\n",
    "zerosum_attributes = {\n",
    "    \"variant\":[\"nonoise\",\"zerosum\"],\n",
    "    # \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"1avgsteps\"], \n",
    "    \"additional_attribute\": [\"nonoise\",\"selfnoise\"],\n",
    "    \"noise_level\":[\"nonoise\",\"32th\",\"64th\",\"128th\"]\n",
    "}\n",
    "\n",
    "muffliato_attributes = {\n",
    "    \"variant\":[\"muffliato\"],\n",
    "    # \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"10avgsteps\"], \n",
    "    \"noise_level\":[\"32th\",\"64th\",\"128th\"]\n",
    "}\n",
    "current_attributes= [zerosum_attributes,muffliato_attributes]\n",
    "zerosum_experiments = plot_loaders.filter_attribute_list(experiments_attributes,current_attributes)\n",
    "\n",
    "plt.figure()\n",
    "plot_utils.plot_all_experiments(\n",
    "    data=formatted_data,\n",
    "    experiments=zerosum_experiments,\n",
    "    display_attributes=display_attributes,\n",
    "    plot_name=\"Low noise:Accuracy of Zerosum and Muffliato with and without self noise-dynamic topology\",\n",
    "    column_name=\"test_acc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "plot_utils.plot_all_experiments(\n",
    "    data=formatted_data,\n",
    "    experiments=zerosum_experiments,\n",
    "    display_attributes=display_attributes,\n",
    "    plot_name=\"Low noise:Linkability attack accuracy of Zerosum and Muffliato with and without self noise-dynamic topology\",\n",
    "    column_name=\"linkability_top1 count_percentage_success\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")\n",
    "plt.ylim(top=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start average trial displays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plot_utils)\n",
    "zerosum_attributes = {\n",
    "    \"variant\":[\"nonoise\",\"zerosum\"],\n",
    "    # \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"1avgsteps\"], \n",
    "    \"additional_attribute\": [\"nonoise\",\"selfnoise\"],\n",
    "    \"noise_level\":[\"nonoise\",\"4th\"]\n",
    "}\n",
    "\n",
    "muffliato_attributes = {\n",
    "    \"variant\":[\"muffliato\"],\n",
    "    # \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"10avgsteps\"], \n",
    "    \"noise_level\":[\"64th\"]\n",
    "}\n",
    "current_attributes= [zerosum_attributes,muffliato_attributes]\n",
    "\n",
    "display_attributes = {\n",
    "    \"hue\":[\"variant\",\"noise_level\",\"avgsteps\"],\n",
    "    \"style\":[\"variant\",\"noise_level\",\"avgsteps\"],\n",
    "    \"size\":[\"variant\",\"noise_level\",\"avgsteps\"], # For some reason having both style and size breaks in this case.\n",
    "    \"col\":\"topology_type\",\n",
    "}\n",
    "\n",
    "order_mapper = {\"muffliato\":2,\"nonoise\":0,\"zerosum\":1}\n",
    "zerosum_experiments = plot_loaders.filter_attribute_list(experiments_attributes,current_attributes)\n",
    "zerosum_experiments = sorted(zerosum_experiments,key = lambda x : order_mapper[x.split(\"_\")[1]])\n",
    "for experiment in sorted(zerosum_experiments):\n",
    "    print(experiment)\n",
    "\n",
    "\n",
    "\n",
    "plot_utils.plot_all_experiments(\n",
    "    data=formatted_data,\n",
    "    experiments=zerosum_experiments,\n",
    "    display_attributes=display_attributes,\n",
    "    plot_name=\"Selected noise: Accuracy of Zerosum and Muffliato\",\n",
    "    column_name=\"test_acc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings = ORDERINGS,\n",
    ")\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plot_utils.plot_all_experiments(\n",
    "    data=formatted_data,\n",
    "    experiments=zerosum_experiments,\n",
    "    display_attributes=display_attributes,\n",
    "    plot_name=\"Selected noise: Threshold AUC rolling average of Zerosum and Muffliato\",\n",
    "    column_name=\"roc_auc mean_start_avg\",\n",
    "    save_directory=save_directory,\n",
    "    orderings = ORDERINGS,\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plot_utils.plot_all_experiments(\n",
    "    data=formatted_data,\n",
    "    experiments=zerosum_experiments,\n",
    "    display_attributes=display_attributes,\n",
    "    plot_name=\"Selected noise: Linkability attack rolling average ac of Zerosum and Muffliato\",\n",
    "    column_name=\"linkability_top1 count_percentage_success_start_avg\",\n",
    "    save_directory=save_directory,\n",
    "    orderings = ORDERINGS,\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "#Needs to only have hue since we can't have other attributes in jointplots\n",
    "display_attributes = {\n",
    "    \"hue\":[\"variant\",\"noise_level\",\"avgsteps\"],\n",
    "}\n",
    "\n",
    "zerosum_attributes = {\n",
    "    \"variant\":[\"nonoise\",\"zerosum\"],\n",
    "    \"topology_type\":[\"static\"],\n",
    "    \"avgsteps\": [\"1avgsteps\"], \n",
    "    \"additional_attribute\": [\"nonoise\",\"selfnoise\"],\n",
    "    \"noise_level\":[\"nonoise\",\"4th\"]\n",
    "}\n",
    "\n",
    "muffliato_attributes = {\n",
    "    \"variant\":[\"muffliato\"],\n",
    "    \"topology_type\":[\"static\"],\n",
    "    \"avgsteps\": [\"10avgsteps\"], \n",
    "    \"noise_level\":[\"64th\"]\n",
    "}\n",
    "current_attributes= [zerosum_attributes,muffliato_attributes]\n",
    "\n",
    "zerosum_experiments = plot_loaders.filter_attribute_list(experiments_attributes,current_attributes)\n",
    "for experiment in sorted(zerosum_experiments):\n",
    "    print(experiment)\n",
    "print(\"-\"*40)\n",
    "\n",
    "\n",
    "plot_utils.scatter_all_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Selected noise: Accuracy vs Threshold AUC rolling average-static\",\n",
    "    \"roc_auc mean_start_avg\",\n",
    "    \"test_acc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")\n",
    "plt.figure()\n",
    "plot_utils.scatter_all_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Selected noise: Accuracy vs Linkability sucess rate rolling average-static\",\n",
    "    \"linkability_top1 count_percentage_success_start_avg\",\n",
    "    \"test_acc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_expe = list(formatted_data.keys())[-1]\n",
    "print(formatted_data[last_expe][\"noise_level\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display the test loss and test accuracy of inflexion point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plot_utils)\n",
    "\n",
    "muffliato_attributes = {\n",
    "    \"variant\":[\"zerosum\"],\n",
    "    \"additional_attribute\":[\"selfnoise\"],\n",
    "    # \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"1avgsteps\"], \n",
    "    \"noise_level\":[\"6th\",\n",
    "        \"7th\",\n",
    "        \"8th\",\n",
    "        \"16th\",\n",
    "        \"32th\",\"64th\",\"128th\"]\n",
    "}\n",
    "current_attributes= [muffliato_attributes]\n",
    "\n",
    "display_attributes = {\n",
    "    \"hue\":[\"variant\",\"noise_level_value\"],\n",
    "    # \"style\":[\"variant\",\"noise_level\",\"avgsteps\"],\n",
    "    # \"size\":[\"variant\",\"noise_level\",\"avgsteps\"], # For some reason having both style and size breaks in this case.\n",
    "    \"col\":\"topology_type\",\n",
    "}\n",
    "\n",
    "muffliato_experiments = plot_loaders.filter_attribute_list(experiments_attributes,current_attributes)\n",
    "for experiment in muffliato_experiments:\n",
    "    print(experiment)\n",
    "\n",
    "plot_utils.plot_all_experiments(\n",
    "    data=formatted_data,\n",
    "    experiments=muffliato_experiments,\n",
    "    display_attributes=display_attributes,\n",
    "    plot_name=\"Inflexion point: test_acc of Muffliato\",\n",
    "    column_name=\"test_acc mean\",\n",
    "    save_directory=save_directory,\n",
    "    # orderings = ORDERINGS,\n",
    ")\n",
    "plt.figure()\n",
    "plot_utils.plot_all_experiments(\n",
    "    data=formatted_data,\n",
    "    experiments=muffliato_experiments,\n",
    "    display_attributes=display_attributes,\n",
    "    plot_name=\"Inflexion point: test_loss of Muffliato\",\n",
    "    column_name=\"test_loss mean\",\n",
    "    save_directory=save_directory,\n",
    "    # orderings = ORDERINGS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data displays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plot_utils)\n",
    "\n",
    "target_accuracy = 50\n",
    "\n",
    "\n",
    "zerosum_attributes = {\n",
    "    \"variant\":[\"nonoise\",\"zerosum\"],\n",
    "    \"topology_type\":[\"static\"],\n",
    "    \"avgsteps\": [\"1avgsteps\"], \n",
    "    \"additional_attribute\": [\"nonoise\",\"selfnoise\"],\n",
    "    # \"noise_level\":[\"nonoise\",\"4th\"]\n",
    "}\n",
    "\n",
    "muffliato_attributes = {\n",
    "    \"variant\":[\"muffliato\"],\n",
    "    \"topology_type\":[\"static\"],\n",
    "    \"avgsteps\": [\"10avgsteps\"], \n",
    "    # \"noise_level\":[\"64th\"]\n",
    "}\n",
    "current_attributes= [zerosum_attributes,muffliato_attributes]\n",
    "\n",
    "zerosum_experiments = plot_loaders.filter_attribute_list(experiments_attributes,current_attributes)\n",
    "for experiment in sorted(zerosum_experiments):\n",
    "    print(experiment)\n",
    "order = ORDERINGS[\"noise_level\"]\n",
    "order_mapper = {\"muffliato\":2,\"nonoise\":1,\"zerosum\":0}\n",
    "zerosum_experiments = sorted(zerosum_experiments, key = lambda x : order_mapper[x.split(\"_\")[1]])\n",
    "\n",
    "plot_utils.plot_communication(formatted_data,zerosum_experiments,target_accuracy,f\"Communications to reach {target_accuracy}% accuracy-static\",save_directory=save_directory,order=order)\n",
    "\n",
    "zerosum_attributes = {\n",
    "    \"variant\":[\"nonoise\",\"zerosum\"],\n",
    "    \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"1avgsteps\"], \n",
    "    \"additional_attribute\": [\"nonoise\",\"selfnoise\"],\n",
    "    # \"noise_level\":[\"nonoise\",\"4th\"]\n",
    "}\n",
    "\n",
    "muffliato_attributes = {\n",
    "    \"variant\":[\"muffliato\"],\n",
    "    \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"10avgsteps\"], \n",
    "    # \"noise_level\":[\"64th\"]\n",
    "}\n",
    "\n",
    "current_attributes= [zerosum_attributes,muffliato_attributes]\n",
    "zerosum_experiments = plot_loaders.filter_attribute_list(experiments_attributes,current_attributes)\n",
    "\n",
    "order = ORDERINGS[\"noise_level\"]\n",
    "order_mapper = {\"muffliato\":2,\"nonoise\":0,\"zerosum\":1}\n",
    "zerosum_experiments = sorted(zerosum_experiments, key = lambda x : order_mapper[x.split(\"_\")[1]])\n",
    "\n",
    "plt.figure()\n",
    "plot_utils.plot_communication(formatted_data,zerosum_experiments,target_accuracy,f\"Communications to reach {target_accuracy}% accuracy-dynamic\",save_directory=save_directory,order=order)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legacy content\n",
    "Old cells that are mostly in the way, and that I won't execute anymore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise cancellation vs no noise cancellation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "importlib.reload(plot_utils)\n",
    "zerosum_attributes = {\"variant\":[\"nonoise\",\"zerosum\"]}\n",
    "# zerosum_attributes = {\"variant\":[\"nonoise\",\"zerosum\"],\"topology_type\":[\"static\"]}\n",
    "# zerosum_attributes = {\"variant\":[\"nonoise\",\"zerosum\"],\"topology_type\":[\"dynamic\"]}\n",
    "\n",
    "display_attributes = {\n",
    "    \"hue\":\"noise_level\",\n",
    "    \"style\": \"additional_attribute\",\n",
    "    \"size\": \"variant\",\n",
    "    \"col\":\"topology_type\"\n",
    "}\n",
    "\n",
    "zerosum_experiments = plot_loaders.filter_attribute(experiments_attributes,zerosum_attributes)\n",
    "for experiment in sorted(zerosum_experiments):\n",
    "    print(experiment)\n",
    "\n",
    "plot_utils.plot_all_experiments(\n",
    "    data=formatted_data,\n",
    "    experiments=zerosum_experiments,\n",
    "    display_attributes=display_attributes,\n",
    "    plot_name=\"Test accuracy evolution of ZeroSum with and without self noise\",\n",
    "    column_name=\"test_acc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-python3.10-decentralizepy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
