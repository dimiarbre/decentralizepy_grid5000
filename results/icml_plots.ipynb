{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys,os\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "import concurrent.futures\n",
    "import importlib\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CIFAR ICML experiments\n",
    "target_dir = \"my_results/icml_experiments/cifar10/\"\n",
    "ATTACK_RESULTS_PATH = \"my_results/icml_experiments/cifar10_attack_results_unbalanced/\"\n",
    "\n",
    "# Tryouts for Femnist\n",
    "# target_dir = \"my_results/test/testing_femnist_convergence_rates/\"\n",
    "# ATTACK_RESULTS_PATH = \"my_results/test/femnist_attack_results/\"\n",
    "\n",
    "#Tryouts for CIFAR\n",
    "# target_dir = \"my_results/test/testing_convergence_rates/\"\n",
    "# ATTACK_RESULTS_PATH = \"my_results/test/femnist_attack_results/\"\n",
    "\n",
    "TOTAL_PROCESSES = 128\n",
    "MAX_MACHINES =  8\n",
    "MAX_ITERATIONS=10000\n",
    "STARTING_ITERATION = 0\n",
    "\n",
    "linestyles = {\n",
    "    \"ZeroSum\" : \"--\"\n",
    "}\n",
    "\n",
    "fontsize=20\n",
    "\n",
    "alpha = 0.1\n",
    "\n",
    "save_directory = \"assets/\"\n",
    "\n",
    "ORDERINGS = {\n",
    "    \"noise_level\" : [\"nonoise\",\"2th\",\"4th\",\"8th\",\"16th\",\"32th\",\"64th\"],\n",
    "    \"variant\":[\"nonoise\",\"zerosum\",\"muffliato\"],\n",
    "    \"avgsteps\": [\"10avgsteps\", \"1avgsteps\"]\n",
    "} \n",
    "\n",
    "assert TOTAL_PROCESSES%MAX_MACHINES == 0\n",
    "MAX_PROCESSES = TOTAL_PROCESSES//MAX_MACHINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the file list\n",
    "experiments_dict = utils.get_full_path_dict(target_dir)\n",
    "experiments_attributes = utils.get_experiments_dict(experiments_dict)\n",
    "\n",
    "print(experiments_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_folder = 'machine{}'\n",
    "result_file = '{}_results.json'\n",
    "\n",
    "\n",
    "def load_data(dir):\n",
    "    data = pd.DataFrame({})\n",
    "    for machine in range(MAX_MACHINES):\n",
    "        for rank in range(MAX_PROCESSES):\n",
    "            # print(f\"Loading results for machine {machine} and rank {rank}.  \",end = \"\\r\")\n",
    "            uid = rank + machine * MAX_PROCESSES\n",
    "\n",
    "            file = os.path.join(dir, machine_folder.format(machine), result_file.format(rank))\n",
    "            tmp_df = pd.read_json(file)\n",
    "            tmp_df[\"uid\"] = uid # Manually add the uid for further processing                                                                   \n",
    "            tmp_df[\"iteration\"] = tmp_df.index\n",
    "            # print(tmp_df)\n",
    "            tmp_df = tmp_df[tmp_df[\"iteration\"]>=STARTING_ITERATION]\n",
    "            tmp_df = tmp_df[tmp_df[\"iteration\"]<=MAX_ITERATIONS]\n",
    "            data = pd.concat([data,tmp_df])\n",
    "    return data\n",
    "\n",
    "def load_attack_results(current_experiment_data,experiment_name,attack_results_path):\n",
    "    expected_file_name = experiment_name + \".csv\"\n",
    "    directories = sorted(os.listdir(attack_results_path))\n",
    "    \n",
    "    if expected_file_name not in directories:\n",
    "        print(f\"Not loading attack results: {expected_file_name} was not listed with attack results in {attack_results_path}. Entire directory:\\n{directories}\")\n",
    "        return current_experiment_data\n",
    "    attacks_df = pd.read_csv(os.path.join(attack_results_path,expected_file_name))\n",
    "    attacks_df = attacks_df.drop(columns = \"Unnamed: 0\")\n",
    "    attacks_df = attacks_df.rename(columns = {\"agent\":\"uid\"})\n",
    "    # print(attacks_df.columns)\n",
    "    # print(current_experiment_data)\n",
    "    # print(attacks_df)\n",
    "    \n",
    "    res = pd.merge(current_experiment_data, attacks_df,on = [\"uid\",\"iteration\"],how=\"outer\" )\n",
    "    # print(res)\n",
    "    return res\n",
    "\n",
    "def load_linkability_attack_results(current_experiment_data,experiment_name,attack_results_path):\n",
    "    expected_file_name = f\"linkability_{experiment_name}.csv\"\n",
    "    directories = sorted(os.listdir(attack_results_path))\n",
    "    if expected_file_name not in directories:\n",
    "        print(f\"Not loading attack results: {expected_file_name} was not listed with attack results in {attack_results_path}. Entire directory:\\n{directories}\")\n",
    "        return current_experiment_data\n",
    "    \n",
    "    linkability_attack_df = pd.read_csv(os.path.join(attack_results_path,expected_file_name))\n",
    "\n",
    "    linkability_attack_df = linkability_attack_df.rename(columns = {\"agent\":\"uid\"})\n",
    "\n",
    "    return pd.merge(current_experiment_data,linkability_attack_df,on = [\"uid\",\"iteration\"],how=\"outer\")\n",
    "\n",
    "# Function to recompute some of the linkability attack results. Should only be used if there are errors in the data (see perform_attack.py).\n",
    "def fix_linkability_attack_results(experiment_name,attack_results_path):\n",
    "    expected_file_name = f\"linkability_{experiment_name}.csv\"\n",
    "    directories = sorted(os.listdir(attack_results_path))\n",
    "    if expected_file_name not in directories:\n",
    "        print(f\"Not loading attack results: {expected_file_name} was not listed with attack results in {attack_results_path}. Entire directory:\\n{directories}\")\n",
    "        raise FileNotFoundError(expected_file_name)\n",
    "    \n",
    "    linkability_attack_df = pd.read_csv(os.path.join(attack_results_path,expected_file_name))\n",
    "    \n",
    "    # Fixing all the missing values/wrongly filled values  \n",
    "    linkability_attack_df[\"linkability_top1\"] = (linkability_attack_df[\"linkability_top1_guess\"]==linkability_attack_df[\"agent\"])\n",
    "    \n",
    "    linkability_attack_df.reset_index(drop = True)\n",
    "    linkability_attack_df.set_index([\"agent\",\"iteration\"])\n",
    "    columns = linkability_attack_df.columns.to_list()\n",
    "    columns_losses = [column for column in columns if \"loss_trainset_\" in column]\n",
    "    \n",
    "    linkability_attack_df[\"linkability_real_rank\"] = np.nan\n",
    "    linkability_attack_df[\"linkability_real_rank\"].astype('Int64',copy=False)\n",
    "    for index,row in linkability_attack_df.iterrows():\n",
    "        losses = [(int(column.split(\"_\")[2]),row[column]) for column in columns_losses]\n",
    "        losses_sorted = sorted(losses, key = lambda x:x[1])\n",
    "        agents_sorted = [x[0] for x in losses_sorted]\n",
    "        current_agent = row[\"agent\"]\n",
    "        linkability_rank = agents_sorted.index(current_agent)\n",
    "        linkability_attack_df.at[index,\"linkability_real_rank\"] = linkability_rank\n",
    "    \n",
    "    linkability_attack_df = linkability_attack_df.drop(columns = \"Unnamed: 0\")\n",
    "    linkability_attack_df.to_csv(os.path.join(attack_results_path,f\"fixed_{expected_file_name}\"))\n",
    "    \n",
    "    return linkability_attack_df\n",
    "\n",
    "def load_data_element(name,filepath,attack_result_path):\n",
    "    print(f\"Loading data from {name}\")\n",
    "    current_results = load_data(filepath).dropna()\n",
    "    current_results = load_attack_results(current_results,name,attack_results_path=attack_result_path)\n",
    "    current_results = load_linkability_attack_results(current_results,name,attack_results_path=attack_result_path)\n",
    "    # input_dict[name] = current_results\n",
    "    attributes = utils.get_attributes(name)\n",
    "    for attribute, attribute_value in attributes.items():\n",
    "        current_results[attribute] = attribute_value\n",
    "    \n",
    "    print(f\"Finished loading data from {name}\")\n",
    "    return current_results\n",
    "\n",
    "\n",
    "loaded_data = {}\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=20) as executor:\n",
    "    futures = {}\n",
    "    for name,filepath in sorted(experiments_dict.items()):\n",
    "        futures[name] = executor.submit(load_data_element,name,filepath,ATTACK_RESULTS_PATH)\n",
    "        \n",
    "        # load_data_element(loaded_data,name,filepath,ATTACK_RESULTS_PATH)\n",
    "        # break\n",
    "        \n",
    "        # fix_linkability_attack_results(name,attack_results_path=ATTACK_RESULTS_PATH)\n",
    "        # break\n",
    "    for name, result in futures.items():\n",
    "        loaded_data[name]=result.result()\n",
    "# print(loaded_data)\n",
    "print(\"Finished loading all data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_agg_methods = [\"mean\", \"std\", \"sum\",\"min\",\"max\"]\n",
    "columns_to_agg = [\"train_loss\",\"test_loss\", \"test_acc\", \"total_bytes\", \"total_meta\", \"total_data_per_n\", \"roc_auc\"]\n",
    "# columns_to_agg = [\"train_loss\",\"test_loss\", \"test_acc\", \"total_bytes\", \"total_meta\", \"total_data_per_n\"]\n",
    "\n",
    "\n",
    "def count_percentage_success(column:pd.Series):\n",
    "    counts = column.value_counts(normalize=True)\n",
    "    if True not in counts:\n",
    "        return np.nan\n",
    "    res = counts[True]\n",
    "    return res \n",
    "\n",
    "\n",
    "linkability_aggregators = {\n",
    "    \"linkability_top1\": [count_percentage_success],\n",
    "    \"linkability_top5\": [count_percentage_success],\n",
    "    \"linkability_real_rank\": [\"median\",\"min\",\"max\"],\n",
    "}\n",
    "\n",
    "def start_avg(column:pd.Series):\n",
    "    res = []\n",
    "    running_elements:pd.Series = pd.Series({})\n",
    "    for (index,value) in column.items():\n",
    "        if np.isnan(value):\n",
    "            res.append(np.NaN)\n",
    "        elif running_elements.empty:\n",
    "            running_elements = pd.Series(value)\n",
    "            res.append(value)\n",
    "        else:\n",
    "            running_elements = pd.concat([running_elements,pd.Series(value)])\n",
    "            res.append(running_elements.mean()) \n",
    "    return res\n",
    "\n",
    "to_start_avg = [\"roc_auc mean\",\"linkability_top1 count_percentage_success\"]\n",
    "\n",
    "general_aggregator = {column:general_agg_methods for column in columns_to_agg}\n",
    "\n",
    "general_aggregator.update(linkability_aggregators) \n",
    "\n",
    "def format_data(data,key):\n",
    "    usable_data = data[[\"iteration\"] + columns_to_agg +  list(linkability_aggregators.keys())]\n",
    "    grouped_data = usable_data.groupby(['iteration']) \n",
    "    usable_data = grouped_data.agg(general_aggregator)\n",
    "    usable_data.reset_index(inplace=True)\n",
    "    usable_data.set_index(\"iteration\",inplace=True)\n",
    "\n",
    "    usable_data.insert(1,\"experience_name\",key)\n",
    "    usable_data.insert(2,\"number_agents\",TOTAL_PROCESSES)\n",
    "\n",
    "    usable_data.columns = [' '.join(e) if len(e[-1])>0 else e[0] for e in usable_data.columns]\n",
    "\n",
    "    \n",
    "    \n",
    "    experiment_attributes = utils.get_attributes(key)\n",
    "    for attribute, attribute_value in experiment_attributes.items():\n",
    "        usable_data[attribute] = attribute_value\n",
    "    \n",
    "    # Compute an additional column: \"{column}_start_avg\"\n",
    "    for column_name in to_start_avg:\n",
    "        rolled_average = start_avg(usable_data[column_name])\n",
    "        usable_data[column_name + \"_start_avg\"] =  rolled_average\n",
    "        print(usable_data[column_name + \"_start_avg\"].dropna() )\n",
    "    return usable_data\n",
    "\n",
    "\n",
    "\n",
    "formatted_data = {}\n",
    "for name,data in sorted(loaded_data.items()):\n",
    "    print(f\"Formatting {name}\")\n",
    "    formatted_data[name] = format_data(data,name)\n",
    "formatted_data[list(formatted_data)[0]].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "static_filter = {\"topology_type\" : [\"static\"] }\n",
    "dynamic_filter = {\"topology_type\" : [\"dynamic\"]}\n",
    "\n",
    "static_experiments =  utils.filter_attribute(experiments_attributes,static_filter)\n",
    "dynamic_experiments = utils.filter_attribute(experiments_attributes,dynamic_filter)\n",
    "\n",
    "#To display full experiments\n",
    "display_attributes = {\n",
    "    \"hue\": \"noise_level\",\n",
    "    \"style\":[\"variant\",\"avgsteps\",\"additional_attribute\"],\n",
    "    \"col\" : \"topology_type\",\n",
    "}\n",
    "\n",
    "# To display experiment parameters tuning.\n",
    "# display_attributes = {\n",
    "#     \"hue\": \"lr\",\n",
    "#     \"style\":\"local_rounds\",\n",
    "#     \"col\" : \"topology_type\",\n",
    "# }\n",
    "\n",
    "utils.plot_all_experiments(\n",
    "    formatted_data,\n",
    "    experiments_attributes,\n",
    "    display_attributes,\n",
    "    \"All experiments accuracies evolution\",\n",
    "    \"test_acc mean\",\n",
    "    save_directory=save_directory\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise cancellation vs no noise cancellation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "importlib.reload(utils)\n",
    "zerosum_attributes = {\"variant\":[\"nonoise\",\"zerosum\"]}\n",
    "# zerosum_attributes = {\"variant\":[\"nonoise\",\"zerosum\"],\"topology_type\":[\"static\"]}\n",
    "# zerosum_attributes = {\"variant\":[\"nonoise\",\"zerosum\"],\"topology_type\":[\"dynamic\"]}\n",
    "\n",
    "display_attributes = {\n",
    "    \"hue\":\"noise_level\",\n",
    "    \"style\": \"additional_attribute\",\n",
    "    \"size\": \"variant\",\n",
    "    \"col\":\"topology_type\"\n",
    "}\n",
    "\n",
    "zerosum_experiments = utils.filter_attribute(experiments_attributes,zerosum_attributes)\n",
    "for experiment in sorted(zerosum_experiments):\n",
    "    print(experiment)\n",
    "\n",
    "utils.plot_all_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Test accuracy evolution of ZeroSum with and without self noise\",\n",
    "    \"test_acc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attack results\n",
    "## In the static case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "zerosum_attributes = {\"variant\":[\"nonoise\",\"zerosum\"]}\n",
    "# zerosum_attributes = {\"variant\":[\"nonoise\",\"zerosum\"],\"topology_type\":[\"static\"]}\n",
    "# zerosum_attributes = {\"variant\":[\"nonoise\",\"zerosum\"],\"topology_type\":[\"dynamic\"]}\n",
    "\n",
    "display_attributes = {\n",
    "    \"hue\":\"noise_level\",\n",
    "    \"style\": \"additional_attribute\",\n",
    "    \"size\": \"variant\",\n",
    "    \"col\": \"topology_type\",\n",
    "}\n",
    "\n",
    "zerosum_experiments = utils.filter_attribute(experiments_attributes,zerosum_attributes)\n",
    "for experiment in sorted(zerosum_experiments):\n",
    "    print(experiment)\n",
    "\n",
    "utils.plot_all_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Attack AUC of Zerosum with and without self noise\",\n",
    "    \"roc_auc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results vs Muffliato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "\n",
    "zerosum_attributes = {\n",
    "    \"variant\":[\"zerosum\",\"nonoise\"],\n",
    "    # \"topology_type\":[\"static\"],\n",
    "    # \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"1avgsteps\"],\n",
    "    # \"avgsteps\": [\"1avgsteps\",\"10avgsteps\"],\n",
    "    \"additional_attribute\": [\"nonoise\",\"selfnoise\"]}\n",
    "muffliato_attributes = {\n",
    "    \"variant\":[\"muffliato\"],\n",
    "    # \"topology_type\":[\"static\"],\n",
    "    # \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\":[\"10avgsteps\"],\n",
    "}\n",
    "\n",
    "current_attributes= [zerosum_attributes,muffliato_attributes]\n",
    "\n",
    "display_attributes = {\n",
    "    \"hue\":\"noise_level\",\n",
    "    \"style\":\"variant\",\n",
    "    # \"size\":\"variant\", # For some reason having both style and size breaks in this case.\n",
    "    \"col\":\"topology_type\",\n",
    "}\n",
    "\n",
    "zerosum_experiments = utils.filter_attribute_list(experiments_attributes,current_attributes)\n",
    "for experiment in sorted(zerosum_experiments):\n",
    "    print(experiment)\n",
    "\n",
    "\n",
    "utils.plot_all_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Accuracy of Zerosum and Muffliato with and without self noise\",\n",
    "    \"test_acc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "utils.plot_all_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Attack AUC of Zerosum and Muffliato with and without self noise\",\n",
    "    \"roc_auc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smaller plots to have an easier time to read the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "zerosum_attributes = {\n",
    "    \"variant\":[\"nonoise\",\"zerosum\"],\n",
    "    # \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"1avgsteps\"], \n",
    "    \"additional_attribute\": [\"nonoise\",\"selfnoise\"],\n",
    "    \"noise_level\":[\"nonoise\",\"2th\",\"4th\"]\n",
    "}\n",
    "\n",
    "muffliato_attributes = {\n",
    "    \"variant\":[\"muffliato\"],\n",
    "    # \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"10avgsteps\"], \n",
    "    \"noise_level\":[\"2th\",\"4th\"]\n",
    "}\n",
    "current_attributes= [zerosum_attributes,muffliato_attributes]\n",
    "\n",
    "\n",
    "display_attributes = {\n",
    "    \"hue\":\"noise_level\",\n",
    "    \"style\":\"variant\",\n",
    "    # \"size\":\"variant\", # For some reason having both style and size breaks in this case.\n",
    "    \"col\":\"topology_type\",\n",
    "}\n",
    "\n",
    "zerosum_experiments = utils.filter_attribute_list(experiments_attributes,current_attributes)\n",
    "for experiment in sorted(zerosum_experiments):\n",
    "    print(experiment)\n",
    "\n",
    "\n",
    "\n",
    "utils.plot_all_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"High noise:Accuracy of Zerosum and Muffliato with and without self noise\",\n",
    "    \"test_acc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "utils.plot_all_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"High noise:Attack AUC of Zerosum and Muffliato with and without self noise\",\n",
    "    \"roc_auc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")\n",
    "plt.ylim(top=1)\n",
    "\n",
    "# Plot the middle noises\n",
    "importlib.reload(utils)\n",
    "zerosum_attributes = {\n",
    "    \"variant\":[\"nonoise\",\"zerosum\"],\n",
    "    # \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"1avgsteps\"], \n",
    "    \"additional_attribute\": [\"nonoise\",\"selfnoise\"],\n",
    "    \"noise_level\":[\"nonoise\",\"8th\",\"16th\"]\n",
    "}\n",
    "\n",
    "muffliato_attributes = {\n",
    "    \"variant\":[\"muffliato\"],\n",
    "    # \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"10avgsteps\"], \n",
    "    \"noise_level\":[\"8th\",\"16th\"]\n",
    "}\n",
    "current_attributes= [zerosum_attributes,muffliato_attributes]\n",
    "zerosum_experiments = utils.filter_attribute_list(experiments_attributes,current_attributes)\n",
    "\n",
    "plt.figure()\n",
    "utils.plot_all_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Middle noise:Accuracy of Zerosum and Muffliato with and without self noise\",\n",
    "    \"test_acc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "utils.plot_all_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Middle noise:Attack AUC of Zerosum and Muffliato with and without self noise\",\n",
    "    \"roc_auc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")\n",
    "plt.ylim(top=1)\n",
    "\n",
    "# Plot the low noises\n",
    "importlib.reload(utils)\n",
    "zerosum_attributes = {\n",
    "    \"variant\":[\"nonoise\",\"zerosum\"],\n",
    "    # \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"1avgsteps\"], \n",
    "    \"additional_attribute\": [\"nonoise\",\"selfnoise\"],\n",
    "    \"noise_level\":[\"nonoise\",\"32th\",\"64th\"]\n",
    "}\n",
    "\n",
    "muffliato_attributes = {\n",
    "    \"variant\":[\"muffliato\"],\n",
    "    # \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"10avgsteps\"], \n",
    "    \"noise_level\":[\"32th\",\"64th\"]\n",
    "}\n",
    "current_attributes= [zerosum_attributes,muffliato_attributes]\n",
    "zerosum_experiments = utils.filter_attribute_list(experiments_attributes,current_attributes)\n",
    "\n",
    "plt.figure()\n",
    "utils.plot_all_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Low noise:Accuracy of Zerosum and Muffliato with and without self noise\",\n",
    "    \"test_acc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "utils.plot_all_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Low noise:Attack AUC of Zerosum and Muffliato with and without self noise\",\n",
    "    \"roc_auc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS\n",
    ")\n",
    "plt.ylim(top=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying out scatterplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "\n",
    "'''\n",
    "\n",
    "zerosum_attributes = {\n",
    "    \"variant\":[\"nonoise\",\"zerosum\"],\n",
    "    \"topology_type\":[\"static\"],\n",
    "    \"avgsteps\": [\"1avgsteps\"], \n",
    "    \"additional_attribute\": [\"nonoise\",\"selfnoise\"],\n",
    "    \"noise_level\":[\"nonoise\",\"2th\",\"4th\"]\n",
    "}\n",
    "\n",
    "muffliato_attributes = {\n",
    "    \"variant\":[\"muffliato\"],\n",
    "    \"topology_type\":[\"static\"],\n",
    "    \"avgsteps\": [\"10avgsteps\"],\n",
    "    \"noise_level\":[\"2th\",\"4th\"]\n",
    "}\n",
    "\n",
    "current_attributes = [zerosum_attributes,muffliato_attributes]\n",
    "\n",
    "\n",
    "display_attributes = {\n",
    "    \"hue\":\"noise_level\",\n",
    "    \"style\":\"variant\",\n",
    "    \"size\":\"variant\", # For some reason having both style and size breaks in this case.\n",
    "    \"col\":\"topology_type\",\n",
    "}\n",
    "\n",
    "zerosum_experiments = utils.filter_attribute_list(experiments_attributes,current_attributes)\n",
    "for experiment in sorted(zerosum_experiments):\n",
    "    print(experiment)\n",
    "print(\"-\"*40)\n",
    "\n",
    "\n",
    "utils.scatter_all_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"High noises:Accuracy vs AUC-static\",\n",
    "    \"roc_auc mean\",\n",
    "    \"test_acc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")\n",
    "\n",
    "# Plot the middle noises\n",
    "zerosum_attributes = {\n",
    "    \"variant\":[\"nonoise\",\"zerosum\"],\n",
    "    \"topology_type\":[\"static\"],\n",
    "    \"avgsteps\": [\"1avgsteps\"], \n",
    "    \"additional_attribute\": [\"nonoise\",\"selfnoise\"],\n",
    "    \"noise_level\":[\"nonoise\",\"16th\",\"8th\"]\n",
    "}\n",
    "\n",
    "muffliato_attributes = {\n",
    "    \"variant\":[\"muffliato\"],\n",
    "    \"topology_type\":[\"static\"],\n",
    "    \"avgsteps\": [\"10avgsteps\"],\n",
    "    \"noise_level\":[\"16th\",\"8th\"]\n",
    "}\n",
    "current_attributes = [zerosum_attributes,muffliato_attributes]\n",
    "\n",
    "zerosum_experiments = utils.filter_attribute_list(experiments_attributes,current_attributes)\n",
    "for experiment in sorted(zerosum_experiments):\n",
    "    print(experiment)\n",
    "print(\"-\"*40)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "utils.scatter_all_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Middle noises:Accuracy vs AUC-static\",\n",
    "    \"roc_auc mean\",\n",
    "    \"test_acc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")\n",
    "\n",
    "\n",
    "# Plot the low noises\n",
    "zerosum_attributes = {\n",
    "    \"variant\":[\"nonoise\",\"zerosum\"],\n",
    "    \"topology_type\":[\"static\"],\n",
    "    \"avgsteps\": [\"1avgsteps\"], \n",
    "    \"additional_attribute\": [\"nonoise\",\"selfnoise\"],\n",
    "    \"noise_level\":[\"nonoise\",\"32th\",\"64th\"]\n",
    "}\n",
    "\n",
    "muffliato_attributes = {\n",
    "    \"variant\":[\"muffliato\"],\n",
    "    \"topology_type\":[\"static\"],\n",
    "    \"avgsteps\": [\"10avgsteps\"],\n",
    "    \"noise_level\":[\"32th\",\"64th\"]\n",
    "}\n",
    "current_attributes = [zerosum_attributes,muffliato_attributes]\n",
    "\n",
    "zerosum_experiments = utils.filter_attribute_list(experiments_attributes,current_attributes)\n",
    "for experiment in sorted(zerosum_experiments):\n",
    "    print(experiment)\n",
    "print(\"-\"*40)\n",
    "\n",
    "plt.figure()\n",
    "utils.scatter_all_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Low noises:Accuracy vs AUC-static\",\n",
    "    \"roc_auc mean\",\n",
    "    \"test_acc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS\n",
    ")\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregated plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "zerosum_attributes = {\n",
    "    \"variant\":[\"nonoise\",\"zerosum\"],\n",
    "    \"topology_type\":[\"static\"],\n",
    "    \"avgsteps\": [\"1avgsteps\"], \n",
    "    \"additional_attribute\": [\"nonoise\",\"selfnoise\"],\n",
    "}\n",
    "\n",
    "muffliato_attributes = {\n",
    "    \"variant\":[\"muffliato\"],\n",
    "    \"topology_type\":[\"static\"],\n",
    "    \"avgsteps\": [\"10avgsteps\"],\n",
    "}\n",
    "\n",
    "current_attributes = [zerosum_attributes,muffliato_attributes]\n",
    "\n",
    "display_attributes = {\n",
    "    \"hue\":\"variant\",\n",
    "    \"style\":\"variant\",\n",
    "    \"size\":\"variant\", # For some reason having both style and size breaks in this case.\n",
    "    # \"col\":\"topology_type\",# Cannot have col argument for the lineplot function\n",
    "}\n",
    "zerosum_experiments = utils.filter_attribute_list(experiments_attributes,current_attributes)\n",
    "for experiment in sorted(zerosum_experiments):\n",
    "    print(experiment)\n",
    "\n",
    "\n",
    "utils.scatter_averaged_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Accuracy vs AUC evolution accross entire runs-static topology\",\n",
    "    \"test_acc mean\",\n",
    "    \"roc_auc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "utils.scatter_averaged_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Accuracy vs Linkability attack for the entire run-static topology\",\n",
    "    \"test_acc mean\",\n",
    "    \"linkability_top1 count_percentage_success\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")\n",
    "\n",
    "zerosum_attributes = {\n",
    "    \"variant\":[\"nonoise\",\"zerosum\"],\n",
    "    \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"1avgsteps\"], \n",
    "    \"additional_attribute\": [\"nonoise\",\"selfnoise\"],\n",
    "}\n",
    "\n",
    "muffliato_attributes = {\n",
    "    \"variant\":[\"muffliato\"],\n",
    "    \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"10avgsteps\"],\n",
    "}\n",
    "current_attributes = [zerosum_attributes,muffliato_attributes]\n",
    "zerosum_experiments = utils.filter_attribute_list(experiments_attributes,current_attributes)\n",
    "\n",
    "plt.figure()\n",
    "utils.scatter_averaged_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Accuracy vs AUC evolution accross entire runs-dynamic topology\",\n",
    "    \"test_acc mean\",\n",
    "    \"roc_auc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "utils.scatter_averaged_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Accuracy vs Linkability attack for the entire run-dynamic topology\",\n",
    "    \"test_acc mean\",\n",
    "    \"linkability_top1 count_percentage_success\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same plots, but with the maxes instead!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "x_method = \"max\"\n",
    "y_method = \"max\"\n",
    "\n",
    "zerosum_attributes = {\n",
    "    \"variant\":[\"nonoise\",\"zerosum\"],\n",
    "    \"topology_type\":[\"static\"],\n",
    "    \"avgsteps\": [\"1avgsteps\"], \n",
    "    \"additional_attribute\": [\"nonoise\",\"selfnoise\"],\n",
    "}\n",
    "\n",
    "muffliato_attributes = {\n",
    "    \"variant\":[\"muffliato\"],\n",
    "    \"topology_type\":[\"static\"],\n",
    "    \"avgsteps\": [\"10avgsteps\"],\n",
    "}\n",
    "\n",
    "current_attributes = [zerosum_attributes,muffliato_attributes]\n",
    "\n",
    "display_attributes = {\n",
    "    \"hue\":\"variant\",\n",
    "    \"style\":\"variant\",\n",
    "    \"size\":\"variant\", # For some reason having both style and size breaks in this case.\n",
    "    # \"col\":\"topology_type\",# Cannot have col argument for the lineplot function\n",
    "}\n",
    "zerosum_experiments = utils.filter_attribute_list(experiments_attributes,current_attributes)\n",
    "for experiment in sorted(zerosum_experiments):\n",
    "    print(experiment)\n",
    "\n",
    "\n",
    "utils.scatter_averaged_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Accuracy vs AUC evolution accross entire runs-static topology\",\n",
    "    \"test_acc mean\",\n",
    "    \"roc_auc mean\",\n",
    "    save_directory=save_directory,\n",
    "    y_method=y_method,\n",
    "    x_method=x_method,\n",
    "    orderings=ORDERINGS,\n",
    ")\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "utils.scatter_averaged_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Accuracy vs Linkability attack for the entire run-static topology\",\n",
    "    \"test_acc mean\",\n",
    "    \"linkability_top1 count_percentage_success\",\n",
    "    save_directory=save_directory,\n",
    "    y_method=y_method,\n",
    "    x_method=x_method,\n",
    "    orderings=ORDERINGS,\n",
    ")\n",
    "\n",
    "zerosum_attributes = {\n",
    "    \"variant\":[\"nonoise\",\"zerosum\"],\n",
    "    \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"1avgsteps\"], \n",
    "    \"additional_attribute\": [\"nonoise\",\"selfnoise\"],\n",
    "}\n",
    "\n",
    "muffliato_attributes = {\n",
    "    \"variant\":[\"muffliato\"],\n",
    "    \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"10avgsteps\"],\n",
    "}\n",
    "current_attributes = [zerosum_attributes,muffliato_attributes]\n",
    "zerosum_experiments = utils.filter_attribute_list(experiments_attributes,current_attributes)\n",
    "\n",
    "plt.figure()\n",
    "utils.scatter_averaged_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Accuracy vs AUC evolution accross entire runs-dynamic topology\",\n",
    "    \"test_acc mean\",\n",
    "    \"roc_auc mean\",\n",
    "    save_directory=save_directory,\n",
    "    y_method=y_method,\n",
    "    x_method=x_method,\n",
    "    orderings=ORDERINGS,\n",
    ")\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "utils.scatter_averaged_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Accuracy vs Linkability attack for the entire run-dynamic topology\",\n",
    "    y_axis_name=\"test_acc mean\",\n",
    "    x_axis_name=\"linkability_top1 count_percentage_success\",\n",
    "    save_directory=save_directory,\n",
    "    y_method=y_method,\n",
    "    x_method=x_method,\n",
    "    orderings=ORDERINGS,\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "utils.scatter_averaged_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Accuracy vs Linkability top5 attack for the entire run-dynamic topology\",\n",
    "    y_axis_name=\"test_acc mean\",\n",
    "    x_axis_name=\"linkability_top5 count_percentage_success\",\n",
    "    save_directory=save_directory,\n",
    "    y_method=y_method,\n",
    "    x_method=x_method,\n",
    "    orderings=ORDERINGS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "zerosum_attributes = {\n",
    "    \"variant\":[\"nonoise\"],\n",
    "    \"topology_type\":[\"static\"],\n",
    "    \"avgsteps\": [\"1avgsteps\"],\n",
    "    # \"noise_level\":[None,\"2th\",\"4th\"]\n",
    "}\n",
    "\n",
    "\n",
    "zerosum_experiments = utils.filter_attribute(experiments_attributes,zerosum_attributes)\n",
    "for experiment in sorted(zerosum_experiments):\n",
    "    print(experiment)\n",
    "\n",
    "\n",
    "experiment = zerosum_experiments[0]\n",
    "experiment_data = formatted_data[experiment] \n",
    "\n",
    "sns.set_theme()\n",
    "sns.relplot(data=experiment_data, x=\"roc_auc mean\", y=\"test_acc mean\", hue=\"iteration\")\n",
    "\n",
    "title = \"Evolution of the unnoised test accuracy and AUC-static topology\"\n",
    "plt.title(title)\n",
    "plt.savefig(save_directory + title.replace(\" \",\"_\") +\".pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better experiment display (selected noises levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "zerosum_attributes = {\n",
    "    \"variant\":[\"nonoise\",\"zerosum\"],\n",
    "    # \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"1avgsteps\"], \n",
    "    \"additional_attribute\": [\"nonoise\",\"selfnoise\"],\n",
    "    \"noise_level\":[\"nonoise\",\"4th\"]\n",
    "}\n",
    "\n",
    "muffliato_attributes = {\n",
    "    \"variant\":[\"muffliato\"],\n",
    "    # \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"10avgsteps\"], \n",
    "    \"noise_level\":[\"64th\"]\n",
    "}\n",
    "current_attributes= [zerosum_attributes,muffliato_attributes]\n",
    "\n",
    "display_attributes = {\n",
    "    \"hue\":[\"variant\",\"noise_level\",\"avgsteps\"],\n",
    "    \"style\":[\"variant\",\"noise_level\",\"avgsteps\"],\n",
    "    \"size\":[\"variant\",\"noise_level\",\"avgsteps\"], # For some reason having both style and size breaks in this case.\n",
    "    \"col\":\"topology_type\",\n",
    "}\n",
    "\n",
    "zerosum_experiments = utils.filter_attribute_list(experiments_attributes,current_attributes)\n",
    "for experiment in sorted(zerosum_experiments):\n",
    "    print(experiment)\n",
    "# zerosum_experiments = [zerosum_experiments[i] for i in [0,1,4,5,2,3] ]\n",
    "\n",
    "\n",
    "\n",
    "utils.plot_all_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Selected noise:Accuracy of Zerosum and Muffliato\",\n",
    "    \"test_acc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings = ORDERINGS,\n",
    ")\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "utils.plot_all_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Selected noise:Attack AUC of Zerosum and Muffliato\",\n",
    "    \"roc_auc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings = ORDERINGS,\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "utils.plot_all_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Selected noise:Linkability attack ac of Zerosum and Muffliato\",\n",
    "    \"linkability_top1 count_percentage_success\",\n",
    "    save_directory=save_directory,\n",
    "    orderings = ORDERINGS,\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "#Needs to only have hue since we can't have other attributes in jointplots\n",
    "display_attributes = {\n",
    "    \"hue\":[\"variant\",\"noise_level\",\"avgsteps\"],\n",
    "}\n",
    "\n",
    "zerosum_attributes = {\n",
    "    \"variant\":[\"nonoise\",\"zerosum\"],\n",
    "    \"topology_type\":[\"static\"],\n",
    "    \"avgsteps\": [\"1avgsteps\"], \n",
    "    \"additional_attribute\": [\"nonoise\",\"selfnoise\"],\n",
    "    \"noise_level\":[\"nonoise\",\"4th\"]\n",
    "}\n",
    "\n",
    "muffliato_attributes = {\n",
    "    \"variant\":[\"muffliato\"],\n",
    "    \"topology_type\":[\"static\"],\n",
    "    \"avgsteps\": [\"10avgsteps\"], \n",
    "    \"noise_level\":[\"64th\"]\n",
    "}\n",
    "current_attributes= [zerosum_attributes,muffliato_attributes]\n",
    "\n",
    "zerosum_experiments = utils.filter_attribute_list(experiments_attributes,current_attributes)\n",
    "for experiment in sorted(zerosum_experiments):\n",
    "    print(experiment)\n",
    "print(\"-\"*40)\n",
    "\n",
    "\n",
    "utils.scatter_all_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Selected noise:Accuracy vs AUC-static\",\n",
    "    \"roc_auc mean\",\n",
    "    \"test_acc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")\n",
    "plt.figure()\n",
    "utils.scatter_all_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Selected noise:Accuracy vs Linkability sucess rate-static\",\n",
    "    \"linkability_top1 count_percentage_success\",\n",
    "    \"test_acc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "zerosum_attributes = {\n",
    "    \"variant\":[\"nonoise\",\"zerosum\"],\n",
    "    # \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"1avgsteps\"], \n",
    "    \"additional_attribute\": [\"nonoise\",\"selfnoise\"],\n",
    "    \"noise_level\":[\"nonoise\",\"2th\",\"4th\"]\n",
    "}\n",
    "\n",
    "muffliato_attributes = {\n",
    "    \"variant\":[\"muffliato\"],\n",
    "    # \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"10avgsteps\"], \n",
    "    \"noise_level\":[\"2th\",\"4th\"]\n",
    "}\n",
    "current_attributes= [zerosum_attributes,muffliato_attributes]\n",
    "\n",
    "\n",
    "display_attributes = {\n",
    "    \"hue\":\"noise_level\",\n",
    "    \"style\":\"variant\",\n",
    "    \"size\":\"avgsteps\", # For some reason having both style and size breaks in this case.\n",
    "    \"col\":\"topology_type\",\n",
    "}\n",
    "\n",
    "zerosum_experiments = utils.filter_attribute_list(experiments_attributes,current_attributes)\n",
    "for experiment in sorted(zerosum_experiments):\n",
    "    print(experiment)\n",
    "\n",
    "\n",
    "\n",
    "utils.plot_all_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"High noise:Accuracy of Zerosum and Muffliato with and without self noise-dynamic topology\",\n",
    "    \"test_acc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "utils.plot_all_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"High noise:Linkability attack accuracy of Zerosum and Muffliato with and without self noise-dynamic topology\",\n",
    "    \"linkability_top1 count_percentage_success\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")\n",
    "\n",
    "# Plot the middle noises\n",
    "importlib.reload(utils)\n",
    "zerosum_attributes = {\n",
    "    \"variant\":[\"nonoise\",\"zerosum\"],\n",
    "    # \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"1avgsteps\"], \n",
    "    \"additional_attribute\": [\"nonoise\",\"selfnoise\"],\n",
    "    \"noise_level\":[\"nonoise\",\"8th\",\"16th\"]\n",
    "}\n",
    "\n",
    "muffliato_attributes = {\n",
    "    \"variant\":[\"muffliato\"],\n",
    "    # \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"10avgsteps\"], \n",
    "    \"noise_level\":[\"8th\",\"16th\"]\n",
    "}\n",
    "current_attributes= [zerosum_attributes,muffliato_attributes]\n",
    "zerosum_experiments = utils.filter_attribute_list(experiments_attributes,current_attributes)\n",
    "\n",
    "plt.figure()\n",
    "utils.plot_all_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Middle noise:Accuracy of Zerosum and Muffliato with and without self noise-dynamic topology\",\n",
    "    \"test_acc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "utils.plot_all_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Middle noise:Linkability attack accuracy of Zerosum and Muffliato with and without self noise-dynamic topology\",\n",
    "    \"linkability_top1 count_percentage_success\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")\n",
    "\n",
    "\n",
    "# Plot the low noises\n",
    "importlib.reload(utils)\n",
    "zerosum_attributes = {\n",
    "    \"variant\":[\"nonoise\",\"zerosum\"],\n",
    "    # \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"1avgsteps\"], \n",
    "    \"additional_attribute\": [\"nonoise\",\"selfnoise\"],\n",
    "    \"noise_level\":[\"nonoise\",\"32th\",\"64th\"]\n",
    "}\n",
    "\n",
    "muffliato_attributes = {\n",
    "    \"variant\":[\"muffliato\"],\n",
    "    # \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"10avgsteps\"], \n",
    "    \"noise_level\":[\"32th\",\"64th\"]\n",
    "}\n",
    "current_attributes= [zerosum_attributes,muffliato_attributes]\n",
    "zerosum_experiments = utils.filter_attribute_list(experiments_attributes,current_attributes)\n",
    "\n",
    "plt.figure()\n",
    "utils.plot_all_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Low noise:Accuracy of Zerosum and Muffliato with and without self noise-dynamic topology\",\n",
    "    \"test_acc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "utils.plot_all_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Low noise:Linkability attack accuracy of Zerosum and Muffliato with and without self noise-dynamic topology\",\n",
    "    \"linkability_top1 count_percentage_success\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")\n",
    "plt.ylim(top=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start average trial displays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "zerosum_attributes = {\n",
    "    \"variant\":[\"nonoise\",\"zerosum\"],\n",
    "    # \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"1avgsteps\"], \n",
    "    \"additional_attribute\": [\"nonoise\",\"selfnoise\"],\n",
    "    \"noise_level\":[\"nonoise\",\"4th\"]\n",
    "}\n",
    "\n",
    "muffliato_attributes = {\n",
    "    \"variant\":[\"muffliato\"],\n",
    "    # \"topology_type\":[\"dynamic\"],\n",
    "    \"avgsteps\": [\"10avgsteps\"], \n",
    "    \"noise_level\":[\"64th\"]\n",
    "}\n",
    "current_attributes= [zerosum_attributes,muffliato_attributes]\n",
    "\n",
    "display_attributes = {\n",
    "    \"hue\":[\"variant\",\"noise_level\",\"avgsteps\"],\n",
    "    \"style\":[\"variant\",\"noise_level\",\"avgsteps\"],\n",
    "    \"size\":[\"variant\",\"noise_level\",\"avgsteps\"], # For some reason having both style and size breaks in this case.\n",
    "    \"col\":\"topology_type\",\n",
    "}\n",
    "\n",
    "zerosum_experiments = utils.filter_attribute_list(experiments_attributes,current_attributes)\n",
    "for experiment in sorted(zerosum_experiments):\n",
    "    print(experiment)\n",
    "\n",
    "\n",
    "\n",
    "utils.plot_all_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Selected noise:Accuracy of Zerosum and Muffliato\",\n",
    "    \"test_acc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings = ORDERINGS,\n",
    ")\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "utils.plot_all_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Selected noise:Attack AUC rolling average of Zerosum and Muffliato\",\n",
    "    \"roc_auc mean_start_avg\",\n",
    "    save_directory=save_directory,\n",
    "    orderings = ORDERINGS,\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "utils.plot_all_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Selected noise:Linkability attack rolling average ac of Zerosum and Muffliato\",\n",
    "    \"linkability_top1 count_percentage_success_start_avg\",\n",
    "    save_directory=save_directory,\n",
    "    orderings = ORDERINGS,\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "#Needs to only have hue since we can't have other attributes in jointplots\n",
    "display_attributes = {\n",
    "    \"hue\":[\"variant\",\"noise_level\",\"avgsteps\"],\n",
    "}\n",
    "\n",
    "zerosum_attributes = {\n",
    "    \"variant\":[\"nonoise\",\"zerosum\"],\n",
    "    \"topology_type\":[\"static\"],\n",
    "    \"avgsteps\": [\"1avgsteps\"], \n",
    "    \"additional_attribute\": [\"nonoise\",\"selfnoise\"],\n",
    "    \"noise_level\":[\"nonoise\",\"4th\"]\n",
    "}\n",
    "\n",
    "muffliato_attributes = {\n",
    "    \"variant\":[\"muffliato\"],\n",
    "    \"topology_type\":[\"static\"],\n",
    "    \"avgsteps\": [\"10avgsteps\"], \n",
    "    \"noise_level\":[\"64th\"]\n",
    "}\n",
    "current_attributes= [zerosum_attributes,muffliato_attributes]\n",
    "\n",
    "zerosum_experiments = utils.filter_attribute_list(experiments_attributes,current_attributes)\n",
    "for experiment in sorted(zerosum_experiments):\n",
    "    print(experiment)\n",
    "print(\"-\"*40)\n",
    "\n",
    "\n",
    "utils.scatter_all_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Selected noise:Accuracy vs AUC rolling average-static\",\n",
    "    \"roc_auc mean_start_avg\",\n",
    "    \"test_acc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")\n",
    "plt.figure()\n",
    "utils.scatter_all_experiments(\n",
    "    formatted_data,\n",
    "    zerosum_experiments,\n",
    "    display_attributes,\n",
    "    \"Selected noise:Accuracy vs Linkability sucess rate rolling average-static\",\n",
    "    \"linkability_top1 count_percentage_success_start_avg\",\n",
    "    \"test_acc mean\",\n",
    "    save_directory=save_directory,\n",
    "    orderings=ORDERINGS,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
