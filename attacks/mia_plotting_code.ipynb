{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To show the installation environment. Disabled due to git conflicts when working on 2 machines, should be changed for a minimal working installation.\n",
    "# import sys\n",
    " \n",
    " \n",
    "# print(\"User Current Version:-\", sys.version)\n",
    "# print()\n",
    "# import pkg_resources\n",
    "# installed_packages = pkg_resources.working_set\n",
    "# installed_packages_list = sorted([\"%s==%s\" % (i.key, i.version)\n",
    "#    for i in installed_packages])\n",
    "# for i in installed_packages_list:\n",
    "#     print(i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Privacy results (FILIP):\n",
    "The aim of this part is to reproduce as closely as possible FILIP's results. A perfect reproduction is unlikely given the different machine setup, as I do not know on how many real machine the experiment was performed.\n",
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dynamic data\n",
    "# Craft folder path\n",
    "\n",
    "dynamic_root_dir = 'my_results/2439939_filip_dynamic/'\n",
    "fc_root_dir = 'my_results/2439940_filip_fullyconnected/'\n",
    "static_root_dir = 'my_results/2439941_filip_4regular_dl/'\n",
    "\n",
    "\n",
    "env = \"NIID-full-model-sharing-dynamic\"\n",
    "FILE_NAMES = ['privacy-summary-PRE-STEP.json', 'privacy-summary-POST-STEP.json']\n",
    "location = FILE_NAMES[1]\n",
    "MAX_PROCESSES = 24\n",
    "MAX_MACHINES =  4\n",
    "MAX_ITERATIONS=2500\n",
    "\n",
    "\n",
    "machine_folder = 'machine{}'\n",
    "privacy_folder = 'privacy'\n",
    "summary_folder = 'summary'\n",
    "process_folder = '{}'\n",
    "\n",
    "def load_privacy_data(path_dir):\n",
    "    data = pd.DataFrame({})  \n",
    "\n",
    "    for location in FILE_NAMES:\n",
    "        for machine in range(MAX_MACHINES):\n",
    "            for rank in range(MAX_PROCESSES):\n",
    "                print(f\"Loading {location} for machine {machine} and rank {rank}  \",end = \"\\r\")\n",
    "                file = os.path.join(path_dir, machine_folder.format(machine),privacy_folder, summary_folder, process_folder.format(machine*MAX_PROCESSES+rank), location)\n",
    "                tmp_df = pd.read_json(file)\n",
    "                tmp_df = tmp_df[tmp_df.iteration < MAX_ITERATIONS]\n",
    "                #tmp_df['location_of_attack']= file.split('.')[0]\n",
    "                data = pd.concat([data,tmp_df])\n",
    "    return data\n",
    "\n",
    "\n",
    "# Load data\n",
    "print(f\"Loading dynamic data:\")\n",
    "dynamic_data = load_privacy_data(dynamic_root_dir)\n",
    "print(f\"\\nLoading fully-connected data:\")\n",
    "fc_data = load_privacy_data(fc_root_dir)\n",
    "print(f\"\\nLoading static data:\")\n",
    "static_data = load_privacy_data(static_root_dir)\n",
    "\n",
    "           \n",
    "# Print\n",
    "dynamic_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group by iterations and plot moving min,max,avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define plot attributes\n",
    "fontsize=20\n",
    "linewidth = 5\n",
    "alpha = 0.2\n",
    "figsize = (17,12)\n",
    "\n",
    "\n",
    "metrics = [\"Attacker advantage\",\"AUC\"]\n",
    "metrics = [metrics[0]]\n",
    "window_size = 50\n",
    "linewidth = 3\n",
    "fig,axs = plt.subplots(len(metrics) * 3 ,2,sharey='row',sharex= True, figsize=(figsize[0]*2,figsize[1]*len(metrics)*3))\n",
    "\n",
    "\n",
    "def plot_data(data, label):\n",
    "    # Group by iteration and extracted mean and std\n",
    "    entire_dataset = data[data['slice feature'] == 'Entire dataset']\n",
    "    for ii,metric in enumerate(metrics):\n",
    "        for j,location in enumerate(data.location_of_attack.unique()):\n",
    "            i = 3*ii\n",
    "            print(f\"{metric}, {location}, {i}\")\n",
    "            location_label = \"\".join(location.split('-'))\n",
    "\n",
    "            # Extract relevant data\n",
    "            location_data = entire_dataset[entire_dataset.location_of_attack==location]\n",
    "\n",
    "            # Aggregate\n",
    "            columns = ['iteration', 'Attacker advantage', 'AUC']\n",
    "            averaged = location_data[columns].groupby('iteration').agg([np.max, np.min, np.mean, np.std])\n",
    "            \n",
    "            # Plot\n",
    "            metric_data = averaged[metric].rolling(window=window_size).mean()\n",
    "                        \n",
    "            data_max, data_min = metric_data[\"amax\"], metric_data[\"amin\"]\n",
    "            \n",
    "\n",
    "            axs[i,j].plot(averaged.index, data_min,label=label+'-MIN', linewidth=linewidth)\n",
    "            axs[i,j].set_xlabel('Iteration', fontsize=fontsize)\n",
    "            axs[i,j].set_ylabel(metric, fontsize=fontsize)\n",
    "            axs[i,j].set_title(f\"{env}    |   {location}    |   {metric}    |  comparison    |   Min of each log\")\n",
    "            axs[i,j].tick_params(labelbottom=True,labelleft = True)\n",
    "\n",
    "\n",
    "\n",
    "            axs[i+1,j].plot(averaged.index, data_max,label=label+'-MAX',linewidth=linewidth)\n",
    "            axs[i+1,j].set_title(f\"{env}    |   {location}    |   {metric}    |  comparison    |   Max of each log \")\n",
    "            axs[i+1,j].set_ylabel(metric, fontsize=fontsize)\n",
    "            axs[i+1,j].set_xlabel('Iteration', fontsize=fontsize)\n",
    "            axs[i+1,j].legend(fontsize=fontsize)\n",
    "\n",
    "\n",
    "\n",
    "            mean = metric_data['mean']\n",
    "            std = metric_data['std']\n",
    "            axs[i+2,j].plot(averaged.index, mean ,label= label + \"-MEAN\",linewidth=linewidth*2)\n",
    "            axs[i+2,j].fill_between(averaged.index, mean-2*std, mean+2*std, alpha=alpha)\n",
    "            axs[i+2,j].set_title(f\"{env}    |   {location}    |   {metric}    |  comparison   |   Mean with min-max filled\")\n",
    "            axs[i+2,j].set_ylabel(metric, fontsize=fontsize)\n",
    "            axs[i+2,j].set_xlabel('Iteration', fontsize=fontsize)\n",
    "\n",
    "\n",
    "plot_data(dynamic_data,\"DYNAMIC\")\n",
    "plot_data(fc_data,\"FULLYCONNECTED\")\n",
    "plot_data(static_data,\"STATIC\")\n",
    "\n",
    "        \n",
    "for ii,metric in enumerate(metrics):\n",
    "    for j,location in enumerate(static_data.location_of_attack.unique()):\n",
    "        i = 3*ii\n",
    "        axs[i,j].legend(fontsize=fontsize)\n",
    "        axs[i,j].grid()\n",
    "        axs[i,j].tick_params(labelbottom=True,labelleft = True)\n",
    "        extent = axs[i,j].get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "        # axs[i,j].figure.savefig(f\"NIID-min-{location}-{metric.replace(' ','_')}.jpg\", bbox_inches=extent.expanded(1.2,1.2))\n",
    "        \n",
    "        axs[i+1,j].legend(fontsize=fontsize)\n",
    "        axs[i+1,j].grid()\n",
    "        axs[i+1,j].tick_params(labelbottom=True,labelleft = True)\n",
    "        extent = axs[i+1,j].get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "        # axs[i+1,j].figure.savefig(f\"NIID-max-{location}-{metric.replace(' ','_')}.jpg\", bbox_inches=extent.expanded(1.2,1.2))\n",
    "        \n",
    "        axs[i+2,j].legend(fontsize=fontsize)\n",
    "        axs[i+2,j].grid()\n",
    "        axs[i+2,j].tick_params(labelbottom=True,labelleft = True)\n",
    "        extent = axs[i+2,j].get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "        # axs[i+2,j].figure.savefig(f\"NIID-mean-{location}-{metric.replace(' ','_')}.jpg\", bbox_inches=extent.expanded(1.2,1.2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient profiling\n",
    "\n",
    "## Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Config used : \n",
    "# walltime=\"5:00:00\"\n",
    "# GRAPH_FILE=\"36regular_4degree.edges\"\n",
    "# NB_MACHINE=2\n",
    "# NB_PROC_PER_MACHINE=36//2\n",
    "# NB_ITERATION=3000\n",
    "# EVAL_FILE= [\"testingPeerSampler.py\", \"testingPeerSamplerDynamic.py\"]\n",
    "# TEST_AFTER=5\n",
    "# LOG_LEVEL=\"INFO\"\n",
    "# CONFIG_NAME=\"only_training_gaussiannoise.ini\"\n",
    "# CONFIG_FILE=\"decentralizepy/run_configuration/\"+CONFIG_NAME\n",
    "# cluster = \"paravance\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Load data\n",
    "# Craft folder path\n",
    "\n",
    "gradient_profiling_dir_static = \"my_results/1932209_gradient_profiling_36nodes_static/\"\n",
    "gradient_profiling_dir_dynamic = \"my_results/1932227_gradient_profiling_36nodes_dynamic/\"\n",
    "\n",
    "\n",
    "MAX_PROCESSES = 18\n",
    "MAX_MACHINES =  2\n",
    "MAX_ITERATIONS=3000\n",
    "\n",
    "machine_folder = 'machine{}'\n",
    "result_file = '{}_results.json'\n",
    "\n",
    "\n",
    "# Load data\n",
    "profiling_data_static = pd.DataFrame({})\n",
    "profiling_data_dynamic = pd.DataFrame({})\n",
    "\n",
    "for machine in range(MAX_MACHINES):\n",
    "    for rank in range(MAX_PROCESSES):\n",
    "        print(f\"Loading results for machine {machine} and rank {rank}.  \",end = \"\\r\")\n",
    "\n",
    "        file = os.path.join(gradient_profiling_dir_static, machine_folder.format(machine),result_file.format(rank))\n",
    "        tmp_df = pd.read_json(file)\n",
    "        # print(f\"tmp_df size : {tmp_df.size}. profiling_data size : {profiling_data_static.size}                        \")\n",
    "        profiling_data_static = pd.concat([profiling_data_static,tmp_df])\n",
    "           \n",
    "        file = os.path.join(gradient_profiling_dir_dynamic, machine_folder.format(machine),result_file.format(rank))\n",
    "        tmp_df = pd.read_json(file)\n",
    "        # print(f\"tmp_df size : {tmp_df.size}. profiling_data size : {profiling_data_dynamic.size}                        \")\n",
    "        profiling_data_dynamic = pd.concat([profiling_data_dynamic,tmp_df])\n",
    "\n",
    "# Print\n",
    "# profiling_data_static\n",
    "profiling_data_dynamic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regroup and average the grad_mean and grad_std. The other metrics are logged, but not important here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iteration_result(data):\n",
    "    data_collapsed = data.groupby(level=0)\n",
    "    return data_collapsed.agg({'grad_norm':['mean','std','min','max']})\n",
    "\n",
    "\n",
    "iteration_avg_results_static = get_iteration_result(profiling_data_static)\n",
    "\n",
    "\n",
    "iteration_avg_results_dynamic=get_iteration_result(profiling_data_dynamic)\n",
    "\n",
    "\n",
    "# iteration_avg_results_static\n",
    "iteration_avg_results_dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory=\"assets/\"\n",
    "fig,axs = plt.subplots(2,1,sharex= True,figsize=(15,10))\n",
    "for key,results in {\"Static\": iteration_avg_results_static, \"Dynamic\" : iteration_avg_results_dynamic}.items():\n",
    "    axs[0].plot(results.index,results[\"grad_norm\"][\"mean\"],label=key)\n",
    "    \n",
    "    axs[1].plot(results.index,results[\"grad_norm\"][\"std\"], label = key)\n",
    "\n",
    "axs[0].set_ylabel(\"Average gradient norm\")\n",
    "\n",
    "axs[1].set_ylabel(\"Gradient norm std\")\n",
    "axs[1].set_title(\"Average of gradient standard deviation value accross all processes\")\n",
    "axs[0].set_title(\"Average of gradient norm value accross all processes\")\n",
    "axs[0].tick_params(labelbottom=True,labelleft = True)\n",
    "axs[1].tick_params(labelbottom=True,labelleft = True)\n",
    "axs[1].legend()\n",
    "axs[1].grid()\n",
    "axs[0].legend()\n",
    "axs[0].grid()\n",
    "extent = axs[0].get_tightbbox(fig.canvas.get_renderer()).transformed(fig.dpi_scale_trans.inverted())\n",
    "fig.savefig(f\"{save_directory}/{axs[0].get_title()}\", bbox_inches=extent)\n",
    "\n",
    "extent = axs[1].get_tightbbox(fig.canvas.get_renderer()).transformed(fig.dpi_scale_trans.inverted())\n",
    "fig.savefig(f\"{save_directory}/{axs[1].get_title()}\", bbox_inches=extent)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss visualization functions\n",
    "The aim of these functions will be to make it easier to visualize/compare losses between processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_dir_static = \"my_results/1932209_gradient_profiling_36nodes_static/\"\n",
    "# target_dir_dynamic = \"my_results/1932227_gradient_profiling_36nodes_dynamic/\"\n",
    "\n",
    "# target_dir = {\n",
    "#     \"Static\" : \"my_results/1932690_mia_36nodes_gaussiannoise_static/\",\n",
    "#     \"Dynamic\" : \"my_results/1932691_mia_36nodes_gaussiannoise_dynamic/\" \n",
    "# }\n",
    "# target_dir_static = 'my_results/1933975_training_gaussiannoise/'\n",
    "\n",
    "target_dir = {\n",
    "    # \"No noise\" : \"my_results/1933979_training_unnoised\",\n",
    "    # \"Gaussian /32\" : \"my_results/1933975_training_gaussiannoise_32th\",\n",
    "    # \"Gaussian /16\" : \"my_results/1934049_training_gaussiannoise_16th\",\n",
    "    # \"Gaussian /8\" : \"my_results/1934011_training_gaussiannoise_8th\",\n",
    "    # \"Gaussian /4\" : \"my_results/1934020_training_gaussiannoise_4th\", \n",
    "    # \"ZeroSumNoise /32\" : \"my_results/1933977_training_zerosumnoise_32th\",\n",
    "    # \"ZeroSumNoise /16\" : \"my_results/1934050_training_zerosumnoise_16th/\",\n",
    "    # \"ZeroSumNoise /8\" : \"my_results/1934012_training_zerosumnoise_8th\",\n",
    "    # \"ZeroSumNoise /4\" : \"my_results/1934033_training_zerosumnoise_4th/\",\n",
    "\n",
    "    # \"No noise Dynamix\" : \"my_results/4081377_training_nonoise_dynamic/\",\n",
    "    # \"Gaussian /32 Dynamic\" : \"my_results/4081366_training_gaussiannoise_32th_dynamic/\",\n",
    "    # \"ZeroSumNoise /32 Dynamic\" : \"my_results/4081367_training_zerosumnoise_32th_dynamic/\",\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # \"No noise static\" : \"my_results/1934908_mia_unnoised_static\",\n",
    "    # \"No noise dynamic\" : \"my_results/4088192_mia_unnoised_dynamic/\",\n",
    "    # \"Gaussian /16 static\": \"my_results/1934909_mia_gaussiannoise_static_16th/\",\n",
    "    # \"ZeroSum /16 static\" : \"my_results/1934910_mia_zerosummnoise_static_16th/\",\n",
    "    # \"Gaussian /16 dynamic\" : \"my_results/1934917_mia_gaussiannoise_dynamic_16th/\",\n",
    "    # \"ZeroSum /16 dynamic\" : \"my_results/1934918_mia_zerosumnoise_dynamic_16th/\",\n",
    "\n",
    "\n",
    "    # \"Amnesia no noise Static\" : \"my_results/2395524_mia_unnoised_static_amnesia/\",\n",
    "    # \"Amnesia Gaussian /16 Static\" : \"my_results/2395525_mia_gaussiannoise_static_amnesia_16th\",\n",
    "    # \"Amnesia ZeroSum /16 Static\" : \"my_results/2395526_mia_zerosumnoise_static_amnesia_16th\",\n",
    "\n",
    "    # \"Amnesia no noise Dynamic\" : \"my_results/2395527_mia_unnoised_dynamic_amnesia\",\n",
    "    # \"Amnesia Gaussian /16 Dynamic\" : \"my_results/2395528_mia_gaussiannoise_dynamic_amnesia_16th\",\n",
    "    # \"Amnesia ZeroSum /16 Dynamic\": \"my_results/2395529_mia_zerosumnoise_dynamic_amnesia_16th\"\n",
    "\n",
    "}\n",
    "\n",
    "target_dir = { # The new study, with more logging about noise as well as rectification for zerosum magnitude \n",
    "    \"No noise static\" : \"my_results/1936484_static_unnoised\",\n",
    "    \"No noise dynamic\" : \"my_results/1936488_dynamic_unnoised/\",\n",
    "    \"Gaussian /16 static\": \"my_results/1936483_static_gaussian_16th\",\n",
    "    \"ZeroSum /16 static\" : \"my_results/1936485_static_zerosum_16th/\",\n",
    "    \"Gaussian /16 dynamic\" : \"my_results/1936489_dynamic_gaussian_16th/\",\n",
    "    \"ZeroSum /16 dynamic\" : \"my_results/1936490_dynamic_zerosum_16th/\",\n",
    "}\n",
    "\n",
    "\n",
    "#Needed information about how the folders are organized, can be easily extracted from just the folders.\n",
    "TOTAL_PROCESSES = 36\n",
    "MAX_MACHINES =  3\n",
    "MAX_ITERATIONS=3000\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "assert TOTAL_PROCESSES%MAX_MACHINES == 0\n",
    "MAX_PROCESSES = TOTAL_PROCESSES//MAX_MACHINES\n",
    "\n",
    "machine_folder = 'machine{}'\n",
    "result_file = '{}_results.json'\n",
    "\n",
    "\n",
    "# Load \n",
    "data_dict = {}\n",
    "for key in target_dir:\n",
    "    data_dict[key] = pd.DataFrame({})\n",
    "\n",
    "# data_static = pd.DataFrame({})\n",
    "# data_dynamic = pd.DataFrame({})\n",
    "# data_fc = pd.DataFrame({})\n",
    "\n",
    "for machine in range(MAX_MACHINES):\n",
    "    for rank in range(MAX_PROCESSES):\n",
    "        print(f\"Loading results for machine {machine} and rank {rank}.  \",end = \"\\r\")\n",
    "        uid = rank + machine * MAX_PROCESSES\n",
    "\n",
    "        for (key, dir) in target_dir.items():\n",
    "            file = os.path.join(dir, machine_folder.format(machine), result_file.format(rank))\n",
    "            tmp_df = pd.read_json(file)\n",
    "            tmp_df[\"uid\"] = uid # Manually add the uid for further processing\n",
    "            data_dict[key] = pd.concat([data_dict[key],tmp_df])\n",
    "           \n",
    "        # file = os.path.join(target_dir_dynamic, machine_folder.format(machine), result_file.format(rank))\n",
    "        # tmp_df = pd.read_json(file)\n",
    "        # tmp_df[\"uid\"] = uid # Manually add the uid for further processing\n",
    "        # data_dynamic = pd.concat([data_dynamic,tmp_df])\n",
    "\n",
    "        # file = os.path.join(target_dir_fc, machine_folder.format(machine), result_file.format(rank))\n",
    "        # tmp_df = pd.read_json(file)\n",
    "        # profiling_data_fc = pd.concat([profiling_data_fc,tmp_df])\n",
    "\n",
    "# Print\n",
    "# data_static\n",
    "# data_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the NaN values, and create a group by train_loss / test_loss with all the necessary metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_iteration_result(data):\n",
    "    data_collapsed = data.groupby(level=0)\n",
    "    return data_collapsed.agg({'train_loss':['mean','std','min','max'], \"test_loss\":['mean','std','min','max'], \"test_acc\": ['mean','std','min','max']})\n",
    "\n",
    "aggregated_data_label_dict = {}\n",
    "\n",
    "for label,data in data_dict.items():\n",
    "    print(f\"Handling {label}\")\n",
    "    data = data[[\"uid\",\"train_loss\",\"test_loss\",\"test_acc\"]] # Since we are interested in losses\n",
    "    data = data.dropna()\n",
    "    data_dict[label] = data\n",
    "    data_aggregated = get_iteration_result(data)\n",
    "    aggregated_data_label_dict[label] = data_aggregated\n",
    "\n",
    "\n",
    "\n",
    "# aggregated_data_label_dict[\"Static\"]\n",
    "# data_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check that the number of row is what we expect (`ITERATION_NUMBER//TEST_AFTER`, since measurement are done every `TEST_AFTER` steps)\n",
    "\n",
    "Now, print the individual and global stats:\n",
    "# Individual loss display "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must be user defined, feel free to adjust figsize (limits to the naïve autoscaling performed here)\n",
    "figsize = (10,10)\n",
    "to_display = [0,1,2] # The process uid that will be shown\n",
    "attributes = [\"train_loss\", \"test_loss\", \"test_acc\"]  # The metric we want to evaluate, must be computed in the table\n",
    "alpha = 0.2\n",
    "\n",
    "\n",
    "subplot_dim = (len(to_display),len(attributes))\n",
    "fig,axs = plt.subplots(subplot_dim[0],subplot_dim[1],sharex= True, figsize=(figsize[0]* subplot_dim[0], figsize[1] * subplot_dim[1]))\n",
    "\n",
    "for i,uid in enumerate(to_display):\n",
    "    for j, attribute in enumerate(attributes):\n",
    "        if \"test\" in attribute:\n",
    "            axs[i][j].set_title(f\"{attribute} of process {uid}, evaluated on global test set\")\n",
    "        elif \"train\" in attribute: \n",
    "            axs[i][j].set_title(f\"{attribute} of process {uid}, evaluated on local train set\") \n",
    "        else:\n",
    "            axs[i][j].set_title(f\"{attribute} of {uid}\")\n",
    "        axs[i][j].set_ylabel(f\"{attribute} of process {uid}\")\n",
    "\n",
    "\n",
    "for key,data in data_dict.items(): \n",
    "    for i,uid in enumerate(to_display):\n",
    "        data_to_plot = data[data[\"uid\"] == uid] \n",
    "        for j, attribute in enumerate(attributes):\n",
    "            axs[i][j].plot(data_to_plot.index,data_to_plot[attribute],label=key)\n",
    "\n",
    "for i in range(subplot_dim[0]):\n",
    "    for j in range(subplot_dim[1]):\n",
    "        axs[i][j].legend()\n",
    "        axs[i][j].grid()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global loss display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must be user defined, feel free to adjust figsize (limits to the naïve autoscaling performed here)\n",
    "figsize = (10,10)\n",
    "attributes = [\"train_loss\", \"test_loss\", \"test_acc\"]\n",
    "metrics = [\"mean\", \"std\"]  # The metric we want to evaluate, must be computed in the table\n",
    "alpha = 0.2\n",
    "\n",
    "\n",
    "\n",
    "subplot_dim = (len(attributes),len(metrics))\n",
    "fig,axs = plt.subplots(subplot_dim[0],subplot_dim[1],sharex= True, figsize=(figsize[0]* subplot_dim[0], figsize[1] * subplot_dim[1]))\n",
    "\n",
    "# Loop to set axis and sublpot titles. \n",
    "for i,attribute in enumerate(attributes):\n",
    "    for j, metric in enumerate(metrics):\n",
    "        if \"test\" in attribute:\n",
    "            axs[i][j].set_title(f\"{metric} of {attribute}, evaluated on global test set\")\n",
    "        elif \"train\" in attribute: \n",
    "            axs[i][j].set_title(f\"{metric} of {attribute}, evaluated on local train set\") \n",
    "        else:\n",
    "            axs[i][j].set_title(f\"{metric} of {attribute}\")\n",
    "        axs[i][j].set_ylabel(f\"{attribute} {metric}\")\n",
    "\n",
    "#Plots the data\n",
    "for key,data in aggregated_data_label_dict.items(): \n",
    "    for i, attribute in enumerate(attributes):\n",
    "        for j, metric in enumerate(metrics):\n",
    "            axs[i][j].plot(data.index,data[attribute][metric],label=key)  \n",
    "            if metric==\"mean\": # When displaying the mean, we also display the min and max for each iteration. \n",
    "                axs[i][j].fill_between(data.index, data[attribute][\"min\"], data[attribute][\"max\"], alpha=alpha)\n",
    "   \n",
    "\n",
    "for i in range(subplot_dim[0]):\n",
    "    for j in range(subplot_dim[1]):\n",
    "        axs[i][j].legend()\n",
    "        axs[i][j].grid()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise control:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict[]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian noise experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dynamic data\n",
    "# Craft folder path\n",
    "\n",
    "# static_root_dir = 'my_results/1932690_mia_36nodes_gaussiannoise_static/'\n",
    "# dynamic_root_dir = 'my_results/1932691_mia_36nodes_gaussiannoise_dynamic/'\n",
    "# # fc_root_dir = 'my_results/2439940_filip_fullyconnected/'\n",
    "\n",
    "#target_dir = {\n",
    "    # \"No noise static\" : \"my_results/1934908_mia_unnoised_static\",\n",
    "    # \"No noise dynamic\" : \"my_results/4088192_mia_unnoised_dynamic/\",\n",
    "    # \"Gaussian /16 static\": \"my_results/1934909_mia_gaussiannoise_static_16th/\",\n",
    "    # \"ZeroSum /16 static\" : \"my_results/1934910_mia_zerosummnoise_static_16th/\",\n",
    "    # \"Gaussian /16 dynamic\" : \"my_results/1934917_mia_gaussiannoise_dynamic_16th/\",\n",
    "    # \"ZeroSum /16 dynamic\" : \"my_results/1934918_mia_zerosumnoise_dynamic_16th/\",\n",
    "\n",
    "\n",
    "    # \"Amnesia no noise static\" : \"my_results/2395524_mia_unnoised_static_amnesia/\",\n",
    "    # \"Amnesia Gaussian /16 static\" : \"my_results/2395525_mia_gaussiannoise_static_amnesia_16th\",\n",
    "    # \"Amnesia ZeroSum /16 static\" : \"my_results/2395526_mia_zerosumnoise_static_amnesia_16th\",\n",
    "\n",
    "    # \"Amnesia no noise dynamic\" : \"my_results/2395527_mia_unnoised_dynamic_amnesia\",\n",
    "    # \"Amnesia Gaussian /16 dynamic\" : \"my_results/2395528_mia_gaussiannoise_dynamic_amnesia_16th\",\n",
    "    # \"Amnesia ZeroSum /16 dynamic\": \"my_results/2395529_mia_zerosumnoise_dynamic_amnesia_16th\"\n",
    "\n",
    "#}\n",
    "\n",
    "target_dir = { # The new study, with more logging about noise as well as rectification for zerosum magnitude \n",
    "    \"No noise static\" : \"my_results/1936484_static_unnoised\",\n",
    "    \"No noise dynamic\" : \"my_results/1936488_dynamic_unnoised/\",\n",
    "    \"Gaussian /16 static\": \"my_results/1936483_static_gaussian_16th\",\n",
    "    \"ZeroSum /16 static\" : \"my_results/1936485_static_zerosum_16th/\",\n",
    "    \"Gaussian /16 dynamic\" : \"my_results/1936489_dynamic_gaussian_16th/\",\n",
    "    \"ZeroSum /16 dynamic\" : \"my_results/1936490_dynamic_zerosum_16th/\",\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "env = \"NIID-full-model-sharing-dynamic\"\n",
    "LOCATIONS_OF_ATTACKS = [\"PRE-STEP\", \"POST-STEP\"]\n",
    "TOTAL_PROCESSES = 36\n",
    "MAX_MACHINES =  3\n",
    "MAX_ITERATIONS=3000\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "assert TOTAL_PROCESSES%MAX_MACHINES == 0\n",
    "MAX_PROCESSES = TOTAL_PROCESSES//MAX_MACHINES\n",
    "FILE_NAMES = [f\"privacy-summary-{loc}.json\" for loc in LOCATIONS_OF_ATTACKS]\n",
    "machine_folder = 'machine{}'\n",
    "privacy_folder = 'privacy'\n",
    "summary_folder = 'summary'\n",
    "process_folder = '{}'\n",
    "\n",
    "def load_privacy_data(path_dir):\n",
    "    data = pd.DataFrame({})  \n",
    "\n",
    "    for location in FILE_NAMES:\n",
    "        for machine in range(MAX_MACHINES):\n",
    "            for rank in range(MAX_PROCESSES):\n",
    "                print(f\"Loading {location} for machine {machine} and rank {rank}  \",end = \"\\r\")\n",
    "                file = os.path.join(path_dir, machine_folder.format(machine),privacy_folder, summary_folder, process_folder.format(machine*MAX_PROCESSES+rank), location)\n",
    "                tmp_df = pd.read_json(file)\n",
    "                tmp_df = tmp_df[tmp_df.iteration < MAX_ITERATIONS]\n",
    "                #tmp_df['location_of_attack']= file.split('.')[0]\n",
    "                data = pd.concat([data,tmp_df])\n",
    "    return data\n",
    "\n",
    "data_dict = {}\n",
    "for key,dir in target_dir.items():\n",
    "    print(f\"Loading privacy data at \\\"{dir}\\\"\")\n",
    "    data_dict[key] = load_privacy_data(dir)\n",
    "\n",
    "# # Load data\n",
    "# print(f\"Loading dynamic data:\\t\\t\")\n",
    "# dynamic_data = load_privacy_data(dynamic_root_dir)\n",
    "# print(f\"Loading static data:\\t\\t\")\n",
    "# static_data = load_privacy_data(static_root_dir)\n",
    "# # print(f\"Loading fully-connected data:\\t\\t\")\n",
    "# # fc_data = load_privacy_data(fc_root_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define plot attributes\n",
    "fontsize=20\n",
    "linewidth = 5\n",
    "alpha = 0.1\n",
    "figsize = (17,12)\n",
    "\n",
    "\n",
    "metrics = [\"Attacker advantage\",\"AUC\"]\n",
    "metrics = [metrics[0]]\n",
    "window_size = 50\n",
    "linewidth = 3\n",
    "fig,axs = plt.subplots(len(metrics) * 3 ,2,sharey='row',sharex= True, figsize=(figsize[0]*2,figsize[1]*len(metrics)*3))\n",
    "\n",
    "\n",
    "def plot_data(data, label):\n",
    "    # Group by iteration and extracted mean and std\n",
    "    line_style = '-'\n",
    "    if \"Amnesia\" in label:\n",
    "        line_style =  \"--\"\n",
    "    entire_dataset = data[data['slice feature'] == 'Entire dataset']\n",
    "    for ii,metric in enumerate(metrics):\n",
    "        for j,location in enumerate(data.location_of_attack.unique()):\n",
    "            i = 3*ii\n",
    "            print(f\"{metric}, {location}, {i}\")\n",
    "            location_label = \"\".join(location.split('-'))\n",
    "\n",
    "            # Extract relevant data\n",
    "            location_data = entire_dataset[entire_dataset.location_of_attack==location]\n",
    "\n",
    "            # Aggregate\n",
    "            columns = ['iteration', 'Attacker advantage', 'AUC']\n",
    "            averaged = location_data[columns].groupby('iteration').agg([np.max, np.min, np.mean, np.std])\n",
    "            \n",
    "            # Plot\n",
    "            metric_data = averaged[metric].rolling(window=window_size).mean()\n",
    "                        \n",
    "            data_max, data_min = metric_data[\"amax\"], metric_data[\"amin\"]\n",
    "            \n",
    "\n",
    "            axs[i,j].plot(averaged.index, data_min, line_style, label=label+'-MIN', linewidth=linewidth)\n",
    "            axs[i,j].set_xlabel('Iteration', fontsize=fontsize)\n",
    "            axs[i,j].set_ylabel(metric, fontsize=fontsize)\n",
    "            axs[i,j].set_title(f\"{env}    |   {location}    |   {metric}    |  comparison    |   Min of each log\")\n",
    "            axs[i,j].tick_params(labelbottom=True,labelleft = True)\n",
    "\n",
    "\n",
    "            axs[i+1,j].plot(averaged.index, data_max, line_style,label=label+'-MAX',linewidth=linewidth)\n",
    "            axs[i+1,j].set_title(f\"{env}    |   {location}    |   {metric}    |  comparison    |   Max of each log \")\n",
    "            axs[i+1,j].set_ylabel(metric, fontsize=fontsize)\n",
    "            axs[i+1,j].set_xlabel('Iteration', fontsize=fontsize)\n",
    "            axs[i+1,j].legend(fontsize=fontsize)\n",
    "\n",
    "\n",
    "            mean = metric_data['mean']\n",
    "            std = metric_data['std']\n",
    "            axs[i+2,j].plot(averaged.index, mean, line_style, label= label + \"-MEAN\",linewidth=linewidth*2)\n",
    "            axs[i+2,j].fill_between(averaged.index, mean-2*std, mean+2*std, alpha=alpha)\n",
    "            axs[i+2,j].set_title(f\"{env}    |   {location}    |   {metric}    |  comparison   |   Mean with min-max filled\")\n",
    "            axs[i+2,j].set_ylabel(metric, fontsize=fontsize)\n",
    "            axs[i+2,j].set_xlabel('Iteration', fontsize=fontsize)\n",
    "            \n",
    "for key,data in data_dict.items(): \n",
    "    plot_data(data,key)    \n",
    "# plot_data(dynamic_data,\"DYNAMIC\")\n",
    "# plot_data(fc_data,\"FULLYCONNECTED\")\n",
    "# plot_data(static_data,\"STATIC\")\n",
    "\n",
    "        \n",
    "for ii,metric in enumerate(metrics):\n",
    "    for j,location in enumerate(LOCATIONS_OF_ATTACKS):\n",
    "        i = 3*ii\n",
    "        axs[i,j].legend(fontsize=fontsize)\n",
    "        axs[i,j].tick_params(labelbottom=True,labelleft = True)\n",
    "        extent = axs[i,j].get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "        axs[i,j].grid()\n",
    "        # axs[i,j].figure.savefig(f\"NIID-min-{location}-{metric.replace(' ','_')}.jpg\", bbox_inches=extent.expanded(1.2,1.2))\n",
    "        \n",
    "        axs[i+1,j].legend(fontsize=fontsize)\n",
    "        axs[i+1,j].tick_params(labelbottom=True,labelleft = True)\n",
    "        extent = axs[i+1,j].get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "        axs[i+1,j].grid()\n",
    "        # axs[i+1,j].figure.savefig(f\"NIID-max-{location}-{metric.replace(' ','_')}.jpg\", bbox_inches=extent.expanded(1.2,1.2))\n",
    "\n",
    "        axs[i+2,j].legend(fontsize=fontsize)\n",
    "        axs[i+2,j].tick_params(labelbottom=True,labelleft = True)\n",
    "        extent = axs[i+2,j].get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "        axs[i+2,j].grid()\n",
    "        # axs[i+2,j].figure.savefig(f\"NIID-mean-{location}-{metric.replace(' ','_')}.jpg\", bbox_inches=extent.expanded(1.2,1.2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
