{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7494bd05",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "This notebook is a new version, that will work on more logged data. The old one is kept for retrocompatibility reasons.\n",
    "\n",
    "## Data definition and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f609dabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# TOTAL_PROCESSES = 36\n",
    "# MAX_MACHINES =  3\n",
    "# STARTING_ITERATION = 0\n",
    "# MAX_ITERATIONS=4000\n",
    "\n",
    "# results_path = \"formatted_results/36nodes\"\n",
    "# save_directory = \"assets/36nodes\"\n",
    "\n",
    "\n",
    "# TOTAL_PROCESSES = 128\n",
    "# MAX_MACHINES =  8\n",
    "# STARTING_ITERATION = 0\n",
    "# MAX_ITERATIONS=4000\n",
    "\n",
    "# results_path = \"formatted_results/128nodes\"\n",
    "# save_directory = \"assets/128nodes\"\n",
    "\n",
    "\n",
    "TOTAL_PROCESSES = 128\n",
    "MAX_MACHINES =  8\n",
    "STARTING_ITERATION = 0\n",
    "MAX_ITERATIONS=4000\n",
    "\n",
    "results_path = \"formatted_results/femnist/128nodes_CNN\"\n",
    "save_directory = \"assets/femnist/128nodes_CNN\"\n",
    "\n",
    "dirlist = os.listdir(results_path)\n",
    "print(dirlist)\n",
    "\n",
    "def get_noise(key):\n",
    "    r = re.findall(r'\\d+', key)\n",
    "    if len(r) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return int(r[0])\n",
    "\n",
    "dirlist.sort(key = lambda x: 1 if \"dynamic\" in x else 0)\n",
    "dirlist.sort(key = lambda x: 2 if \"ZeroSum\" in x else 1 if \"Gaussian\" in x else 0)\n",
    "dirlist.sort(key = lambda x: get_noise(x))\n",
    "print(dirlist)\n",
    "\n",
    "global_data = {}\n",
    "for filename in dirlist:\n",
    "    key = filename.split('.')[0]\n",
    "    global_data[key] = pd.read_csv(f\"{results_path}/{filename}\")\n",
    "\n",
    "linestyles = {\n",
    "    \"ZeroSum\" : \"--\"\n",
    "}\n",
    "\n",
    "fontsize=20\n",
    "\n",
    "alpha = 0.1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5431eb9a",
   "metadata": {},
   "source": [
    "# Global loss display:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717d7fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must be user defined, feel free to adjust figsize (limits to the na√Øve autoscaling performed here)\n",
    "figsize = (25,10)\n",
    "alpha = 0.1\n",
    "\n",
    "attributes = [\"test_acc\",\"test_niid_acc\"]\n",
    "\n",
    "metrics = [\"mean\"]  # The metric we want to evaluate, must be computed in the table\n",
    "\n",
    "to_plot = [ \n",
    "    \"No_noise_static\",\n",
    "    # \"No_noise_dynamic\",\n",
    "\n",
    "    # \"Muffliato64_static_10steps\",\n",
    "    # \"Muffliato64_dynamic_10steps\",\n",
    "\n",
    "    # \"Muffliato32_static_10steps\",\n",
    "    # \"Muffliato32_dynamic_10steps\",\n",
    "\n",
    "    # \"Muffliato16_static_10steps\",\n",
    "    # \"Muffliato16_dynamic_10steps\",\n",
    "\n",
    "    # \"Muffliato8_static_10steps\",\n",
    "    # \"Muffliato8_dynamic_10steps\",\n",
    "\n",
    "    \"Muffliato4_static_10steps\",\n",
    "    # \"Muffliato4_dynamic_10steps\",\n",
    "\n",
    "    # \"Muffliato2_static_10steps\",\n",
    "    # \"Muffliato2_dynamic_10steps\",\n",
    "\n",
    "    # \"Gaussian64_static\",\n",
    "    # \"Gaussian64_dynamic\",\n",
    "\n",
    "    # \"Gaussian32_static\",\n",
    "    # \"Gaussian32_dynamic\",\n",
    "\n",
    "    # \"Gaussian16_static\",\n",
    "    # \"Gaussian16_dynamic\",\n",
    "\n",
    "    # \"Gaussian8_static\",\n",
    "    # \"Gaussian8_dynamic\",\n",
    "\n",
    "    # \"Gaussian4_static\",\n",
    "    # \"Gaussian4_dynamic\",\n",
    "\n",
    "    # \"Gaussian2_static\",\n",
    "    # \"Gaussian2_dynamic\",\n",
    "\n",
    "    # \"ZeroSum64_static\",\n",
    "    # \"ZeroSum64_dynamic\",\n",
    "\n",
    "    # \"ZeroSum32_static\",\n",
    "    # \"ZeroSum32_dynamic\",\n",
    "    \n",
    "    # \"ZeroSum16_static\",\n",
    "    # \"ZeroSum16_dynamic\",\n",
    "    \n",
    "    # \"ZeroSum8_static\",\n",
    "    # \"ZeroSum8_dynamic\",\n",
    "    \n",
    "    \"ZeroSum4_static\",\n",
    "    # \"ZeroSum4_dynamic\"\n",
    "\n",
    "    # \"ZeroSum2_static\",\n",
    "    # \"ZeroSum2_dynamic\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "subplot_dim = (len(attributes),len(metrics))\n",
    "fig,axs = plt.subplots(subplot_dim[0],subplot_dim[1],sharex= True, figsize=figsize)\n",
    "\n",
    "if subplot_dim[1] ==1:\n",
    "    axs = [[ax] for ax in axs]\n",
    "# Loop to set axis and sublpot titles. \n",
    "for i,attribute in enumerate(attributes):\n",
    "    for j, metric in enumerate(metrics):\n",
    "        if \"test\" in attribute:\n",
    "            axs[i][j].set_title(f\"{metric} of {attribute}, evaluated on global test set\",fontsize=fontsize)\n",
    "        elif \"train\" in attribute: \n",
    "            axs[i][j].set_title(f\"{metric} of {attribute}, evaluated on local train set\",fontsize=fontsize) \n",
    "        else:\n",
    "            axs[i][j].set_title(f\"{metric} of {attribute}\",fontsize=fontsize)\n",
    "        axs[i][j].set_xlabel(f\"Communication rounds\",fontsize=fontsize)\n",
    "        axs[i][j].set_ylabel(f\"{attribute} {metric}\",fontsize=fontsize)\n",
    "\n",
    "#Plots the data\n",
    "for key in to_plot:\n",
    "    data = global_data[key] \n",
    "    for i, attribute in enumerate(attributes):\n",
    "        for j, metric in enumerate(metrics):\n",
    "            line = \"-\"\n",
    "            for substring,linestyle in linestyles.items():\n",
    "                if substring in key:\n",
    "                    line = linestyle\n",
    "            no_nan_data = data[[\"iteration\",f\"{attribute} {metric}\",f\"{attribute} lower confidence\", f\"{attribute} upper confidence\"]].dropna()\n",
    "            axs[i][j].plot(no_nan_data[\"iteration\"],no_nan_data[f\"{attribute} {metric}\"],line,label=key)  \n",
    "            if metric==\"mean\": # When displaying the mean, we also display the min and max for each iteration. \n",
    "                # min_data = no_nan_data[f\"{attribute} {metric}\"] - 1.96*data[f\"{attribute} std\"].dropna()\n",
    "                # max_data = no_nan_data[f\"{attribute} {metric}\"] + 1.96*data[f\"{attribute} std\"].dropna()\n",
    "                axs[i][j].fill_between(no_nan_data[\"iteration\"], no_nan_data[f\"{attribute} lower confidence\"], no_nan_data[f\"{attribute} upper confidence\"], alpha=alpha)\n",
    "   \n",
    "for i in range(subplot_dim[0]):\n",
    "    for j in range(subplot_dim[1]):\n",
    "        axs[i][j].legend(ncol=3,fontsize=3*fontsize/4)\n",
    "        axs[i][j].grid()\n",
    "        axs[i][j].tick_params(labelbottom=True,labelleft = True,axis=\"both\", labelsize=fontsize) \n",
    "\n",
    "fig.tight_layout()\n",
    "for i in range(subplot_dim[0]):\n",
    "    for j in range(subplot_dim[1]):\n",
    "        extent = axs[i][j].get_tightbbox(fig.canvas.get_renderer()).transformed(fig.dpi_scale_trans.inverted())\n",
    "        fig.savefig(f\"{save_directory}/{axs[i][j].get_title()}.pdf\", bbox_inches=extent)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0236017",
   "metadata": {},
   "source": [
    "## Privacy attack display:\n",
    "\n",
    "The relevant data must have been loaded by now, into `privacy_data_dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d6900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"Attacker advantage\",\"AUC\"]\n",
    "metrics = [metrics[0]]\n",
    "figsize = (15,15)\n",
    "LOCATIONS_OF_ATTACKS = [\"PRE-STEP\", \"PRE-STEP-niid\"] # The one we want to show here\n",
    "window_size = 10\n",
    "alpha=0.1\n",
    "to_plot = [ \n",
    "    \"No_noise_static\",\n",
    "    # \"No_noise_dynamic\",\n",
    "\n",
    "    # \"Muffliato64_static_10steps\",\n",
    "    # \"Muffliato64_dynamic_10steps\",\n",
    "\n",
    "    # \"Muffliato32_static_10steps\",\n",
    "    # \"Muffliato32_dynamic_10steps\",\n",
    "\n",
    "    # \"Muffliato16_static_10steps\",\n",
    "    # \"Muffliato16_dynamic_10steps\",\n",
    "\n",
    "    # \"Muffliato8_static_10steps\",\n",
    "    # \"Muffliato8_dynamic_10steps\",\n",
    "\n",
    "    # \"Muffliato4_static_10steps\",\n",
    "    # \"Muffliato4_dynamic_10steps\",\n",
    "\n",
    "    # \"Muffliato2_static_10steps\",\n",
    "    # \"Muffliato2_dynamic_10steps\",\n",
    "\n",
    "    # \"Gaussian64_static\",\n",
    "    # \"Gaussian64_dynamic\",\n",
    "\n",
    "    # \"Gaussian32_static\",\n",
    "    # \"Gaussian32_dynamic\",\n",
    "\n",
    "    # \"Gaussian16_static\",\n",
    "    # \"Gaussian16_dynamic\",\n",
    "\n",
    "    # \"Gaussian8_static\",\n",
    "    # \"Gaussian8_dynamic\",\n",
    "\n",
    "    # \"Gaussian4_static\",\n",
    "    # \"Gaussian4_dynamic\",\n",
    "\n",
    "    # \"Gaussian2_static\",\n",
    "    # \"Gaussian2_dynamic\",\n",
    "\n",
    "    \"ZeroSum64_static\",\n",
    "    # \"ZeroSum64_dynamic\",\n",
    "\n",
    "    # \"ZeroSum32_static\",\n",
    "    # \"ZeroSum32_dynamic\",\n",
    "    \n",
    "    \"ZeroSum16_static\",\n",
    "    # \"ZeroSum16_dynamic\",\n",
    "    \n",
    "    # \"ZeroSum8_static\",\n",
    "    # \"ZeroSum8_dynamic\",\n",
    "    \n",
    "    \"ZeroSum4_static\",\n",
    "    # \"ZeroSum4_dynamic\"\n",
    "\n",
    "    # \"ZeroSum2_static\",\n",
    "    # \"ZeroSum2_dynamic\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "linewidth = 3\n",
    "\n",
    "\n",
    "def plot_privacy_data(to_plot,LOCATIONS_OF_ATTACKS):\n",
    "    fig,axs = plt.subplots(len(metrics),2,sharey=False,sharex= True, figsize=(figsize[0]*2,figsize[1]*len(metrics)))\n",
    "\n",
    "    if len(metrics) ==1:\n",
    "        axs = [axs]\n",
    "    # Group by iteration and extracted mean and std\n",
    "    for label in to_plot: \n",
    "        data = global_data[label]\n",
    "        line_style = '-'\n",
    "        for key,line in linestyles.items():\n",
    "            if key in label:\n",
    "                line_style =  line\n",
    "        # entire_dataset = data[data['slice feature'] == 'Entire dataset']\n",
    "        for i,metric in enumerate(metrics):\n",
    "            for j,location in enumerate(LOCATIONS_OF_ATTACKS):\n",
    "                complementary_name = \"\"\n",
    "                if \"niid\" in location:\n",
    "                    complementary_name = \" NIID\"\n",
    "                location_label = \"\".join(location.split('-'))\n",
    "                \n",
    "                # Plot\n",
    "                mean = data[f\"{metric} mean {location}\"].rolling(window=window_size).mean()\n",
    "                # print(metric_data)\n",
    "                \n",
    "                # data_max, data_min = metric_data[\"amax\"], metric_data[\"amin\"]\n",
    "\n",
    "                # mean = metric_data['mean']\n",
    "                # std = metric_data['std']\n",
    "                axs[i][j].plot(data[\"iteration\"], mean, line_style, label= label + \"-MEAN\",linewidth=linewidth*2)\n",
    "                # axs[i][j].fill_between(averaged.index, mean-2*std, mean + 2*std, alpha=alpha)\n",
    "                axs[i][j].set_title(f\"Evolution of the {metric} | {location} | Window : {window_size}\",fontsize=fontsize)\n",
    "                axs[i][j].set_ylabel(metric+complementary_name, fontsize=fontsize)\n",
    "                axs[i][j].set_xlabel('Communication rounds', fontsize=fontsize)\n",
    "                \n",
    "    for i,metric in enumerate(metrics):\n",
    "        for j,location in enumerate(LOCATIONS_OF_ATTACKS):\n",
    "            axs[i][j].legend(fontsize=fontsize,ncol=2)\n",
    "            axs[i][j].tick_params(labelbottom=True,labelleft = True)\n",
    "            axs[i][j].tick_params(axis=\"both\", labelsize=fontsize) \n",
    "            axs[i][j].grid()\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    for i,metric in enumerate(metrics):\n",
    "        for j,location in enumerate(LOCATIONS_OF_ATTACKS):\n",
    "            extent = axs[i][j].get_tightbbox(fig.canvas.get_renderer()).transformed(fig.dpi_scale_trans.inverted())\n",
    "            fig.savefig(f\"{save_directory}/{axs[i][j].get_title()}.pdf\", bbox_inches=extent)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "plot_privacy_data(to_plot,LOCATIONS_OF_ATTACKS)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "12ab49a8",
   "metadata": {},
   "source": [
    "## Tentative d'affichage loss/privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42314969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attributes = [\"train_loss\", \"test_loss\",\"test_acc\",\"test_niid_loss\",\"test_niid_acc\"]\n",
    "attributes = [\"test_acc mean\",\"test_niid_acc mean\"]\n",
    "figsize = (10,10)\n",
    "point_size = 30\n",
    "\n",
    "to_plot = [ \n",
    "    \"No_noise_static\",\n",
    "    # \"No_noise_dynamic\",\n",
    "\n",
    "    # \"Gaussian64_static\",\n",
    "    # \"Gaussian64_dynamic\",\n",
    "\n",
    "    # \"Gaussian32_static\",\n",
    "    # \"Gaussian32_dynamic\",\n",
    "\n",
    "    # \"Gaussian16_static\",\n",
    "    # \"Gaussian16_dynamic\",\n",
    "\n",
    "    # \"Gaussian8_static\",\n",
    "    # \"Gaussian8_dynamic\",\n",
    "\n",
    "    # \"Gaussian4_static\",\n",
    "    # \"Gaussian4_dynamic\",\n",
    "\n",
    "    # \"Gaussian2_static\",\n",
    "    # \"Gaussian2_dynamic\",\n",
    "\n",
    "    # \"ZeroSum64_static\",\n",
    "    # \"ZeroSum64_dynamic\",\n",
    "\n",
    "    \"ZeroSum32_static\",\n",
    "    # \"ZeroSum32_dynamic\",\n",
    "    \n",
    "    # \"ZeroSum16_static\",\n",
    "    # \"ZeroSum16_dynamic\",\n",
    "    \n",
    "    # \"ZeroSum8_static\",\n",
    "    # \"ZeroSum8_dynamic\",\n",
    "    \n",
    "    # \"ZeroSum4_static\",\n",
    "    # \"ZeroSum4_dynamic\"\n",
    "\n",
    "    # \"ZeroSum2_static\",\n",
    "    # \"ZeroSum2_dynamic\",\n",
    "\n",
    "    # \"Muffliato64_static_10steps\",\n",
    "    # \"Muffliato64_dynamic_10steps\",\n",
    "\n",
    "    \"Muffliato32_static_10steps\",\n",
    "    # \"Muffliato32_dynamic_10steps\",\n",
    "\n",
    "    # \"Muffliato16_static_10steps\",\n",
    "    # \"Muffliato16_dynamic_10steps\",\n",
    "\n",
    "    # \"Muffliato8_static_10steps\",\n",
    "    # \"Muffliato8_dynamic_10steps\",\n",
    "\n",
    "    # \"Muffliato4_static_10steps\",\n",
    "    # \"Muffliato4_dynamic_10steps\",\n",
    "\n",
    "    # \"Muffliato2_static_10steps\",\n",
    "    # \"Muffliato2_dynamic_10steps\",\n",
    "]\n",
    "\n",
    "min_iteration = 3000\n",
    "max_iteration = 4000\n",
    "\n",
    "shapes = {\n",
    "    (\"No_noise\",): (\"o\", \"No noise\"),\n",
    "    (\"64\",) : (\"1\",\"œÉ/64\"),\n",
    "    (\"32\",): (\"*\",\"œÉ/32\"),\n",
    "    (\"16\",): (\"D\",\"œÉ/16\"),\n",
    "    (\"8\",): (\"X\",\"œÉ/8\"),\n",
    "    (\"4\",): (\"^\",\"œÉ/4\"),\n",
    "    (\"2\",): (\"s\",\"œÉ/2\")\n",
    "}\n",
    "\n",
    "color_groups = {\n",
    "    # (\"Gaussian\",\"static\"): \"blue\",\n",
    "    # (\"Gaussian\",\"dynamic\") : \"cyan\",\n",
    "    (\"ZeroSum\",\"static\"): \"red\",\n",
    "    # (\"ZeroSum\",\"dynamic\"): \"orange\",\n",
    "    (\"Muffliato\",\"static\"): \"violet\",\n",
    "    # (\"Muffliato\",\"dynamic\"): \"pink\",\n",
    "    (\"No_noise_static\"):\"darkgreen\",\n",
    "    # (\"No_noise_dynamic\") :\"limegreen\",\n",
    "}\n",
    "\n",
    "\n",
    "locations = [\"PRE-STEP\", \"POST-STEP\", \"PRE-STEP-niid\", \"POST-STEP-niid\"]\n",
    "# locations = [\"PRE-STEP\"]\n",
    "\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "def clip_iterations_bounds(data,min_iteration,max_iteration):\n",
    "    if \"iteration\" in data.columns:\n",
    "        tmp_df= data[data[\"iteration\"] <= max_iteration]\n",
    "        tmp_df = tmp_df[tmp_df[\"iteration\"] >= min_iteration]\n",
    "\n",
    "        return tmp_df \n",
    "    else:\n",
    "\n",
    "        print(data.columns)\n",
    "        print(data)\n",
    "        raise KeyError(f\"`iteration` key not in the dataframe column, probably missing a reset_index\")\n",
    "\n",
    "def find_discriminator(key,shapes):\n",
    "    # print(shapes)\n",
    "    if shapes is not None:\n",
    "        for shape_discriminator,shape in shapes.items():\n",
    "            all_attributes_in = True\n",
    "            for attribute in shape_discriminator: #All the attributes of the discriminator must be matched in the name we want to display. \n",
    "                if attribute not in key:\n",
    "                    all_attributes_in = False\n",
    "                    break\n",
    "            if all_attributes_in:\n",
    "                # print(f\"{key} matched by {shape_discriminator}\")\n",
    "                return shape_discriminator\n",
    "    print(f\"RETURNED NONE on {key}\")\n",
    "    return None\n",
    "\n",
    "def format_attribute(attr):\n",
    "    if type(attr) != tuple:\n",
    "        return attr\n",
    "    for i,attribute in enumerate(attr):\n",
    "        if i != 0:\n",
    "            formatted += \" + \" + attribute\n",
    "        else:\n",
    "            formatted = attribute\n",
    "    return formatted\n",
    "\n",
    "def get_custom_legend(shapes,color_groups):\n",
    "    custom_legend = []\n",
    "    for label, shape in shapes.items():\n",
    "        formatted_label = format_attribute(shape[1])\n",
    "        custom_legend.append(Line2D([0], [0], marker=shape[0], linewidth=0,color='blue', label=formatted_label, markersize=15))\n",
    "    \n",
    "    for label,color in color_groups.items():\n",
    "        formatted_label = format_attribute(label)\n",
    "        custom_legend.append(Line2D([0], [0], marker=\".\", color=color, lw=4, label=formatted_label))\n",
    "    return custom_legend\n",
    "\n",
    "def plot_privacyvsloss(to_plot, locations = [\"PRE-STEP\", \"POST-STEP\"], display_type = \"all\" ,shapes = None,\\\n",
    "                        min_iteration=STARTING_ITERATION, max_iteration=MAX_ITERATIONS):\n",
    "    subplot_dim = (len(attributes), len(locations))\n",
    "    fig,axs = plt.subplots(subplot_dim[0], subplot_dim[1],sharey=False,sharex= False, figsize=(figsize[1]* subplot_dim[0], figsize[0] * subplot_dim[1]))\n",
    "    \n",
    "    for i,attribute in enumerate(attributes):\n",
    "        for j,location in enumerate(locations):\n",
    "            legend_elements=None\n",
    "            if display_type==\"center\":\n",
    "                legend_elements = get_custom_legend(shapes,color_groups)\n",
    "           \n",
    "            axs[i][j].set_xlabel(attribute,fontsize=fontsize*2/3)\n",
    "            suffix = \"IID\"\n",
    "            if \"niid\" in location: \n",
    "                suffix = \"NIID\"\n",
    "            axs[i][j].set_ylabel(f\"Attacker advantage {suffix}\",fontsize=fontsize*2/3)\n",
    "            if display_type == \"all\":\n",
    "                axs[i][j].set_title(f\"Attacker advantage vs {attribute} at {location}, iterations {min_iteration}-{max_iteration}\",fontsize=fontsize*2/3)\n",
    "            elif display_type == \"center\":\n",
    "                points_history = {}\n",
    "                for shape_key in color_groups.keys():\n",
    "                    points_history[shape_key] = []\n",
    "                axs[i][j].set_title(f\"Centroid of attacker advantage vs {attribute} at {location}, iterations {min_iteration}-{max_iteration}\",fontsize=fontsize*2/3)\n",
    "            for key in to_plot:\n",
    "                x_axis = attribute\n",
    "                y_axis= f\"Attacker advantage mean {location}\"\n",
    "\n",
    "                data = global_data[key]\n",
    "                data = clip_iterations_bounds(data,min_iteration=min_iteration,max_iteration=max_iteration)\n",
    "\n",
    "                data = data[[\"iteration\",x_axis,y_axis]]\n",
    "                \n",
    "                # x_axis, averaged = get_scatterplot(data,privacy_data,attribute,min_iteration,max_iteration)\n",
    "\n",
    "                shape_discriminator = find_discriminator(key,shapes)\n",
    "                marker = None\n",
    "                if shape_discriminator is not None:\n",
    "                    marker = shapes[shape_discriminator][0]\n",
    "\n",
    "                color_discriminator = find_discriminator(key,color_groups)\n",
    "                color = color_groups[color_discriminator]\n",
    "\n",
    "                if display_type == \"all\":\n",
    "                    axs[i][j].scatter(data[x_axis],data[y_axis], s= point_size,marker = marker, color=color, label = key)\n",
    "                elif display_type == \"center\":\n",
    "\n",
    "                    # axs[i][j].scatter(x_axis,privacy_data, s= point_size,marker = marker, color='w', alpha=0)\n",
    "                    axs[i][j].scatter(data[x_axis],data[y_axis], s= point_size,marker = marker,color = color,alpha=0)\n",
    "                    x_value = np.mean(data[x_axis])\n",
    "                    y_value = data[y_axis].mean(axis=0)\n",
    "\n",
    "\n",
    "                    if color_discriminator is not None:\n",
    "                        points_history[color_discriminator].append((x_value,y_value))\n",
    "                    axs[i][j].scatter(x_value,y_value, s= point_size * 10,marker = marker, color = color, label = key)\n",
    "\n",
    "            if display_type == \"center\":\n",
    "                for key, coordinates in points_history.items():\n",
    "                    if len(coordinates)>1: #To discard the unnoised baselines.\n",
    "                        formatted_label = format_attribute(key)\n",
    "                        p1, = axs[i][j].plot([x[0] for x in coordinates],[x[1] for x in coordinates],label = formatted_label,color=color_groups[key])\n",
    "                        # legend_elements.append(p1)\n",
    "            axs[i][j].legend(fontsize=fontsize*2/3,ncol=3,handles=legend_elements)\n",
    "\n",
    "    for ax_list in axs:\n",
    "        for ax in ax_list:\n",
    "            ax.tick_params(labelbottom=True,labelleft = True,axis=\"both\", labelsize=2*fontsize/3)\n",
    "            ax.grid()\n",
    "    fig.tight_layout()\n",
    "    for ax_list in axs:\n",
    "        for ax in ax_list:\n",
    "            extent = ax.get_tightbbox(fig.canvas.get_renderer()).transformed(fig.dpi_scale_trans.inverted())\n",
    "            fig.savefig(f\"{save_directory}/{ax.get_title()}.pdf\", bbox_inches=extent)\n",
    "\n",
    "plot_privacyvsloss(to_plot,[\"PRE-STEP\",\"PRE-STEP-niid\"], shapes = shapes, min_iteration=min_iteration, max_iteration=max_iteration)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c2b481ac",
   "metadata": {},
   "source": [
    "### Affichage des centres de gravit√©\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c0935a",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = global_data.keys()\n",
    "\n",
    "shapes = {\n",
    "    (\"No_noise\",): (\"o\", \"No noise\"),\n",
    "    (\"64\",) : (\"1\",\"œÉ/64\"),\n",
    "    (\"32\",): (\"*\",\"œÉ/32\"),\n",
    "    (\"16\",): (\"D\",\"œÉ/16\"),\n",
    "    (\"8\",): (\"X\",\"œÉ/8\"),\n",
    "    (\"4\",): (\"^\",\"œÉ/4\"),\n",
    "    (\"2\",): (\"s\",\"œÉ/2\")\n",
    "}\n",
    "\n",
    "color_groups = {\n",
    "    # (\"Gaussian\",\"static\"): \"blue\",\n",
    "    # (\"Gaussian\",\"dynamic\") : \"cyan\",\n",
    "    (\"ZeroSum\",\"static\"): \"red\",\n",
    "    (\"ZeroSum\",\"dynamic\"): \"orange\",\n",
    "    (\"Muffliato\",\"static_10step\"): \"violet\",\n",
    "    (\"Muffliato\",\"dynamic_10step\"): \"pink\",\n",
    "    (\"No_noise\", \"static\"):\"darkgreen\",\n",
    "    (\"No_noise\",\"dynamic\") :\"limegreen\",\n",
    "}\n",
    "\n",
    "\n",
    "plot_privacyvsloss(to_plot,[\"PRE-STEP\",\"PRE-STEP-niid\"],display_type = \"center\", shapes = shapes, min_iteration=min_iteration, max_iteration=max_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2f8114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data used for the plots above\n",
    "def save_privacyvsloss(to_plot, locations = [\"PRE-STEP\", \"POST-STEP\"] ,shapes = None,\\\n",
    "                        min_iteration=STARTING_ITERATION, max_iteration=MAX_ITERATIONS):\n",
    "\n",
    "    centroids_data = pd.DataFrame({})\n",
    "    centroids_data.insert(0,\"Method_name\", \"Muffliato\")\n",
    "    centroids_data.insert(1,\"Topology\", \"static\")\n",
    "    centroids_data.insert(2,\"Noise_level\",16)\n",
    "    centroids_data.insert(3,\"Start_iteration\", min_iteration)\n",
    "    centroids_data.insert(4,\"End_iteration\", max_iteration)\n",
    "    \n",
    "    #Instantiate data\n",
    "    for i,attribute in enumerate(attributes):\n",
    "        centroids_data.insert(len(centroids_data.columns),attribute,0)\n",
    "    for j,location in enumerate(locations):\n",
    "        suffix = \"IID\"\n",
    "        if \"niid\" in location: \n",
    "            suffix = \"NIID\"\n",
    "        centroids_data.insert(len(centroids_data.columns),f\"Attacker advantage {suffix}\",0)\n",
    "\n",
    "    print(centroids_data)\n",
    "\n",
    "    for key in to_plot:\n",
    "        data = global_data[key]  \n",
    "        data = clip_iterations_bounds(data,min_iteration=min_iteration,max_iteration=max_iteration)\n",
    "\n",
    "        #Label data correctly\n",
    "        shape_discriminator = find_discriminator(key,shapes)\n",
    "        marker = None\n",
    "        if shape_discriminator is not None:\n",
    "            marker = shapes[shape_discriminator][0]\n",
    "\n",
    "        color_discriminator = find_discriminator(key,color_groups)\n",
    "        color = color_groups[color_discriminator]\n",
    "\n",
    "        #Create the basic data line\n",
    "        data_to_save = {\n",
    "            \"Method_name\": [color_discriminator[0]],\n",
    "            \"Topology\": [color_discriminator[1]],\n",
    "            \"Noise_level\": [format_attribute(shape_discriminator)],\n",
    "            \"Start_iteration\" : [min_iteration],\n",
    "            \"End_iteration\": [max_iteration],\n",
    "        }   \n",
    "\n",
    "        for i,attribute in enumerate(attributes):\n",
    "            for j,location in enumerate(locations):               \n",
    "                x_axis = data[attribute]\n",
    "                y_axis = data[f\"Attacker advantage mean {location}\"]\n",
    "                \n",
    "                \n",
    "\n",
    "                suffix = \"IID\"\n",
    "                if \"niid\" in location: \n",
    "                    suffix = \"NIID\"\n",
    "                x_value = np.mean(x_axis)\n",
    "                y_value = y_axis.mean(axis=0)\n",
    "                \n",
    "                data_to_save[attribute] = x_value\n",
    "                data_to_save[f\"Attacker advantage {suffix}\"] =  y_value\n",
    "        data_to_save = pd.DataFrame(data_to_save)\n",
    "        centroids_data = pd.concat([centroids_data,data_to_save])\n",
    "    print(centroids_data)\n",
    "    print(f\"Saving centroids data to {save_directory}/centroid_data.csv\")\n",
    "    centroids_data.to_csv(f\"{save_directory}/centroid_data.csv\")\n",
    "\n",
    "save_privacyvsloss(to_plot,[\"PRE-STEP\",\"PRE-STEP-niid\"], shapes = shapes, min_iteration=min_iteration, max_iteration=max_iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553cd6f2",
   "metadata": {},
   "source": [
    "## Computing byte ratio for effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14149846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_highest_acc(data,metric):\n",
    "    data_to_consider = data[[\"iteration\", metric]]\n",
    "    best_acc = data_to_consider[metric].iloc[0]\n",
    "    best_iteration = data_to_consider[\"iteration\"].iloc[0]\n",
    "\n",
    "    for index, line in data_to_consider.iterrows():\n",
    "        current_iteration, current_acc = line[\"iteration\"],line[metric]\n",
    "        if current_acc>best_acc:\n",
    "            best_acc = current_acc\n",
    "            best_iteration = current_iteration\n",
    "    return best_iteration, best_acc\n",
    "\n",
    "def find_intersection_acc(data,objective,metric):\n",
    "    # Will return the 1st iteration above witch data[metric]> objective\n",
    "    data_to_consider = data[[\"iteration\", metric]]\n",
    "    for index,line in data_to_consider.iterrows():\n",
    "        iteration,current_acc = line[\"iteration\"], line[metric]\n",
    "        if current_acc>=objective:\n",
    "            # print(current_acc)\n",
    "            return iteration\n",
    "    # print(current_acc)\n",
    "    return iteration \n",
    "\n",
    "\n",
    "def compute_crossing_iteration(data_muffliato,data_zerosum,metric,objective=0.95):\n",
    "    '''\n",
    "    This function returns a tuple (iteration_muffliato, iteration_zerosum), where:\n",
    "        iteration_muffliato (int) : the iteration at which the metric for Muffliato goes above 95% of the best value of this metric for Muffliato\n",
    "        iteration_zerosum (int): the iteration at which the metric for ZeroSum goes above 95% of the best value of this metric for Muffliato\n",
    "        objective (float):  The target accuracy. either <=1, and is considered a ratio of Muffliato top accuracy, or >1 and is considered a hard target. \n",
    "    '''\n",
    "  \n",
    "    if objective <=1:\n",
    "        best_iteration_muffliato,best_acc_muffliato = find_highest_acc(data_muffliato,metric)\n",
    "        reference_accuracy = objective*best_acc_muffliato\n",
    "\n",
    "    else:\n",
    "        reference_accuracy = objective\n",
    "    \n",
    "    crossing_muffliato = find_intersection_acc(data_muffliato,reference_accuracy, metric)\n",
    "    print(f\" {reference_accuracy} accuracy for Muffliato :{crossing_muffliato}\")\n",
    "\n",
    "    crossing_zerosum = find_intersection_acc(data_zerosum,reference_accuracy,metric)\n",
    "\n",
    "    # print(f\" {objective} accuracy for zerosum :{crossing_zerosum}\")\n",
    "\n",
    "    return int(crossing_muffliato), int(crossing_zerosum), reference_accuracy\n",
    "\n",
    "\n",
    "def compute_communication_ratio(data,name_muffliato,name_zerosum,metric,objective=0.95):\n",
    "    '''\n",
    "    objective (float): either <1, and is considered a ratio, or >1 and is considered a hard target. \n",
    "    '''\n",
    "    data_muffliato = data[name_muffliato][[\"iteration\", metric, \"total_bytes sum\"]]\n",
    "    data_zerosum = data[name_zerosum][[\"iteration\", metric, \"total_bytes sum\"]]\n",
    "\n",
    "    iteration_muffliato, iteration_zerosum,target_accuracy = compute_crossing_iteration(data_muffliato,data_zerosum, metric=metric, objective= objective)\n",
    "\n",
    "    data_muffliato = data_muffliato[data_muffliato[\"iteration\"] == iteration_muffliato]\n",
    "    data_zerosum = data_zerosum[data_zerosum[\"iteration\"] == iteration_zerosum]\n",
    "\n",
    "    total_bytes_muffliato = data_muffliato[\"total_bytes sum\"].item()\n",
    "    total_bytes_zerosum = data_zerosum[\"total_bytes sum\"].item()\n",
    "\n",
    "    res = {\n",
    "        \"ratio\" : total_bytes_muffliato/total_bytes_zerosum,\n",
    "        \"total_bytes_muffliato\": total_bytes_muffliato,\n",
    "        \"total_bytes_zerosum\" : total_bytes_zerosum,\n",
    "        \"best_iteration_muffliato\":iteration_muffliato,\n",
    "        \"best_iteration_zerosum\":iteration_zerosum,\n",
    "        \"target_accuracy\": target_accuracy,\n",
    "    }\n",
    "    return res\n",
    "\n",
    "\n",
    "ratio_data_frame = None\n",
    "\n",
    "for target in [1,0.95,20,30,40,50,60,70]:\n",
    "# for target in [1]:\n",
    "    ratio_data ={\n",
    "            \"ratio\" : {},\n",
    "            \"target\": {},\n",
    "            \"total_bytes_muffliato\": {},\n",
    "            \"total_bytes_zerosum\" : {},\n",
    "            \"best_iteration_muffliato\": {},\n",
    "            \"best_iteration_zerosum\": {},\n",
    "            \"target_accuracy\": {},\n",
    "    }\n",
    "    for noise in [\"64\",\"32\",\"16\",\"8\",\"4\",\"2\"]:\n",
    "        name_muffliato = f\"Muffliato{noise}_static_10steps\"\n",
    "        name_zerosum = f\"ZeroSum{noise}_static\"\n",
    "        res = compute_communication_ratio(global_data,name_muffliato,name_zerosum,\"test_acc mean\",target)\n",
    "        res[\"target\"] = target\n",
    "        for (key,value) in res.items():\n",
    "            ratio_data[key][noise] = value     \n",
    "        print(f\"Noise œÉ/{noise} : {res['ratio']:.3f}\") #, Muffliato : {total_bytes_muffliato}, ZeroSum : {total_bytes_zerosum}\")\n",
    "\n",
    "    ratio_data = pd.DataFrame(ratio_data)\n",
    "    if ratio_data_frame is None:\n",
    "        ratio_data_frame = ratio_data\n",
    "    else:\n",
    "        ratio_data_frame = pd.concat([ratio_data_frame,ratio_data])\n",
    "ratio_data_frame.rename_axis(\"Noise_level\",axis=0) \n",
    "ratio_data_frame.to_csv(f\"{save_directory}/network_data.csv\")\n",
    "print(ratio_data_frame)\n",
    "ratio_data_frame"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30fce65a",
   "metadata": {},
   "source": [
    "## Utility comparison display\n",
    "We will simply present the utility of each method in a clearer manner here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d608c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in global_data.keys():\n",
    "    print(f\"\\\"{key}\\\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b28520f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"test_acc\",\"test_niid_acc\"]\n",
    "figsize = (20,4)\n",
    "alpha = 0.4\n",
    "width = 0.25  # the width of the bars\n",
    "window_size = 1\n",
    "ncols = 1\n",
    "\n",
    "topology = \"static\"\n",
    "\n",
    "\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "total_colors = prop_cycle.by_key()['color']\n",
    "\n",
    "attributes = [ #The attributes to display and color by\n",
    "    ([\"Muffliato\", \"static_10step\"],total_colors[0]),\n",
    "    # ([\"Muffliato\", \"dynamic\"],total_colors[1]),\n",
    "    # ([\"Gaussian\", \"static\"],total_colors[2]),\n",
    "    # ([\"Gaussian\", \"dynamic\"],total_colors[3]),\n",
    "    ([\"ZeroSum\", \"static\"],total_colors[4]),\n",
    "    # ([\"ZeroSum\", \"dynamic\"],total_colors[5]) \n",
    "]\n",
    "\n",
    "\n",
    "baselines = {\n",
    "    f\"No_noise_static\" : \"b\",\n",
    "    # f\"No_noise_dynamic\" : \"r\"\n",
    "}\n",
    "\n",
    "to_plot = [[\"64\"],[\"32\"], [\"16\"], [\"8\"], [\"4\"], [\"2\"]]\n",
    "for e in to_plot:\n",
    "    e.append(topology)\n",
    "\n",
    "\n",
    "\n",
    "to_plot_dict = {}\n",
    "for attr_list in to_plot:\n",
    "    to_plot_dict[attr_list[0]] = []\n",
    "\n",
    "for e in global_data.keys():\n",
    "    for attr_list in to_plot:\n",
    "        match = True\n",
    "        for attr in attr_list:\n",
    "            if attr not in e:\n",
    "                match = False\n",
    "                break\n",
    "        if match:\n",
    "            to_plot_dict[attr_list[0]].append(e)\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "def is_attribute_match(name,attribute_list):\n",
    "    is_match = True\n",
    "    for attribute in attribute_list:\n",
    "        if attribute not in name:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def get_last_n_indexes(data_to_consider,window_size):\n",
    "    data = data_to_consider.tail(window_size)\n",
    "    return data.index\n",
    "\n",
    "def plot_utility(metric,to_plot_dict,baselines, window_size):\n",
    "    fig,ax = plt.subplots(figsize=figsize)\n",
    "    x = np.arange(len(to_plot_dict.keys()))\n",
    "    indexes = None\n",
    "    multiplier = 0\n",
    "    total_plot = {}\n",
    "    for name,keys in to_plot_dict.items():\n",
    "        for key in keys:\n",
    "            data = global_data[key]\n",
    "            data_to_consider = data[f\"{metric} mean\"].dropna()\n",
    "            if indexes is None:\n",
    "                indexes = get_last_n_indexes(data_to_consider, window_size)\n",
    "                # print(indexes)\n",
    "            data_to_plot = np.mean(data_to_consider[indexes])\n",
    "            # print(f\"{key} : {data_to_plot}\")\n",
    "            for attribute_list,color in attributes:\n",
    "                \n",
    "                if is_attribute_match(key,attribute_list):\n",
    "                    attribute = \" \".join(attribute_list)\n",
    "                    if (attribute,color) not in total_plot.keys():\n",
    "                        total_plot[(attribute,color)] = []\n",
    "                    total_plot[(attribute,color)].append(data_to_plot)\n",
    "\n",
    "    for (attribute,color), data_to_plot in total_plot.items():\n",
    "        offset = width * multiplier\n",
    "        rects = plt.bar(x + offset, data_to_plot, width, label=attribute,color=color)\n",
    "        plt.bar_label(rects, padding=len(keys))\n",
    "        multiplier += 1\n",
    "\n",
    "    #Draw the baseline:\n",
    "    for key,color in baselines.items():\n",
    "        data = global_data[key]\n",
    "        data_to_consider = data[f\"{metric} mean\"].dropna()\n",
    "        data_to_plot = np.mean(data_to_consider[indexes])\n",
    "        plt.axhline(y=data_to_plot,linewidth=1,label = key,linestyle =\"--\",color= color)\n",
    "\n",
    "    # plt.bar(x,y,color = total_colors,alpha = alpha)\n",
    "    ax.set_xticks(x + ((len(keys)-1) * width/2), to_plot_dict.keys(),fontsize=fontsize)\n",
    "    plt.ylabel(f\"{metric}\",fontsize=fontsize)\n",
    "    plt.grid()\n",
    "    if topology != None:\n",
    "        plt.title(f\"Mean of last {window_size} {metric} comparison, {topology} topology\")\n",
    "    else:\n",
    "        plt.title(f\"Mean of last {window_size} {metric} comparison\")\n",
    "    plt.legend(fontsize=fontsize*2/3,ncol = ncols )\n",
    "    plt.tick_params(labelbottom=True,labelleft = True,axis=\"both\", labelsize=2*fontsize/3)\n",
    "    extent = fig.axes[0].get_tightbbox(fig.canvas.get_renderer()).transformed(fig.dpi_scale_trans.inverted())\n",
    "    fig.savefig(f\"{save_directory}/{fig.axes[0].get_title()}\", bbox_inches=extent)\n",
    "    # plt.rc('ytick',labelsize=fontsize)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for name,keys in to_plot_dict.items():\n",
    "    print(f\"{name} : {keys}\")\n",
    "for metric in metrics:\n",
    "    plot_utility(metric,to_plot_dict,baselines,window_size)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ba9658",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols=1\n",
    "\n",
    "attributes = [ #The attributes to display and color by\n",
    "    # ([\"Muffliato\", \"static\"],total_colors[0]),\n",
    "    ([\"Muffliato\", \"dynamic\"],total_colors[1]),\n",
    "    # ([\"Gaussian\", \"static\"],total_colors[2]),\n",
    "    ([\"Gaussian\", \"dynamic\"],total_colors[3]),\n",
    "    # ([\"ZeroSum\", \"static\"],total_colors[4]),\n",
    "    ([\"ZeroSum\", \"dynamic\"],total_colors[5]) \n",
    "]\n",
    "topology=\"dynamic\"\n",
    "baselines = {\n",
    "    f\"No_noise_static\" : \"b\",\n",
    "    f\"No_noise_dynamic\" : \"r\"\n",
    "}\n",
    "to_plot = [[\"64\"],[\"32\"], [\"16\"], [\"8\"], [\"4\"], [\"2\"]]\n",
    "# to_plot = [[\"32\"], [\"16\"], [\"8\"]]\n",
    "\n",
    "for e in to_plot:\n",
    "    e.append(topology)\n",
    "\n",
    "to_plot_dict = {}\n",
    "for attr_list in to_plot:\n",
    "    to_plot_dict[attr_list[0]] = []\n",
    "\n",
    "# Initialize the dict of things to plot and group by\n",
    "for e in global_data.keys():\n",
    "    for attr_list in to_plot:\n",
    "        match = True\n",
    "        for attr in attr_list:\n",
    "            if attr not in e:\n",
    "                match = False\n",
    "                break\n",
    "        if match:\n",
    "            to_plot_dict[attr_list[0]].append(e)\n",
    "            break\n",
    "\n",
    "for name,keys in to_plot_dict.items():\n",
    "    print(f\"{name} : {keys}\")\n",
    "for metric in metrics:\n",
    "    plot_utility(metric,to_plot_dict,baselines,window_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d9a0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 0.20  # the width of the bars\n",
    "ncols=2\n",
    "attributes = [ #The attributes to display and color by\n",
    "    ([\"Muffliato\", \"static\"],total_colors[0]),\n",
    "    ([\"Muffliato\", \"dynamic\"],total_colors[1]),\n",
    "    ([\"Gaussian\", \"static\"],total_colors[2]),\n",
    "    ([\"Gaussian\", \"dynamic\"],total_colors[3]),\n",
    "    ([\"ZeroSum\", \"static\"],total_colors[4]),\n",
    "    ([\"ZeroSum\", \"dynamic\"],total_colors[5]) \n",
    "]\n",
    "topology = None\n",
    "\n",
    "baselines = {\n",
    "    f\"No_noise_static\" : \"b\",\n",
    "    f\"No_noise_dynamic\" : \"r\"\n",
    "}\n",
    "to_plot = [[\"64\"],[\"32\"], [\"16\"], [\"8\"], [\"4\"], [\"2\"]]\n",
    "\n",
    "\n",
    "\n",
    "to_plot_dict = {}\n",
    "for attr_list in to_plot:\n",
    "    to_plot_dict[attr_list[0]] = []\n",
    "\n",
    "# Initialize the dict of things to plot and group by\n",
    "for e in global_data.keys():\n",
    "    for attr_list in to_plot:\n",
    "        match = True\n",
    "        for attr in attr_list:\n",
    "            if attr not in e:\n",
    "                match = False\n",
    "                break\n",
    "        if match:\n",
    "            to_plot_dict[attr_list[0]].append(e)\n",
    "            break\n",
    "\n",
    "for name,keys in to_plot_dict.items():\n",
    "    print(f\"{name} : {keys}\")\n",
    "for metric in metrics:\n",
    "    plot_utility(metric,to_plot_dict,baselines,window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b48aaf3",
   "metadata": {},
   "source": [
    "TODO: remove the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1c8a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = {\n",
    "    \"Gaussian_static\" : [key for key in global_data.keys() if \"Gaussian\" in key and \"static\" in key],\n",
    "    \"Gaussian_dynamic\" : [key for key in global_data.keys() if \"Gaussian\" in key and \"dynamic\" in key],\n",
    "    \"ZeroSum_static\" : [key for key in global_data.keys() if \"ZeroSum\" in key and \"static\" in key],\n",
    "    \"ZeroSum_dynamic\" : [key for key in global_data.keys() if \"ZeroSum\" in key and \"dynamic\" in key],\n",
    "    \"No noise_static\" : [\"No noise_static\"],\n",
    "    \"No noise_dynamic\" : [\"No noise_dynamic\"]\n",
    "}\n",
    "\n",
    "baseline = [\"No_noise_static\", \"No_noise_dynamic\"]\n",
    "colors = {\n",
    "    \"static\" : \"b\",\n",
    "    \"dynamic\" : \"r\"\n",
    "}\n",
    "metrics = [\"test_acc\",\"test_niid_acc\"]\n",
    "\n",
    "for metric in metrics:\n",
    "    fig = plt.figure(figsize = figsize)\n",
    "    indexes = None\n",
    "    for expe_type, expe_list in to_plot.items():\n",
    "        \n",
    "        if len(expe_list) == 1 and expe_list[0] in baseline:\n",
    "            expe = expe_list[0] \n",
    "            data = global_data[expe][f\"{metric} mean\"].dropna()\n",
    "            \n",
    "            if indexes is None:\n",
    "                indexes = get_last_n_indexes(data,window_size)\n",
    "                print(indexes)\n",
    "            y_value = np.mean(data[indexes])\n",
    "            found = False\n",
    "            for substring,color in colors.items():\n",
    "                if substring in expe:\n",
    "                    plt.axhline(y=y_value,linewidth=1, color=color,label = expe,linestyle =\"--\")\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                plt.axhline(y=y_value,linewidth=1,label = expe,linestyle =\"--\")\n",
    "        else:\n",
    "            data_to_plot = []\n",
    "            for expe in expe_list:\n",
    "                data = global_data[expe]\n",
    "                x_value = np.mean(data[\"generated_noise_std\"][\"mean\"])\n",
    "\n",
    "                data = data[metric][\"mean\"].dropna()\n",
    "                if indexes is None:    \n",
    "                    indexes = get_last_n_indexes(data,window_size)\n",
    "                    print(indexes)\n",
    "                y_value = np.mean(data[indexes])\n",
    "                data_to_plot.append((x_value,y_value))\n",
    "\n",
    "            data_to_plot.sort(key = lambda x : x[0])\n",
    "\n",
    "            plt.plot([x for (x,y) in data_to_plot],[y for (x,y) in data_to_plot], marker = 'o', label=expe_type)\n",
    "\n",
    "    \n",
    "    plt.legend(fontsize=fontsize*2/3)\n",
    "    plt.xlabel(\"Noise level\",fontsize=fontsize)\n",
    "    plt.ylabel(metric,fontsize=fontsize)\n",
    "    plt.tick_params(labelbottom=True,labelleft = True,axis=\"both\", labelsize=2*fontsize/3)\n",
    "    plt.title(f\"Evolution of the last {window_size} {metric} according to noise level\",fontsize=fontsize)\n",
    "    plt.grid()\n",
    "    ax = fig.axes[0]\n",
    "    extent = ax.get_tightbbox(fig.canvas.get_renderer()).transformed(fig.dpi_scale_trans.inverted())\n",
    "    fig.savefig(f\"{save_directory}/{ax.get_title()}\", bbox_inches=extent)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78002bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
